{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with chunking/embedding code from https://huggingface.co/learn/cookbook/advanced_rag on PythonDSHandbook.txt, Week7-lecture.txt, Week9-lecture.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from tqdm.notebook import tqdm #progress bar\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple #type hinting\n",
    "# from datasets import Dataset #to load in premade example datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # This will be helpful when visualizing retriever outputs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #splitter\n",
    "\n",
    "#load in Documents\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter #alt import\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# embedding and searching\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "#plotting\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:24<00:00, 28.32s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88289dacc6ec4d698453ef6cfc8cef3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load in docs (must be in IA-in-HigherEd dir)\n",
    "loader = DirectoryLoader('./RAG-docs/processed/', glob=\"**/*.txt\", show_progress = True) #all .txt files in processed folder\n",
    "docs = loader.load()\n",
    "docs\n",
    "\n",
    "# save as LC docs\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc.page_content, metadata={\"source\": doc.metadata}) for doc in tqdm(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faaee2a74a546a8b2aa49d3047c2653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wat6sv\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df64dc2227f648b6a73c435922359f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be059f809d4b4a908a00c149af255cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0340a746ae7446d958661dedfff1549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a53fc68c1f4a8abe2b6ab48c5bb541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApAAAAGxCAYAAADVrYZeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABEHUlEQVR4nO3deXgV5d3/8c+BnJwsJCEhJCeBEAIFXAJoQVaVJRBAVgFRUQuCLS7QIlCr8oiJVVC0iMWKtSqLimBbiCgIBFmUB1BArUCtYmVVQpQdAiEk9+8Pf5mHQxLIDUlOAu/XdeWCM3OfmXvmOzPnk1lOXMYYIwAAAKCUqvm7AwAAAKhaCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWrALkzJkz5XK5nJ+goCB5vV516tRJkyZNUnZ2dpH3pKWlyeVyWXUqJydHaWlpWrVqldX7iptX/fr11atXL6vpnM+cOXM0derUYse5XC6lpaWV6fzK2ocffqiWLVsqNDRULpdLGRkZVu9ftWqVXC6XdX0uFxMnTrRap5VpmznXvle4f/3000/lNv/69etr6NChZTa9tWvXKi0tTYcOHSp2XmV9bChORc2nrHTs2FEdO3Ys02mWdV1Lq/Aza+PGjRU+74v18ccfy+PxaOfOnc6w8qhNZXahWaA0duzYoZ49eyoqKkoul0ujR48usa3tMf1shZ+Z//jHPy54GuXlscce0y9/+UsVFBRYv/eCzkDOmDFD69atU2Zmpv7yl7/ommuu0TPPPKMrr7xSy5cv92l7zz33aN26dVbTz8nJUXp6uvVGcyHzuhDnCpDr1q3TPffcU+59uFDGGA0aNEhut1sLFy7UunXr1KFDB39365JysQcbf7rQfa+sLFiwQI899liZTW/t2rVKT08vNkAClZUxRqNHj9avf/1rJSYmOsNfeuklvfTSS37sWcUqz+PRgw8+qE8++USvv/661q1bpwcffLDEtlX5mH4+48aN0/bt2zVr1izr9wZcyAyTk5PVsmVL5/WAAQP04IMP6vrrr1f//v21bds2xcbGSpLq1q2runXrXshsSi0nJ0chISEVMq/zadOmjV/nfz4//PCDDhw4oJtvvlkpKSn+7g7g49prr/V3FwC/W7JkiT777DPNmTPHZ/hVV13lpx5derZs2aJWrVqpX79+/u6KX0VEROjOO+/U008/raFDh1pdMS6zeyDr1aunP/3pTzp69Kj++te/OsOLu6y8YsUKdezYUbVq1VJwcLDq1aunAQMGKCcnRzt27FDt2rUlSenp6c7l8sLLH4XT++yzzzRw4EBFRkaqYcOGJc6r0IIFC9SsWTMFBQWpQYMG+vOf/+wzvvBSx44dO3yGn325tmPHjlq0aJF27tzpczm/UHGXI7ds2aK+ffsqMjJSQUFBuuaaa4qk/cL5vP322xo/frzi4+MVHh6uLl266Ouvvy55xZ9hzZo1SklJUVhYmEJCQtSuXTstWrTIGZ+WluYE7D/84Q9yuVyqX7/+Oaf5n//8R927d1dISIiio6N177336ujRo8W2ff3119W8eXMFBQUpKipKN998s7766qsi7T755BP17t1btWrVUlBQkBo2bOhz+WDo0KHF9qu4+rpcLo0cOVIzZsxQkyZNFBwcrJYtW2r9+vUyxujZZ59VUlKSatSooc6dO+vbb78tMt3ly5crJSVF4eHhCgkJUfv27fXhhx8WO++tW7fq9ttvV0REhGJjYzVs2DAdPnzYpz/Hjx/XrFmznG3jQi45ZWVlacSIEapbt64CAwOVlJSk9PR0nT592mmzY8cOuVwuPffcc5oyZYqznG3bttX69euLTPNvf/ubGjduLI/Ho6uuukpz5szxWdfn2/cK7du375zrQJL+/ve/q3Xr1oqIiFBISIgaNGigYcOGnXe5z77UeTH7RVpamn7/+99LkpKSkpzlOftsxpIlS/TLX/5SwcHBuuKKK/T6668XmVZp6mHjpZdeUkBAgB5//HFJ9rVcuHCh2rZtq5CQEIWFhalr164+V1+2bt0ql8ulv//9786wTZs2yeVy6eqrr/aZVp8+fdSiRYtz9vfUqVN68skndcUVV8jj8ah27dq6++679eOPP/q0y8vL00MPPSSv16uQkBBdf/31+vTTT4ud5po1a9S2bVsFBQWpTp06euyxx/Tqq68WexyeN2+e2rZtq9DQUNWoUUPdunXT559/fs4+n+ngwYO6++67FRUVpdDQUPXu3VvfffedT5vMzEz17dtXdevWVVBQkH7xi19oxIgRRW7Z+PHHH/Wb3/xGCQkJzrpo3759katvpTmulGT69Om67rrr1KRJE5/hZ1/Ctt1uivP99987yxMYGKj4+HgNHDhQ+/btc9rs2rVLd955p2JiYuTxeHTllVfqT3/6k89lz5JubSrs48yZM51hQ4cOVY0aNfTtt9/qpptuUo0aNZSQkKCxY8cqNzfXeV9pjkdnO19fC/v57bff6oMPPnCme/Y2V+h8x/TSfL4X58iRI+rWrZtiY2OdfaS0+1nhbTHnO3bl5ORo3LhxSkpKcj6XW7Zsqbffftun3V133aVvvvlGK1euPG+/fRgLM2bMMJLMhg0bih1/7NgxU716dZOSkuIMe/zxx82Zs9m+fbsJCgoyXbt2NRkZGWbVqlXmrbfeMnfddZc5ePCgOXnypFmyZImRZIYPH27WrVtn1q1bZ7799luf6SUmJpo//OEPJjMz02RkZBQ7L2OMSUxMNHXq1DH16tUzr7/+ulm8eLG54447jCTz7LPPFlm27du3+7x/5cqVRpJZuXKlMcaYrVu3mvbt2xuv1+v0bd26dU57Sebxxx93Xv/nP/8xYWFhpmHDhmb27Nlm0aJF5vbbbzeSzDPPPFNkPvXr1zd33HGHWbRokXn77bdNvXr1TKNGjczp06fPWZtVq1YZt9ttWrRoYebNm2cyMjJMamqqcblcZu7cucYYY3bv3m3mz59vJJlRo0aZdevWmc8++6zEaWZlZZmYmBhTp04dM2PGDGfd1atXz2edGGPMxIkTjSRz++23m0WLFpnZs2ebBg0amIiICPPNN9847ZYsWWLcbrdp1qyZmTlzplmxYoV5/fXXzW233ea0GTJkiElMTCzSn+LqW7gttGvXzsyfP98sWLDANG7c2ERFRZkHH3zQ9O3b17z//vvmrbfeMrGxsaZZs2amoKDAef8bb7xhXC6X6devn5k/f7557733TK9evUz16tXN8uXLi8y7SZMmZsKECSYzM9NMmTLFeDwec/fddzvt1q1bZ4KDg81NN93kbBtbt249Z+3O3mb27t1rEhISTGJiovnrX/9qli9fbv74xz8aj8djhg4d6rTbvn27s810797dZGRkmIyMDNO0aVMTGRlpDh065LT961//aiSZAQMGOOujcePGJjEx0VnXpd33zrcO1q5da1wul7ntttvM4sWLzYoVK8yMGTPMXXfddc71YMzP++uQIUOc1xezX+zevduMGjXKSDLz5893lufw4cPOvOrWrWuuuuoqM3v2bLN06VJzyy23GElm9erV1vU41zL17NnTGGNMQUGBGTt2rHG73WbGjBlOG5tavvXWW0aSSU1NNRkZGWbevHmmRYsWJjAw0Hz88cdOu7i4OPOb3/zGef3000+b4OBgI8l8//33xhhj8vLyTHh4uHnooYecdh06dDAdOnRwXufn55vu3bub0NBQk56ebjIzM82rr75q6tSpY6666iqTk5PjtB0yZIhxuVzm97//vVm2bJmZMmWKqVOnjgkPD/ep67/+9S8TFBRkmjVrZubOnWsWLlxobrrpJlO/fv0ix+GnnnrKuFwuM2zYMPP++++b+fPnm7Zt25rQ0NDz7luFx/WEhAQzbNgw88EHH5hXXnnFxMTEmISEBHPw4EGn7fTp082kSZPMwoULzerVq82sWbNM8+bNTZMmTcypU6ecdt26dTO1a9c2r7zyilm1apXJyMgwEyZMcI6zxpT+uFKc3NxcExwc7FOTkmpjs90UZ8+ePSYuLs5ER0ebKVOmmOXLl5t58+aZYcOGma+++soYY0x2drapU6eOqV27tnn55ZfNkiVLzMiRI40kc9999znTOvuz8uw+nrm9DxkyxAQGBporr7zSPPfcc2b58uVmwoQJxuVymfT0dGPM+Y9HxSlNXw8fPmzWrVtnvF6vad++vTPdkydPFjvNcx3TbT/f//73vxtjfj42NW3a1DRp0sT897//NcbY7WelPXaNGDHChISEmClTppiVK1ea999/3zz99NNm2rRpPst4+vRpU6NGDTNmzJgS121xyjRAGmNMbGysufLKK53XZ3/o/+Mf/zCSzBdffFHiNH788cciH6pnT2/ChAkljjtTYmKicblcRebXtWtXEx4ebo4fP+6zbOcLkMYY07Nnz2IDjjFFw8Btt91mPB6P2bVrl0+7Hj16mJCQEGcHL5zPTTfd5NPunXfeMZJ8Qmpx2rRpY2JiYszRo0edYadPnzbJycmmbt26Tmgq3JnPDM8l+cMf/lDiujtznRw8eNDZwc60a9cu4/F4zODBg51hDRs2NA0bNjQnTpwocb62AdLr9Zpjx445wzIyMowkc8011/iExalTpxpJ5ssvvzTGGHP8+HETFRVlevfu7TPN/Px807x5c9OqVasi8548ebJP2/vvv98EBQX5zCc0NNTnw/J8zt5mRowYYWrUqGF27tzp0+65554zkpyDV2EtmzZt6hOkPv30UyPJvP32287yeL1e07p1a5/p7dy507jdbp91XZp973zroLCf5/vwKk5JAfJC94tnn3222P26cF5BQUE+6/nEiRMmKirKjBgxwhlW2nqca5l69uxpcnJyzIABA0xERESREGFTy/j4eNO0aVOTn5/vtDt69KiJiYkx7dq1c4bdeeedpkGDBs7rLl26mF//+tcmMjLSzJo1yxhjzP/+7/8aSWbZsmVOu7NDyttvv20kmX/+858+fd6wYYORZF566SVjjDFfffWVkWQefPBBn3aFgffMut5yyy0mNDTU/Pjjj86w/Px8c9VVV/nUa9euXSYgIMCMGjXKZ5pHjx41Xq/XDBo0yJxL4XH95ptv9hleuNxPPvlkse8rKCgweXl5ZufOnUaSeffdd51xNWrUMKNHjy5xnjbHleJ88sknRpJPIC1UUoA833ZTkmHDhhm3223+/e9/l9jm4YcfNpLMJ5984jP8vvvuMy6Xy3z99dfGGPsAKcm88847Pm1vuukm06RJE+f1uY5HF9NXY3x/sTufko7ptp/vf//7383nn39u4uPjzQ033GD279/vvKe0+1lh30tz7EpOTjb9+vUr1TK2b9++yGfE+ZT51/gYY845/pprrlFgYKB+85vfaNasWUUuI5TWgAEDSt326quvVvPmzX2GDR48WEeOHNFnn312QfMvrRUrViglJUUJCQk+w4cOHaqcnJwiD/306dPH53WzZs0kyedJvLMdP35cn3zyiQYOHKgaNWo4w6tXr6677rpLe/bsKfVl8DOtXLmyxHV3pnXr1unEiRNFLi0kJCSoc+fOzmWbb775Rv/97381fPhwBQUFWfenJJ06dVJoaKjz+sorr5Qk9ejRw+eSd+HwwnW5du1aHThwQEOGDNHp06edn4KCAnXv3l0bNmzQ8ePHfeZVXH1OnjxZ7DcQXKj3339fnTp1Unx8vE+/evToIUlavXq1T/uePXuqevXqPn06czm//vprZWVladCgQT7vq1evntq3b2/dv/Otg+uuu06SNGjQIL3zzjv6/vvvredRmnlK594vSuOaa65RvXr1nNdBQUFq3Lixz3Rt61Gc/fv3q3Pnzvr000+dW02KU5pa/vDDD7rrrrtUrdr/Hb5r1KihAQMGaP369crJyZEkpaSk6LvvvtP27dt18uRJrVmzRt27d1enTp2UmZkp6efLrB6PR9dff32JfX///fdVs2ZN9e7d22f5r7nmGnm9XueSZeHlrzvuuMPn/YMGDVJAgO/t9qtXr1bnzp0VHR3tDKtWrVqRbXTp0qU6ffq0fvWrX/nMOygoSB06dCj1wxVn96ldu3ZKTEz0uWSXnZ2te++9VwkJCQoICJDb7XYeYDnzVpxWrVpp5syZevLJJ7V+/Xrl5eX5TPtCjitn+uGHHyRJMTExpVo26fzbTUk++OADderUyTk2FmfFihW66qqr1KpVK5/hQ4cOlTFGK1asKHU/z+RyudS7d2+fYc2aNbuofbq8+nqu+dl8vi9dulQ33HCDbrzxRmVmZioqKsoZV9r9rFBpjl2tWrXSBx98oIcfflirVq3SiRMnSlyWmJgY62N1mQbI48ePa//+/YqPjy+xTcOGDbV8+XLFxMTogQceUMOGDdWwYUO98MILVvOKi4srdVuv11visP3791vN19b+/fuL7WvhOjp7/rVq1fJ57fF4JOmchT948KCMMVbzKY39+/efc92d2U4qvibx8fHO+ML7OMr6Qaczd0JJCgwMPOfwkydPSpJzj8/AgQPldrt9fp555hkZY3TgwAGfaVxIfWzt27dP7733XpE+Fd67dvY9WefrU+H6L3yw7UzFDTuf883vxhtvVEZGhvPBX7duXSUnJxe576Ys51lW0y2c9pnTta1Hcb755ht98skn6tGjh5KTk0vdn5JqWdK+VlBQoIMHD0qSunTpIunnkLhmzRrl5eWpc+fO6tKli/NL3fLly9W+fXsFBweX2Kd9+/bp0KFDCgwMLLIOsrKynOUv7NvZx4eAgIAiy7V///5SbY+F++h1111XZN7z5s0r9VdKlXQcK+xzQUGBUlNTNX/+fD300EP68MMP9emnnzr3EZ65PcybN09DhgzRq6++qrZt2yoqKkq/+tWvlJWV5dNnm+PKmQrnZfNL9oXuHz/++ON5j8e2n2GlFRISUmQZPR6Pc3y+EOXV17KaX0ZGhk6cOKH77rvPqVGh0u5nhUpz7Przn/+sP/zhD8rIyFCnTp0UFRWlfv36adu2bUXeGxQUZH08vaCnsEuyaNEi5efnn/ehgRtuuEE33HCD8vPztXHjRk2bNk2jR49WbGysbrvttlLNy+ZJocIdu7hhhUUo3JALb+AtdLHfeVerVi3t3bu3yPDC3zLP/A38QkVGRqpatWplPp9atWqdc92d2U5SifMvnHfhDdF79uw553yDgoKK1EG6+FqcrbBf06ZNK/Hp+QsJWBcrOjpazZo101NPPVXs+HP9glacwvqceVN8oeLqWxb69u2rvn37Kjc3V+vXr9ekSZM0ePBg1a9fX23bti2XeZaXsqhH27Ztdcstt2j48OGSfn5I4swziKV1vn2tWrVqioyMlPTzL2qNGzfW8uXLVb9+fbVs2VI1a9ZUSkqK7r//fn3yySdav3690tPTzznP6Oho1apVS0uWLCl2fFhYmE/fsrKyVKdOHWf86dOni/1FuTTbY+E++o9//MPn62xslXQc+8UvfiHp5wch/vWvf2nmzJkaMmSI06a4h+6io6M1depUTZ06Vbt27dLChQv18MMPKzs7W0uWLLno40rh+88VMstK7dq1z3s8Lu1nWHl9htqoiM/bi5nf888/r3nz5qlHjx5asGCBUlNTnXGl3c9shIaGKj09Xenp6dq3b59zNrJ37976z3/+49P2wIED1uunzM5A7tq1S+PGjVNERIRGjBhRqvdUr15drVu31l/+8hdJci4nl/VZna1bt+pf//qXz7A5c+YoLCxMv/zlLyXJeRL1yy+/9Gm3cOHCItM7O+WfS0pKilasWOFsUIVmz56tkJCQMvnan9DQULVu3Vrz58/36VdBQYHefPNN54PEVqdOnUpcd2dq27atgoOD9eabb/oM37Nnj3OKX5IaN26shg0b6vXXXy82IBaqX7++srOzfT5gTp06paVLl1ovw7m0b99eNWvW1L///W+1bNmy2J/Cs5Y2bLaP4vTq1UtbtmxRw4YNi+2TbYBs0qSJvF6v3nnnHZ/hu3bt0tq1a4v0XSq7fc/j8ahDhw565plnJMnqydmymr90cctTVvUYMmSI5s6dqxkzZuhXv/qV8vPzrfvSpEkT1alTR3PmzPG5Xej48eP65z//6TyZXahLly5asWKFMjMz1bVrV0k/74f16tXThAkTlJeX55ypPNfy79+/X/n5+cUuf+GTwoUnDt566y2f97/zzjtFnlbv0KGDVqxY4RMuCgoKfJ4al6Ru3bopICBA//3vf0vcR0vj7D6tXbtWO3fudPpceELi7LNCZ36jSHHq1aunkSNHqmvXrs7n18UeVwovJ//3v/8t1bJdjB49emjlypXnvMUpJSVF//73v4vc7jV79my5XC516tRJkt1naGnZ7r+l7euF9KO4Pth+vgcFBWn+/Pnq1auX+vTpo3fffdcZV9r97ELFxsZq6NChuv322/X11187t7oU+u6776y/JuqCzkBu2bLFuT6fnZ2tjz/+WDNmzFD16tW1YMEC50xTcV5++WWtWLFCPXv2VL169XTy5Enn0fPCA1lYWJgSExP17rvvKiUlRVFRUYqOjj7vV86UJD4+Xn369FFaWpri4uL05ptvKjMzU88884xzsC38yoRx48bp9OnTioyM1IIFC7RmzZoi02vatKnmz5+v6dOnq0WLFqpWrVqJB7LHH3/cuYdqwoQJioqK0ltvvaVFixZp8uTJioiIuKBlOtukSZPUtWtXderUSePGjVNgYKBeeuklbdmyRW+//bb1XwOSpNGjR+v1119Xz5499eSTTyo2NlZvvfVWkd9catasqccee0yPPvqofvWrX+n222/X/v37lZ6erqCgIOerSiTpL3/5i3r37q02bdrowQcfVL169bRr1y4tXbrUOcjfeuutmjBhgm677Tb9/ve/18mTJ/XnP//5gj5wz6VGjRqaNm2ahgwZogMHDmjgwIGKiYnRjz/+qH/961/68ccfNX36dOvpNm3aVKtWrdJ7772nuLg4hYWFWe38TzzxhDIzM9WuXTv99re/VZMmTXTy5Ent2LFDixcv1ssvv2x1G0C1atWUnp6uESNGaODAgRo2bJgOHTqk9PR0xcXF+ZwJK4t9b8KECdqzZ49SUlJUt25dHTp0SC+88ILcbneFf2l906ZNJUkvvPCChgwZIrfbrSZNmlj9Nl+W9Rg4cKBCQkI0cOBAnThxQm+//bbVLynVqlXT5MmTdccdd6hXr14aMWKEcnNz9eyzz+rQoUN6+umnfdqnpKTopZde0k8//eTzxw9SUlI0Y8YMRUZGnvcrfG677Ta99dZbuummm/S73/1OrVq1ktvt1p49e7Ry5Ur17dtXN998s6688krdeeedmjp1qtxut7p06aItW7boueeeU3h4uM80x48fr/fee08pKSkaP368goOD9fLLLzv3BhZuk/Xr19cTTzyh8ePH67vvvlP37t0VGRmpffv26dNPP3XOsJzPxo0bdc899+iWW27R7t27NX78eNWpU0f333+/JOmKK65Qw4YN9fDDD8sYo6ioKL333nvOvaKFDh8+rE6dOmnw4MG64oorFBYWpg0bNmjJkiXq37+/pIs/rtStW1cNGjTQ+vXr9dvf/va8y3YxnnjiCX3wwQe68cYb9eijj6pp06Y6dOiQlixZojFjxuiKK67Qgw8+qNmzZ6tnz5564oknlJiYqEWLFumll17Sfffd55yc8Hq96tKliyZNmqTIyEglJibqww8/1Pz58y+4f7bHo9L21VZJx/QL+Xx3u916++23dc8992jgwIGaPXu2br/99lLvZzZat26tXr16qVmzZoqMjNRXX32lN954o8gvmvv379e2bds0atQouxVj88RN4RNthT+BgYEmJibGdOjQwUycONFkZ2cXec/ZT86uW7fO3HzzzSYxMdF4PB5Tq1Yt06FDB7Nw4UKf9y1fvtxce+21xuPx+DzBVzi9M5/eK2lexvzfk1b/+Mc/zNVXX20CAwNN/fr1zZQpU4q8/5tvvjGpqakmPDzc1K5d24waNcosWrSoyJNlBw4cMAMHDjQ1a9Y0LpfLZ54q5omxzZs3m969e5uIiAgTGBhomjdv7vNEmjFFH/MvVNwTbCX5+OOPTefOnU1oaKgJDg42bdq0Me+9916x0yvNU9jGGPPvf//bdO3a1QQFBZmoqCgzfPhw8+677xb7tN2rr75qmjVrZgIDA01ERITp27dvsU+orlu3zvTo0cNEREQYj8djGjZsWOTJzcWLF5trrrnGBAcHmwYNGpgXX3yxxKewH3jggVItY0nrePXq1aZnz54mKirKuN1uU6dOHdOzZ0+fdiVtd8U9vf/FF1+Y9u3bm5CQECPJ56nJ4hS3zfz444/mt7/9rUlKSjJut9tERUWZFi1amPHjxztPnJ+rlsVN85VXXjG/+MUvTGBgoGncuLF5/fXXTd++fc21117r08523zt7Hbz//vumR48epk6dOs4x4qabbvL5ipmSlPQU9sXsF4888oiJj4831apV89luS3oK8+wnXY0pXT3OtUxnz2flypWmRo0apnv37iYnJ8e6lhkZGaZ169YmKCjIhIaGmpSUFPO///u/Rd578OBBU61aNRMaGurzVTSFT0b379+/VMufl5dnnnvuOdO8eXMTFBRkatSoYa644gozYsQIs23bNqddbm6uGTt2rImJiTFBQUGmTZs2Zt26dUXqaszPx6vWrVsbj8djvF6v+f3vf2+eeeaZYp/gz8jIMJ06dTLh4eHG4/GYxMREM3DgwPN+JU7htrls2TJz1113mZo1azrfGHFmv435v2NdWFiYiYyMNLfccovZtWuXz/o/efKkuffee02zZs1MeHi4CQ4ONk2aNDGPP/64840ehUpzXCnJY489ZiIjI4t8tUxJT2GXdrspzu7du82wYcOM1+s1brfbxMfHm0GDBpl9+/Y5bXbu3GkGDx5satWqZdxut2nSpIl59tlnfb4JwJifv/Jq4MCBJioqykRERJg777zTbNy4sdinsENDQ4v0pbhjfEnHo5KUtq82T2Gf65h+oZ/vBQUF5re//a2pVq2a+dvf/maMKf1+Vtpj18MPP2xatmxpIiMjjcfjMQ0aNDAPPvig+emnn3ze99prrxm3222ysrJKtT4KuYw5z2PTAC5Jhw4dUuPGjdWvXz+98sor/u4OoNTUVO3YsUPffPONv7viVz/88IOSkpI0e/Zs3Xrrrf7uDi5xN9xwg+rVq1fkVo/zKdOHaABUTllZWXrqqafUqVMn1apVSzt37tTzzz+vo0eP6ne/+52/u4fL0JgxY3TttdcqISFBBw4c0FtvvaXMzEy99tpr/u6a38XHx2v06NF66qmndMstt1zQA1dAaXz00UfasGFDxf0tbABVi8fj0Y4dO3T//ffrwIEDzg3eL7/8cpE/bQdUhPz8fE2YMEFZWVlyuVy66qqr9MYbb+jOO+/0d9cqhf/5n/9RSEiIvv/++yLfMwiUlf3792v27Nlq0KCB9Xu5hA0AAAArnBcHAACAFQIkAAAArBAgAQAAYIWHaC5CQUGBfvjhB4WFhV3QF3UDAICKZ4zR0aNHFR8fz1PuF4gAeRF++OEHno4DAKCK2r17t9Vf9sL/IUBehMI/h7Z79+4if6oLUl5enpYtW6bU1FS53W5/d+eyRi0qF+pReVCLyqWi6nHkyBElJCRY/VlT+CJAXoTCy9bh4eEEyGLk5eUpJCRE4eHhHJj9jFpULtSj8qAWlUtF14Pbzy4cF/4BAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALAS4O8OAABQ1dR/eJG/u3BBdjzd099dwCWCM5AAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFipkgFy0qRJuu666xQWFqaYmBj169dPX3/9tU+boUOHyuVy+fy0adPGp01ubq5GjRql6OhohYaGqk+fPtqzZ09FLgoAAECVUyUD5OrVq/XAAw9o/fr1yszM1OnTp5Wamqrjx4/7tOvevbv27t3r/CxevNhn/OjRo7VgwQLNnTtXa9as0bFjx9SrVy/l5+dX5OIAAABUKQH+7sCFWLJkic/rGTNmKCYmRps2bdKNN97oDPd4PPJ6vcVO4/Dhw3rttdf0xhtvqEuXLpKkN998UwkJCVq+fLm6detW5D25ubnKzc11Xh85ckSSlJeXp7y8vIterktN4Tph3fgftahcqEflcaG18FQ35dGdclfZt7mK2jcq+3qoClzGmKq5F5zh22+/VaNGjbR582YlJydL+vkSdkZGhgIDA1WzZk116NBBTz31lGJiYiRJK1asUEpKig4cOKDIyEhnWs2bN1e/fv2Unp5eZD5paWnFDp8zZ45CQkLKaekAAEBZysnJ0eDBg3X48GGFh4f7uztVUpUPkMYY9e3bVwcPHtTHH3/sDJ83b55q1KihxMREbd++XY899phOnz6tTZs2yePxaM6cObr77rt9zihKUmpqqpKSkvTXv/61yLyKOwOZkJCgn376iQ2wGHl5ecrMzFTXrl3ldrv93Z3LGrWoXKhH5XGhtUhOW1qOvSo/W9KKXl2rTCpq3zhy5Iiio6MJkBehSl7CPtPIkSP15Zdfas2aNT7Db731Vuf/ycnJatmypRITE7Vo0SL179+/xOkZY+RyuYod5/F45PF4igx3u918CJwD66fyoBaVC/WoPGxrkZtf/OdEZVdVtrfy3jeqynqozKrkQzSFRo0apYULF2rlypWqW7fuOdvGxcUpMTFR27ZtkyR5vV6dOnVKBw8e9GmXnZ2t2NjYcuszAABAVVclA6QxRiNHjtT8+fO1YsUKJSUlnfc9+/fv1+7duxUXFydJatGihdxutzIzM502e/fu1ZYtW9SuXbty6zsAAEBVVyUvYT/wwAOaM2eO3n33XYWFhSkrK0uSFBERoeDgYB07dkxpaWkaMGCA4uLitGPHDj366KOKjo7WzTff7LQdPny4xo4dq1q1aikqKkrjxo1T06ZNnaeyAQAAUFSVDJDTp0+XJHXs2NFn+IwZMzR06FBVr15dmzdv1uzZs3Xo0CHFxcWpU6dOmjdvnsLCwpz2zz//vAICAjRo0CCdOHFCKSkpmjlzpqpXr16RiwMAAFClVMkAeb4Hx4ODg7V06fmfkAsKCtK0adM0bdq0suoaAADAJa9K3gMJAAAA/yFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsVMkAOWnSJF133XUKCwtTTEyM+vXrp6+//tqnjTFGaWlpio+PV3BwsDp27KitW7f6tMnNzdWoUaMUHR2t0NBQ9enTR3v27KnIRQEAAKhyqmSAXL16tR544AGtX79emZmZOn36tFJTU3X8+HGnzeTJkzVlyhS9+OKL2rBhg7xer7p27aqjR486bUaPHq0FCxZo7ty5WrNmjY4dO6ZevXopPz/fH4sFAABQJQT4uwMXYsmSJT6vZ8yYoZiYGG3atEk33nijjDGaOnWqxo8fr/79+0uSZs2apdjYWM2ZM0cjRozQ4cOH9dprr+mNN95Qly5dJElvvvmmEhIStHz5cnXr1q3ClwsAAKAqqJIB8myHDx+WJEVFRUmStm/frqysLKWmpjptPB6POnTooLVr12rEiBHatGmT8vLyfNrEx8crOTlZa9euLTZA5ubmKjc313l95MgRSVJeXp7y8vLKZdmqssJ1wrrxP2pRuVCPyuNCa+GpbsqjO+Wusm9zFbVvVPb1UBVU+QBpjNGYMWN0/fXXKzk5WZKUlZUlSYqNjfVpGxsbq507dzptAgMDFRkZWaRN4fvPNmnSJKWnpxcZvmzZMoWEhFz0slyqMjMz/d0F/H/UonKhHpWHbS0mtyqnjpSzxYsX+7sLpVLe+0ZOTk65Tv9yUOUD5MiRI/Xll19qzZo1Rca5XC6f18aYIsPOdq42jzzyiMaMGeO8PnLkiBISEpSamqrw8PAL6P2lLS8vT5mZmeratavcbre/u3NZoxaVC/WoPC60FslpS8uxV+VnS1rlvj2rovaNwiuIuHBVOkCOGjVKCxcu1EcffaS6des6w71er6SfzzLGxcU5w7Ozs52zkl6vV6dOndLBgwd9zkJmZ2erXbt2xc7P4/HI4/EUGe52u/kQOAfWT+VBLSoX6lF52NYiN//cJyMqq6qyvZX3vlFV1kNlViWfwjbGaOTIkZo/f75WrFihpKQkn/FJSUnyer0+p8BPnTql1atXO+GwRYsWcrvdPm327t2rLVu2lBggAQAAUEXPQD7wwAOaM2eO3n33XYWFhTn3LEZERCg4OFgul0ujR4/WxIkT1ahRIzVq1EgTJ05USEiIBg8e7LQdPny4xo4dq1q1aikqKkrjxo1T06ZNnaeyAQAAUFSVDJDTp0+XJHXs2NFn+IwZMzR06FBJ0kMPPaQTJ07o/vvv18GDB9W6dWstW7ZMYWFhTvvnn39eAQEBGjRokE6cOKGUlBTNnDlT1atXr6hFAQAAqHKqZIA05vxfn+ByuZSWlqa0tLQS2wQFBWnatGmaNm1aGfYOAADg0lYl74EEAACA/xAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWCJAAAACwQoAEAACAFQIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQAIAAMAKARIAAABWqmSA/Oijj9S7d2/Fx8fL5XIpIyPDZ/zQoUPlcrl8ftq0aePTJjc3V6NGjVJ0dLRCQ0PVp08f7dmzpwKXAgAAoGoK8HcHLsTx48fVvHlz3X333RowYECxbbp3764ZM2Y4rwMDA33Gjx49Wu+9957mzp2rWrVqaezYserVq5c2bdqk6tWrl2v/AQD/p/7Di/w2b091o8mtpOS0pcrNd/mtH0BVUyUDZI8ePdSjR49ztvF4PPJ6vcWOO3z4sF577TW98cYb6tKliyTpzTffVEJCgpYvX65u3bqVeZ8BAAAuFVUyQJbGqlWrFBMTo5o1a6pDhw566qmnFBMTI0natGmT8vLylJqa6rSPj49XcnKy1q5dW2KAzM3NVW5urvP6yJEjkqS8vDzl5eWV49JUTYXrhHXjf9SicqEevjzVjf/mXc34/Hupq+zbXEXtG5V9PVQFl2SA7NGjh2655RYlJiZq+/bteuyxx9S5c2dt2rRJHo9HWVlZCgwMVGRkpM/7YmNjlZWVVeJ0J02apPT09CLDly1bppCQkDJfjktFZmamv7uA/49aVC7U42eTW/m7B9IfWxb4uwsVYvHixf7uQqmU976Rk5NTrtO/HFySAfLWW291/p+cnKyWLVsqMTFRixYtUv/+/Ut8nzFGLlfJ98A88sgjGjNmjPP6yJEjSkhIUGpqqsLDw8um85eQvLw8ZWZmqmvXrnK73f7uzmWNWlQu1MNXctpSv83bU83ojy0L9NjGasotuPTvgdySVrlv0aqofaPwCiIu3CUZIM8WFxenxMREbdu2TZLk9Xp16tQpHTx40OcsZHZ2ttq1a1fidDwejzweT5HhbrebD4FzYP1UHtSicqEeP6sMD6/kFrgqRT/KW1XZ3sp736gq66Eyq5Jf42Nr//792r17t+Li4iRJLVq0kNvt9jlFvnfvXm3ZsuWcARIAAABV9AzksWPH9O233zqvt2/fri+++EJRUVGKiopSWlqaBgwYoLi4OO3YsUOPPvqooqOjdfPNN0uSIiIiNHz4cI0dO1a1atVSVFSUxo0bp6ZNmzpPZQMAAKB4VTJAbty4UZ06dXJeF96XOGTIEE2fPl2bN2/W7NmzdejQIcXFxalTp06aN2+ewsLCnPc8//zzCggI0KBBg3TixAmlpKRo5syZfAckAADAeVTJANmxY0cZU/JXLixdev4bsoOCgjRt2jRNmzatLLsGAABwybss7oEEAABA2SFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsVMkA+dFHH6l3796Kj4+Xy+VSRkaGz3hjjNLS0hQfH6/g4GB17NhRW7du9WmTm5urUaNGKTo6WqGhoerTp4/27NlTgUsBAABQNVXJAHn8+HE1b95cL774YrHjJ0+erClTpujFF1/Uhg0b5PV61bVrVx09etRpM3r0aC1YsEBz587VmjVrdOzYMfXq1Uv5+fkVtRgAAABVUoC/O3AhevTooR49ehQ7zhijqVOnavz48erfv78kadasWYqNjdWcOXM0YsQIHT58WK+99preeOMNdenSRZL05ptvKiEhQcuXL1e3bt0qbFkAAACqmioZIM9l+/btysrKUmpqqjPM4/GoQ4cOWrt2rUaMGKFNmzYpLy/Pp018fLySk5O1du3aEgNkbm6ucnNznddHjhyRJOXl5SkvL6+clqjqKlwnrBv/oxaVC/Xw5alu/Dfvasbn30tdZd/mKmrfqOzroSq45AJkVlaWJCk2NtZneGxsrHbu3Om0CQwMVGRkZJE2he8vzqRJk5Senl5k+LJlyxQSEnKxXb9kZWZm+rsL+P+oReVCPX42uZW/eyD9sWWBv7tQIRYvXuzvLpRKee8bOTk55Tr9y8ElFyALuVwun9fGmCLDzna+No888ojGjBnjvD5y5IgSEhKUmpqq8PDwi+vwJSgvL0+ZmZnq2rWr3G63v7tzWaMWlQv18JWcttRv8/ZUM/pjywI9trGacgvO/RlxKdiSVrlv0aqofaPwCiIu3CUXIL1er6SfzzLGxcU5w7Ozs52zkl6vV6dOndLBgwd9zkJmZ2erXbt2JU7b4/HI4/EUGe52u/kQOAfWT+VBLSoX6vGz3Hz/B7fcAlel6Ed5qyrbW3nvG1VlPVRmVfIp7HNJSkqS1+v1Of196tQprV692gmHLVq0kNvt9mmzd+9ebdmy5ZwBEgAAAFX0DOSxY8f07bffOq+3b9+uL774QlFRUapXr55Gjx6tiRMnqlGjRmrUqJEmTpyokJAQDR48WJIUERGh4cOHa+zYsapVq5aioqI0btw4NW3a1HkqGwAAAMWrkgFy48aN6tSpk/O68L7EIUOGaObMmXrooYd04sQJ3X///Tp48KBat26tZcuWKSwszHnP888/r4CAAA0aNEgnTpxQSkqKZs6cqerVq1f48gAAAFQlVTJAduzYUcaU/JULLpdLaWlpSktLK7FNUFCQpk2bpmnTppVDDwEAAC5dl9w9kAAAAChfBEgAAABYIUACAADACgESAAAAVgiQAAAAsEKABAAAgBUCJAAAAKwQIAEAAGCFAAkAAAArBEgAAABYIUACAADACgESAAAAVgiQAAAAsEKABAAAgBUCJAAAAKwQIAEAAGAlwN8dAACUnfoPL/J3FwBcBjgDCQAAACsESAAAAFjhEjYAAJeJyn6Lg6e60eRWUnLaUuXmuyRJO57u6edeoTicgQQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsBPi7A+UlLS1N6enpPsNiY2OVlZUlSTLGKD09Xa+88ooOHjyo1q1b6y9/+Yuuvvpqf3QXQCVU/+FF5TJdT3Wjya2k5LSlys13lcs8AKA8XdJnIK+++mrt3bvX+dm8ebMzbvLkyZoyZYpefPFFbdiwQV6vV127dtXRo0f92GMAAIDK75IOkAEBAfJ6vc5P7dq1Jf189nHq1KkaP368+vfvr+TkZM2aNUs5OTmaM2eOn3sNAABQuV2yl7Aladu2bYqPj5fH41Hr1q01ceJENWjQQNu3b1dWVpZSU1Odth6PRx06dNDatWs1YsSIYqeXm5ur3Nxc5/WRI0ckSXl5ecrLyyvfhamCCtcJ68b/qMWF8VQ35TPdasbnX/gPtahciqtHeRy3OBZePJcx5pLcaz744APl5OSocePG2rdvn5588kn95z//0datW/X111+rffv2+v777xUfH++85ze/+Y127typpUuXFjvN4u6rlKQ5c+YoJCSk3JYFAACUnZycHA0ePFiHDx9WeHi4v7tTJV2yAfJsx48fV8OGDfXQQw+pTZs2at++vX744QfFxcU5bX79619r9+7dWrJkSbHTKO4MZEJCgn766Sc2wGLk5eUpMzNTXbt2ldvt9nd3LmvU4sIkpxX/y+TF8lQz+mPLAj22sZpyC3iIxp+oReVSXD22pHUr8/kcOXJE0dHRBMiLcElfwj5TaGiomjZtqm3btqlfv36SpKysLJ8AmZ2drdjY2BKn4fF45PF4igx3u918KJ8D66fyoBZ2yvsJ6dwCF09hVxLUonI5sx7lccziOHjxLumHaM6Um5urr776SnFxcUpKSpLX61VmZqYz/tSpU1q9erXatWvnx14CAABUfpfsGchx48apd+/eqlevnrKzs/Xkk0/qyJEjGjJkiFwul0aPHq2JEyeqUaNGatSokSZOnKiQkBANHjzY310HAACo1C7ZALlnzx7dfvvt+umnn1S7dm21adNG69evV2JioiTpoYce0okTJ3T//fc7XyS+bNkyhYWF+bnnAAAAldslGyDnzp17zvEul0tpaWlKS0urmA4BAABcIi6beyABAABQNgiQAAAAsEKABAAAgBUCJAAAAKwQIAEAAGCFAAkAAAArBEgAAABYIUACAADACgESAAAAVgiQAAAAsEKABAAAgJVL9m9hA6hc6j+8yN9dAACUEc5AAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwH+7gAAe/UfXmTV3lPdaHIrKTltqXLzXeXUKwDA5YIzkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAICVyz5AvvTSS0pKSlJQUJBatGihjz/+2N9dAgAAqNQu6wA5b948jR49WuPHj9fnn3+uG264QT169NCuXbv83TUAAIBKK8DfHfCnKVOmaPjw4brnnnskSVOnTtXSpUs1ffp0TZo0yc+9Q0Wp//Aif3cBAIAq5bINkKdOndKmTZv08MMP+wxPTU3V2rVri31Pbm6ucnNzndeHDx+WJB04cEB5eXll3sfWkz4s82lWJE81o/+5tkDXjJ+v3AKXv7tTosthJwgoMMrJKVBAXjXlV+JaXC6oR+VBLSqX4uqxf//+Mp/P0aNHJUnGmDKf9uXicvjsLNZPP/2k/Px8xcbG+gyPjY1VVlZWse+ZNGmS0tPTiwxPSkoqlz5eCgb7uwNwUIvKhXpUHtSicjm7HtF/Kr95HT16VBEREeU3g0vYZRsgC7lcvr9xGmOKDCv0yCOPaMyYMc7rgoICHThwQLVq1SrxPZezI0eOKCEhQbt371Z4eLi/u3NZoxaVC/WoPKhF5VJR9TDG6OjRo4qPjy+3eVzqLtsAGR0drerVqxc525idnV3krGQhj8cjj8fjM6xmzZrl1cVLRnh4OAfmSoJaVC7Uo/KgFpVLRdSDM48X57J9CjswMFAtWrRQZmamz/DMzEy1a9fOT70CAACo/C7bM5CSNGbMGN11111q2bKl2rZtq1deeUW7du3Svffe6++uAQAAVFqXdYC89dZbtX//fj3xxBPau3evkpOTtXjxYiUmJvq7a5cEj8ejxx9/vMhlf1Q8alG5UI/Kg1pULtSj6nAZnmEHAACAhcv2HkgAAABcGAIkAAAArBAgAQAAYIUACQAAACsESAAAAFghQMLKRx99pN69eys+Pl4ul0sZGRk+440xSktLU3x8vIKDg9WxY0dt3brVp01ubq5GjRql6OhohYaGqk+fPtqzZ08FLsWlYdKkSbruuusUFhammJgY9evXT19//bVPG+pRMaZPn65mzZo5fz2jbdu2+uCDD5zx1MF/Jk2aJJfLpdGjRzvDqEfFSUtLk8vl8vnxer3OeGpRdREgYeX48eNq3ry5XnzxxWLHT548WVOmTNGLL76oDRs2yOv1qmvXrjp69KjTZvTo0VqwYIHmzp2rNWvW6NixY+rVq5fy8/MrajEuCatXr9YDDzyg9evXKzMzU6dPn1ZqaqqOHz/utKEeFaNu3bp6+umntXHjRm3cuFGdO3dW3759nQ9C6uAfGzZs0CuvvKJmzZr5DKceFevqq6/W3r17nZ/Nmzc746hFFWaACyTJLFiwwHldUFBgvF6vefrpp51hJ0+eNBEREebll182xhhz6NAh43a7zdy5c50233//valWrZpZsmRJhfX9UpSdnW0kmdWrVxtjqIe/RUZGmldffZU6+MnRo0dNo0aNTGZmpunQoYP53e9+Z4xhv6hojz/+uGnevHmx46hF1cYZSJSZ7du3KysrS6mpqc4wj8ejDh06aO3atZKkTZs2KS8vz6dNfHy8kpOTnTa4MIcPH5YkRUVFSaIe/pKfn6+5c+fq+PHjatu2LXXwkwceeEA9e/ZUly5dfIZTj4q3bds2xcfHKykpSbfddpu+++47SdSiqrus/5QhylZWVpYkKTY21md4bGysdu7c6bQJDAxUZGRkkTaF74c9Y4zGjBmj66+/XsnJyZKoR0XbvHmz2rZtq5MnT6pGjRpasGCBrrrqKudDjjpUnLlz5+qzzz7Thg0bioxjv6hYrVu31uzZs9W4cWPt27dPTz75pNq1a6etW7dSiyqOAIky53K5fF4bY4oMO1tp2qBkI0eO1Jdffqk1a9YUGUc9KkaTJk30xRdf6NChQ/rnP/+pIUOGaPXq1c546lAxdu/erd/97ndatmyZgoKCSmxHPSpGjx49nP83bdpUbdu2VcOGDTVr1iy1adNGErWoqriEjTJT+GTd2b8VZmdnO79her1enTp1SgcPHiyxDeyMGjVKCxcu1MqVK1W3bl1nOPWoWIGBgfrFL36hli1batKkSWrevLleeOEF6lDBNm3apOzsbLVo0UIBAQEKCAjQ6tWr9ec//1kBAQHO+qQe/hEaGqqmTZtq27Zt7BtVHAESZSYpKUler1eZmZnOsFOnTmn16tVq166dJKlFixZyu90+bfbu3astW7Y4bVA6xhiNHDlS8+fP14oVK5SUlOQznnr4lzFGubm51KGCpaSkaPPmzfriiy+cn5YtW+qOO+7QF198oQYNGlAPP8rNzdVXX32luLg49o2qzi+P7qDKOnr0qPn888/N559/biSZKVOmmM8//9zs3LnTGGPM008/bSIiIsz8+fPN5s2bze23327i4uLMkSNHnGnce++9pm7dumb58uXms88+M507dzbNmzc3p0+f9tdiVUn33XefiYiIMKtWrTJ79+51fnJycpw21KNiPPLII+ajjz4y27dvN19++aV59NFHTbVq1cyyZcuMMdTB3858CtsY6lGRxo4da1atWmW+++47s379etOrVy8TFhZmduzYYYyhFlUZARJWVq5caSQV+RkyZIgx5uevZXj88ceN1+s1Ho/H3HjjjWbz5s0+0zhx4oQZOXKkiYqKMsHBwaZXr15m165dfliaqq24OkgyM2bMcNpQj4oxbNgwk5iYaAIDA03t2rVNSkqKEx6NoQ7+dnaApB4V59ZbbzVxcXHG7Xab+Ph4079/f7N161ZnPLWoulzGGOOfc58AAACoirgHEgAAAFYIkAAAALBCgAQAAIAVAiQAAACsECABAABghQAJAAAAKwRIAAAAWCFAAgAAwAoBEgAAAFYIkAAAALBCgAQAAICV/wc38uKUXFGPxgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split (chunk) docs with chunk size <512\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in knowledge_base:\n",
    "        docs_processed += text_splitter.split_documents([doc])\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n",
    "docs_processed = split_documents(\n",
    "    512,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")\n",
    "\n",
    "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
    "fig = pd.Series(lengths).hist()\n",
    "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf054172bad34aa19e346ed5a7bccc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e62a86c966241df9d552729c26a293d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44682f3674e54d1caeaac1b9ab590309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ae535283f748ab983a2871228ba786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2270ed6b7c4dc1a7c220e601f24c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664860b7bd1c4b04aee275bdacc5ec1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f818968b9c974a35bc8ced35a2909fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create embeddings for docs \n",
    "## Takes a while to run loacally (~6 min w/ PythonDS, Week7, Week9)\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    # model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "#edit distance strategy for use case\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a user query in the same space\n",
    "user_query = \"What is a decision tree?\"\n",
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pacmap\\pacmap.py:822: UserWarning: Warning: random state is set to 1\n",
      "  warnings.warn(f'Warning: random state is set to {_RANDOM_STATE}')\n"
     ]
    }
   ],
   "source": [
    "# create pca projection of embeddings for visualization\n",
    "\n",
    "embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "\n",
    "embeddings_2d = [\n",
    "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0]) for idx in range(len(docs_processed))\n",
    "] + [query_vector]\n",
    "\n",
    "# Fit the data (the index of transformed data corresponds to the index of the original data)\n",
    "documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Archives | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nArchives and ..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "data\n\nscience\n\nvenn\n\ndiagram). Used by permission.)\n\nWhile some of the intersection labels are a bit..."
          ],
          [
           "Who Is This Book For?¶In my teaching both at the University of Washington and at various tech-focuse..."
          ],
          [
           "Python 2 vs Python 3¶This book uses the syntax of Python 3, which contains language enhancements tha..."
          ],
          [
           "Using Code Examples¶Supplemental material (code examples, figures, etc.) is available for download a..."
          ],
          [
           "Anaconda includes both Python and conda, and additionally bundles a suite of other pre-installed pac..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "IPython: Beyond Normal Python\n\n< Preface | Contents | Help and Documentation in IPython >\n\nThere are..."
          ],
          [
           "Shell or Notebook?¶There are two primary means of using IPython that we'll discuss in this chapter: ..."
          ],
          [
           "Launching the Jupyter Notebook¶The Jupyter notebook is a browser-based graphical interface to the IP..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "Here we'll discuss IPython's tools to quickly access this information, namely the ? character to exp..."
          ],
          [
           "Importantly, this will even work for functions or other objects you create yourself! Here we'll defi..."
          ],
          [
           "Return the number of items of a sequence or mapping.\n\nUsing ? and/or ? ? gives a powerful and quick ..."
          ],
          [
           "For brevity, we've only shown the first couple lines of the output. Most of these are Python's speci..."
          ],
          [
           "I find this type of flexible wildcard search can be very useful for finding a particular command whe..."
          ],
          [
           "Keyboard Shortcuts in the IPython Shell\n\n< Help and Documentation in IPython | Contents | IPython Ma..."
          ],
          [
           "Ctrl-b or the left arrow key Move cursor back one character\n\nCtrl-f or the right arrow key Move curs..."
          ],
          [
           "Ctrl-n (or the down arrow key) Access next command in history\n\nCtrl\n\nr\n\nReverse\n\nsearch through comm..."
          ],
          [
           "Keystroke\n\nAction\n\nCtrl\n\nl\n\nClear terminal screen\n\nCtrl\n\nc\n\nInterrupt current Python command\n\nCtrl\n\n..."
          ],
          [
           "Pasting Code Blocks: %paste and %cpaste¶When working in the IPython interpreter, one common gotcha i..."
          ],
          [
           "These magic commands, like others we'll see, make available functionality that would be difficult or..."
          ],
          [
           "The benefit of %timeit is that for short commands it will automatically perform multiple runs in ord..."
          ],
          [
           "Input and Output History\n\n< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nPrevio..."
          ],
          [
           "Out[5]: {2: 0.9092974268256817, 3:\n\n0.4161468365471424}\n\nThe In object is a list, which keeps track ..."
          ],
          [
           "In [11]: print(___)\n\n0.9092974268256817\n\nIPython stops there: more than three underscores starts to ..."
          ],
          [
           "< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nIPython and Shell Commands | Pyt..."
          ],
          [
           "Quick Introduction to the Shell¶A full intro to using the shell/terminal/command-line is well beyond..."
          ],
          [
           "osx:projects $ pwd\n\n/home/jake/projects\n\nosx:projects $ ls datasci_book   mpld3   myproject.txt\n\nosx..."
          ],
          [
           "['myproject.txt']\n\nIn [6]: directory = !pwd\n\nIn [7]: print(directory)\n\n['/Users/jakevdp/notebooks/tm..."
          ],
          [
           "In fact, by default you can even use this without the % sign: In [15]: cd myproject /home/jake/proje..."
          ],
          [
           "Controlling Exceptions: %xmode¶Most of the time when a Python script fails, it will raise an Excepti..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nCalling func2 results in an error, and reading the printed trac..."
          ],
          [
           "In [5]:\n\n%xmode Verbose\n\nException reporting mode: Verbose\n\nIn [6]:\n\nfunc2(1)\n\n---------------------..."
          ],
          [
           "Debugging: When Reading Tracebacks Is Not Enough¶The standard Python tool for interactive debugging ..."
          ],
          [
           "ipdb> print(x)\n\n1\n\nipdb> up\n\n> <ipython\n\ninput\n\n6\n\nb2e110f6fc8f>(1)<module>()\n\n---\n\n> 1 func2(1)\n\nip..."
          ],
          [
           "ipdb> print(b)\n\n0\n\nipdb> quit\n\nFinally, if you have a script that you'd like to run from the beginni..."
          ],
          [
           "Profiling and Timing Code\n\n< Errors and Debugging | Contents | More IPython Resources >\n\nIn the proc..."
          ],
          [
           "In [2]:\n\n%%timeit\n\ntotal = 0\n\nfor i in range(1000):\n\nfor j in range(1000):\n\ntotal += i\n\n(\n\n1) *\n\nj\n\n..."
          ],
          [
           "sorting an already sorted list: CPU times: user 8.18 ms, sys: 10 µs, total: 8.19 ms Wall time: 8.24 ..."
          ],
          [
           "Now we can call %prun with a function call to see the profiled results:\n\nIn [8]:\n\n%prun sum_of_lists..."
          ],
          [
           "In [9]:\n\n%load_ext line_profiler\n\nNow the %lprun command will do a line-by-line profiling of any fun..."
          ],
          [
           "Profiling Memory Use: %memit and %mprun¶Another aspect of profiling is the amount of memory an opera..."
          ],
          [
           "In [15]:\n\nfrom mprun_demo import sum_of_lists\n\n%mprun\n\nf sum_of_lists sum_of_lists(1000000)\n\nThe res..."
          ],
          [
           "< Errors and Debugging | Contents | More IPython Resources >\n\nMore IPython Resources | Python Data S..."
          ],
          [
           "Books¶ Python for Data Analysis: Wes McKinney's book includes a chapter that covers using IPython as..."
          ],
          [
           "Introduction to NumPy\n\n< More IPython Resources | Contents | Understanding Data Types in Python >\n\nT..."
          ],
          [
           "In [1]:\n\nimport numpy\n\nnumpy.__version__\n\nOut[1]:\n\n'1.11.1'\n\nFor the pieces of the package discussed..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "This sort of flexibility is one piece that makes Python and other dynamically-typed languages conven..."
          ],
          [
           "This means that there is some overhead in storing an integer in Python as compared to an integer in ..."
          ],
          [
           "In [5]:\n\nL3 = [True, \"2\", 3.0, 4] [type(item) for item in L3]\n\nOut[5]:\n\n[bool, str, float, int]\n\nBut..."
          ],
          [
           "A\n\nOut[6]:\n\narray('i', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nHere 'i' is a type code indicating the conte..."
          ],
          [
           "Finally, unlike Python lists, NumPy arrays can explicitly be multi-dimensional; here's one way of in..."
          ],
          [
           "In [15]:\n\n# Create an array filled with a linear sequence # Starting at 0, ending at 20, stepping by..."
          ],
          [
           "# Create a 3x3 array of random integers in the interval [0, 10) np.random.randint(0, 10, (3, 3))\n\nOu..."
          ],
          [
           "int8\n\nByte (\n\n128 to 127)\n\nint16\n\nInteger (\n\n32768 to 32767)\n\nint32\n\nInteger (\n\n2147483648 to 214748..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "Each array has attributes ndim (the number of dimensions), shape (the size of each dimension), and s..."
          ],
          [
           "In [6]:\n\nx1[0]\n\nOut[6]:\n\n5\n\nIn [7]:\n\nx1[4]\n\nOut[7]:\n\n7\n\nTo index from the end of the array, you can ..."
          ],
          [
           "In [15]:\n\nx1[0] = 3.14159  # this will be truncated! x1\n\nOut[15]:\n\narray([3, 0, 3, 3, 7, 9])\n\nArray ..."
          ],
          [
           "In [21]:\n\nx[1::2]  # every other element, starting at index 1\n\nOut[21]:\n\narray([1, 3, 5, 7, 9])\n\nA p..."
          ],
          [
           "In [27]:\n\nx2[::\n\n1, ::\n\n1]\n\nOut[27]:\n\narray([[ 7,  7,  6,  1], [ 8,  8,  6,  7], [ 4,  2,  5, 12]])\n..."
          ],
          [
           "Now if we modify this subarray, we'll see that the original array is changed! Observe:\n\nIn [33]:\n\nx2..."
          ],
          [
           "In [38]:\n\ngrid = np.arange(1, 10).reshape((3, 3)) print(grid)\n\n[[1 2 3]\n\n[4 5 6]\n\n[7 8 9]]\n\nNote tha..."
          ],
          [
           "array([[1],\n\n[2],\n\n[3]])\n\nWe will see this type of transformation often throughout the remainder of ..."
          ],
          [
           "[4, 5, 6],\n\n[1, 2, 3],\n\n[4, 5, 6]])\n\nIn [47]:\n\n# concatenate along the second axis (zero-indexed) np..."
          ],
          [
           "[1 2 3] [99 99] [3 2 1]\n\nNotice that N split-points, leads to N + 1 subarrays. The related functions..."
          ],
          [
           "Computation on NumPy Arrays: Universal Functions\n\n< The Basics of NumPy Arrays | Contents | Aggregat..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nnp.random.seed(0)\n\ndef compute_reciprocals(values): output = np.empty(l..."
          ],
          [
           "Introducing UFuncs¶For many types of operations, NumPy provides a convenient interface into just thi..."
          ],
          [
           "2 *\n\nx\n\nOut[6]:\n\narray([[  1,   2,   4], [  8,  16,  32], [ 64, 128, 256]])\n\nComputations using vect..."
          ],
          [
           "x     =  [ 0\n\n1\n\n2\n\n3] x\n\n** 2 =  [0 1 4 9] x % 2  =  [0 1 0 1]\n\nIn addition, these can be strung to..."
          ],
          [
           "% np.mod Modulus/remainder (e.g., 9 % 4 = 1)\n\nAdditionally there are Boolean/bitwise operators; we w..."
          ],
          [
           "theta = np.linspace(0, np.pi, 3)\n\nNow we can compute some trigonometric functions on these values:\n\n..."
          ],
          [
           "Exponents and logarithms¶Another common type of operation available in a NumPy ufunc are the exponen..."
          ],
          [
           "exp(x) - 1 = [ 0. 0.0010005   0.01005017  0.10517092] log(1 + x) = [ 0. 0.0009995   0.00995033  0.09..."
          ],
          [
           "In [23]:\n\n# Error function (integral of Gaussian) # its complement, and its inverse x = np.array([0,..."
          ],
          [
           "In [25]:\n\ny = np.zeros(10)\n\nnp.power(2, x, out=y[::2])\n\nprint(y)\n\n[  1. 0. 2. 0. 4. 0. 8. 0. 16. 0.]..."
          ],
          [
           "In [29]:\n\nnp.multiply.accumulate(x)\n\nOut[29]:\n\narray([  1,   2,   6,  24, 120])\n\nNote that for these..."
          ],
          [
           "Aggregations: Min, Max, and Everything In Between | Python Data Science Handbook\n\nPython Data Scienc..."
          ],
          [
           "In [4]:\n\nbig_array = np.random.rand(1000000)\n\n%timeit sum(big_array)\n\n%timeit np.sum(big_array)\n\n10 ..."
          ],
          [
           "In [8]:\n\nprint(big_array.min(), big_array.max(), big_array.sum())\n\n1.17171281366e\n\n06 0.999997678497..."
          ],
          [
           "In [12]:\n\nM.max(axis=1)\n\nOut[12]:\n\narray([ 0.8967576 ,  0.99196818,  0.6687194 ])\n\nThe way the axis ..."
          ],
          [
           "np.argmax np.nanargmax Find index of maximum value\n\nnp.median\n\nnp.nanmedian\n\nCompute median of eleme..."
          ],
          [
           "Now that we have this data array, we can compute a variety of summary statistics:\n\nIn [15]:\n\nprint(\"..."
          ],
          [
           "< Computation on NumPy Arrays: Universal Functions | Contents | Computation on Arrays: Broadcasting ..."
          ],
          [
           "In [3]:\n\na + 5\n\nOut[3]:\n\narray([5, 6, 7])\n\nWe can think of this as an operation that stretches or du..."
          ],
          [
           "Out[7]:\n\narray([[0, 1, 2],\n\n[1, 2, 3],\n\n[2, 3, 4]])\n\nJust as before we stretched or broadcasted one ..."
          ],
          [
           "M.shape\n\n> (2, 3)\n\na.shape\n\n> (1, 3)\n\nBy rule 2, we now see that the first dimension disagrees, so w..."
          ],
          [
           "[1, 2, 3],\n\n[2, 3, 4]])\n\nBroadcasting example 3¶Now let's take a look at an example in which the two..."
          ],
          [
           "ValueError: operands could not be broadcast together with shapes (3,2) (3,)\n\nNote the potential conf..."
          ],
          [
           "Broadcasting in Practice¶\n\nBroadcasting operations form the core of many examples we'll see througho..."
          ],
          [
           "17,\n\n1.66533454e\n\n17])\n\nTo within machine precision, the mean is now zero.\n\nPlotting a two\n\ndimensio..."
          ],
          [
           "Comparisons, Masks, and Boolean Logic\n\n< Computation on Arrays: Broadcasting | Contents | Fancy Inde..."
          ],
          [
           "In [3]:\n\nplt.hist(inches, 40);\n\nThis histogram gives us a general idea of what the data looks like: ..."
          ],
          [
           "x < 3  # less than\n\nOut[5]:\n\narray([ True,  True, False, False, False], dtype=bool)\n\nIn [6]:\n\nx > 3 ..."
          ],
          [
           "Operator\n\nEquivalent ufunc\n\nOperator\n\nEquivalent ufunc\n\n==\n\nnp.equal\n\n!=\n\nnp.not_equal\n\n<\n\nnp.less\n\n..."
          ],
          [
           "In [15]:\n\n# how many values less than 6? np.count_nonzero(x < 6)\n\nOut[15]:\n\n8\n\nWe see that there are..."
          ],
          [
           "In [22]:\n\n# are all values in each row less than 8? np.all(x < 8, axis=1)\n\nOut[22]:\n\narray([ True, F..."
          ],
          [
           "In [24]:\n\nnp.sum(~( (inches <= 0.5) | (inches >= 1) ))\n\nOut[24]:\n\n29\n\nCombining comparison operators..."
          ],
          [
           "x\n\nOut[26]:\n\narray([[5, 0, 3, 3],\n\n[7, 9, 3, 5],\n\n[2, 4, 7, 6]])\n\nWe can obtain a Boolean array for ..."
          ],
          [
           "Median precip on rainy days in 2014 (inches):    0.194881889764 Median precip on summer days in 2014..."
          ],
          [
           "'0b111011'\n\nIn [35]:\n\nbin(42 & 59)\n\nOut[35]:\n\n'0b101010'\n\nIn [36]:\n\nbin(42 | 59)\n\nOut[36]:\n\n'0b11101..."
          ],
          [
           "Similarly, when doing a Boolean expression on a given array, you should use | or & rather than or or..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "When using fancy indexing, the shape of the result reflects the shape of the index arrays rather tha..."
          ],
          [
           "Here, each row value is matched with each column vector, exactly as we saw in broadcasting of arithm..."
          ],
          [
           "[ 4,  6],\n\n[ 8, 10]])\n\nAll of these indexing options combined lead to a very flexible set of operati..."
          ],
          [
           "(20, 2)\n\nNow to see which points were selected, let's over-plot large circles at the locations of th..."
          ],
          [
           "In [21]:\n\ni = [2, 3, 3, 4, 4, 4] x[i] += 1 x\n\nOut[21]:\n\narray([ 6.,  0.,  1.,  1.,  1.,  0.,  0.,  0..."
          ],
          [
           "In [23]:\n\nnp.random.seed(42)\n\nx = np.random.randn(100)\n\n# compute a histogram by hand bins = np.lins..."
          ],
          [
           "NumPy routine: 10000 loops, best of 3: 97.6 µs per loop Custom routine: 10000 loops, best of 3: 19.5..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "Out[2]:\n\narray([1, 2, 3, 4, 5])\n\nAs any first-year computer science major will tell you, the selecti..."
          ],
          [
           "Fast Sorting in NumPy: np.sort and np.argsort¶Although Python has built-in sort and sorted functions..."
          ],
          [
           "A useful feature of NumPy's sorting algorithms is the ability to sort along specific rows or columns..."
          ],
          [
           "In [12]:\n\nx = np.array([7, 2, 3, 1, 6, 5, 4]) np.partition(x, 3)\n\nOut[12]:\n\narray([2, 1, 3, 4, 6, 5,..."
          ],
          [
           "Now we'll compute the distance between each pair of points. Recall that the squared-distance between..."
          ],
          [
           "Out[20]:\n\narray([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n\nIt checks out! With the pairwis..."
          ],
          [
           "plt.scatter(X[:, 0], X[:, 1], s=100)\n\n# draw lines from each point to its two nearest neighbors K = ..."
          ],
          [
           "Aside: Big-O Notation¶Big-O notation is a means of describing how the number of operations required ..."
          ],
          [
           "When trying to analyze billions or trillions of samples, the difference between $\\mathcal{O}[N]$ and..."
          ],
          [
           "Structured Data: NumPy's Structured Arrays\n\n< Sorting Arrays | Contents | Data Manipulation with Pan..."
          ],
          [
           "[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')]\n\nHere 'U10' translates to \"Unicode string of m..."
          ],
          [
           "Out[8]:\n\n'Doug'\n\nUsing Boolean masking, this even allows you to do some more sophisticated operation..."
          ],
          [
           "A compound type can also be specified as a list of tuples:\n\nIn [12]:\n\nnp.dtype([('name', 'S10'), ('a..."
          ],
          [
           "'c'\n\nComplex floating point\n\nnp.dtype('c16') == np.complex128\n\n'S', 'a'\n\nString\n\nnp.dtype('S5')\n\n'U'..."
          ],
          [
           "RecordArrays: Structured Arrays with a Twist¶NumPy also provides the np.recarray class, which is alm..."
          ],
          [
           "< Sorting Arrays | Contents | Data Manipulation with Pandas >\n\nData Manipulation with Pandas | Pytho..."
          ],
          [
           "In this chapter, we will focus on the mechanics of using Series, DataFrame, and related structures e..."
          ],
          [
           "Python Data Science Handbook | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nAr..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "In [2]:\n\ndata = pd.Series([0.25, 0.5, 0.75, 1.0]) data\n\nOut[2]:\n\n0    0.25 1    0.50 2    0.75 3    ..."
          ],
          [
           "As we will see, though, the Pandas Series is much more general and flexible than the one-dimensional..."
          ],
          [
           "In [10]:\n\ndata[5]\n\nOut[10]:\n\n0.5\n\nSeries as specialized dictionary¶In this way, you can think of a P..."
          ],
          [
           "California    38332521 Florida       19552860 Illinois      12882135 dtype: int64\n\nWe'll discuss som..."
          ],
          [
           "Out[17]:\n\n3    c 2    a dtype: object\n\nNotice that in this case, the Series is populated only with t..."
          ],
          [
           "California\n\n423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n14129..."
          ],
          [
           "Out[22]:\n\nCalifornia    423967 Florida       170312 Illinois      149995 New York      141297 Texas ..."
          ],
          [
           "2\n\n2\n\n4\n\nEven if some keys in the dictionary are missing, Pandas will fill them in with NaN (i.e., \"..."
          ],
          [
           "Out[27]:\n\nfoo\n\nbar\n\na\n\n0.865257\n\n0.213169\n\nb\n\n0.442759\n\n0.108267\n\nc\n\n0.047110\n\n0.905718\n\nFrom a NumP..."
          ],
          [
           "In [30]:\n\nind = pd.Index([2, 3, 5, 7, 11]) ind\n\nOut[30]:\n\nInt64Index([2, 3, 5, 7, 11], dtype='int64'..."
          ],
          [
           "/Users/jakevdp/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py in __setitem__(self, key,..."
          ],
          [
           "These operations may also be accessed via object methods, for example indA.intersection(indB).\n\n< Da..."
          ],
          [
           "Series as dictionary¶Like a dictionary, the Series object provides a mapping from a collection of ke..."
          ],
          [
           "This easy mutability of the objects is a convenient feature: under the hood, Pandas is making decisi..."
          ],
          [
           "In [11]:\n\ndata = pd.Series(['a', 'b', 'c'], index=[1, 3, 5]) data\n\nOut[11]:\n\n1    a 3    b 5    c dt..."
          ],
          [
           "'b'\n\nIn [17]:\n\ndata.iloc[1:3]\n\nOut[17]:\n\n3    b 5    c dtype: object\n\nA third indexing attribute, ix..."
          ],
          [
           "38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n141297\n\n19651127\n\nTexas\n\n..."
          ],
          [
           "In [22]:\n\ndata.pop is data['pop']\n\nOut[22]:\n\nFalse\n\nIn particular, you should avoid the temptation t..."
          ],
          [
           "In [24]:\n\ndata.values\n\nOut[24]:\n\narray([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01], [  1..."
          ],
          [
           "1.148061e+02\n\n8.588376e+01\n\n1.390767e+02\n\n3.801874e+01\n\nWhen it comes to indexing of DataFrame objec..."
          ],
          [
           "In [29]:\n\ndata.loc[:'Illinois', :'pop']\n\nOut[29]:\n\narea\n\npop\n\nCalifornia\n\n423967\n\n38332521\n\nFlorida\n..."
          ],
          [
           "data\n\nOut[32]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n\n38332521\n\n90.000000\n\nFlorida\n\n170312\n\n195528..."
          ],
          [
           "19552860\n\n114.806121\n\nIllinois\n\n149995\n\n12882135\n\n85.883763\n\nSimilarly, direct masking operations ar..."
          ],
          [
           "Operating on Data in Pandas\n\n< Data Indexing and Selection | Contents | Handling Missing Data >\n\nOne..."
          ],
          [
           "Out[3]:\n\nA\n\nB\n\nC\n\nD\n\n0\n\n6\n\n9\n\n2\n\n6\n\n1\n\n7\n\n4\n\n3\n\n7\n\n2\n\n7\n\n2\n\n5\n\n4\n\nIf we apply a NumPy ufunc on eithe..."
          ],
          [
           "1.224647e\n\n16\n\nAny of the ufuncs discussed in Computation on NumPy Arrays: Universal Functions can b..."
          ],
          [
           "In [9]:\n\nA = pd.Series([2, 4, 6], index=[0, 1, 2]) B = pd.Series([1, 3, 5], index=[1, 2, 3]) A + B\n\n..."
          ],
          [
           "2\n\n9\n\n2\n\n6\n\nIn [13]:\n\nA + B\n\nOut[13]:\n\nA\n\nB\n\nC\n\n0\n\n1.0\n\n15.0\n\nNaN\n\n1\n\n13.0\n\n6.0\n\nNaN\n\n2\n\nNaN\n\nNaN\n\nN..."
          ],
          [
           "truediv(), div(), divide()\n\n//\n\nfloordiv()\n\n%\n\nmod()\n\npow()\n\nUfuncs: Operations Between DataFrame an..."
          ],
          [
           "1\n\n1\n\n2\n\n2\n\n4\n\n2\n\n3\n\n7\n\n1\n\n4\n\nIf you would instead like to operate column-wise, you can use the obje..."
          ],
          [
           "< Data Indexing and Selection | Contents | Handling Missing Data >\n\nHandling Missing Data | Python D..."
          ],
          [
           "Trade-Offs in Missing Data Conventions¶There are a number of schemes that have been developed to ind..."
          ],
          [
           "For example, the R language uses reserved bit patterns within each data type as sentinel values indi..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\nIn [2]:\n\nvals1 = np.array([1, None, 3, 4]) vals1\n\n..."
          ],
          [
           "/Users/jakevdp/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py in _sum(a, axis, dtype, o..."
          ],
          [
           "In [8]:\n\nvals2.sum(), vals2.min(), vals2.max()\n\nOut[8]:\n\n(nan, nan, nan)\n\nNumPy does provide some sp..."
          ],
          [
           "In [12]:\n\nx[0] = None\n\nx\n\nOut[12]:\n\n0    NaN 1    1.0 dtype: float64\n\nNotice that in addition to cas..."
          ],
          [
           "In [13]:\n\ndata = pd.Series([1, np.nan, 'hello', None])\n\nIn [14]:\n\ndata.isnull()\n\nOut[14]:\n\n0    Fals..."
          ],
          [
           "In [18]:\n\ndf.dropna()\n\nOut[18]:\n\n0\n\n1\n\n2\n\n1\n\n2.0\n\n3.0\n\n5\n\nAlternatively, you can drop NA values alon..."
          ],
          [
           "0\n\n1\n\n2\n\n0\n\n1.0\n\nNaN\n\n2\n\n1\n\n2.0\n\n3.0\n\n5\n\n2\n\nNaN\n\n4.0\n\n6\n\nFor finer-grained control, the thresh param..."
          ],
          [
           "a    1.0 b    0.0 c    2.0 d    0.0 e    3.0 dtype: float64\n\nWe can specify a forward-fill to propag..."
          ],
          [
           "2.0\n\n1\n\n2.0\n\n3.0\n\n5.0\n\n5.0\n\n2\n\nNaN\n\n4.0\n\n6.0\n\n6.0\n\nNotice that if a previous value is not available ..."
          ],
          [
           "In [1]:\n\nimport pandas as pd\n\nimport numpy as np\n\nA Multiply Indexed Series¶Let's start by consideri..."
          ],
          [
           "In [4]:\n\npop[[i for i in pop.index if i[1] == 2010]]\n\nOut[4]:\n\n(California, 2010)    37253956 (New Y..."
          ],
          [
           "Now to access all data for which the second index is 2010, we can simply use the Pandas slicing nota..."
          ],
          [
           "Out[9]:\n\nCalifornia  2000    33871648 2010    37253956 New York    2000    18976457 2010    19378102..."
          ],
          [
           "In [11]:\n\nf_u18 = pop_df['under18'] / pop_df['total'] f_u18.unstack()\n\nOut[11]:\n\n2000\n\n2010\n\nCalifor..."
          ],
          [
           "In [13]:\n\ndata = {('California', 2000): 33871648, ('California', 2010): 37253956, ('Texas', 2000): 2..."
          ],
          [
           "MultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nYou can even construct..."
          ],
          [
           "In [18]:\n\npop.index.names = ['state', 'year']\n\npop\n\nOut[18]:\n\nstate       year California  2000    3..."
          ],
          [
           "36.7\n\n35.0\n\n37.2\n\n2\n\n44.0\n\n37.7\n\n50.0\n\n35.0\n\n29.0\n\n36.7\n\n2014\n\n1\n\n30.0\n\n37.4\n\n39.0\n\n37.8\n\n61.0\n\n36.9..."
          ],
          [
           "Multiply indexed Series¶Consider the multiply indexed Series of state populations we saw earlier:\n\nI..."
          ],
          [
           "pop[pop > 22000000]\n\nOut[26]:\n\nstate       year California  2000    33871648 2010    37253956 Texas ..."
          ],
          [
           "In [29]:\n\nhealth_data['Guido', 'HR']\n\nOut[29]:\n\nyear  visit 2013  1        32.0 2        50.0 2014  ..."
          ],
          [
           "health_data.loc[(:, 1), (:, 'HR')]\n\n^\n\nSyntaxError: invalid syntax\n\nYou could get around this by bui..."
          ],
          [
           "In [34]:\n\nindex = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]]) data = pd.Series(np.random.r..."
          ],
          [
           "With the index sorted in this way, partial slicing will work as expected:\n\nIn [37]:\n\ndata['a':'b']\n\n..."
          ],
          [
           "Out[40]:\n\nstate       year California  2000    33871648 2010    37253956 New York    2000    1897645..."
          ],
          [
           "33871648\n\n2010\n\n37253956\n\nNew York\n\n2000\n\n18976457\n\n2010\n\n19378102\n\nTexas\n\n2000\n\n20851820\n\n2010\n\n251..."
          ],
          [
           "2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nPerhaps we'd like to average-out the measurements in the two ..."
          ],
          [
           "Aside: Panel Data¶Pandas has a few other fundamental data structures that we have not yet discussed,..."
          ],
          [
           "Combining Datasets: Concat and Append\n\n< Hierarchical Indexing | Contents | Combining Datasets: Merg..."
          ],
          [
           "In [3]:\n\nclass display(object): \"\"\"Display HTML representation of multiple objects\"\"\" template = \"\"\"..."
          ],
          [
           "In [5]:\n\nx = [[1, 2],\n\n[3, 4]]\n\nnp.concatenate([x, x], axis=1)\n\nOut[5]:\n\narray([[1, 2, 1, 2],\n\n[3, 4..."
          ],
          [
           "Out[7]:\n\ndf1\n\nA\n\nB\n\n1\n\nA1\n\nB1\n\n2\n\nA2\n\nB2\n\ndf2\n\nA\n\nB\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\npd.concat([df1, df2])\n\nA\n..."
          ],
          [
           "pd.concat([df3, df4], axis='col')\n\nA\n\nB\n\nC\n\nD\n\n0\n\nA0\n\nB0\n\nC0\n\nD0\n\n1\n\nA1\n\nB1\n\nC1\n\nD1\n\nWe could have e..."
          ],
          [
           "B3\n\nNotice the repeated indices in the result. While this is valid within DataFrames, the outcome is..."
          ],
          [
           "B0\n\n1\n\nA1\n\nB1\n\n2\n\nA2\n\nB2\n\n3\n\nA3\n\nB3\n\nAdding MultiIndex keys¶Another option is to use the keys option..."
          ],
          [
           "In [13]:\n\ndf5 = make_df('ABC', [1, 2]) df6 = make_df('BCD', [3, 4]) display('df5', 'df6', 'pd.concat..."
          ],
          [
           "display('df5', 'df6',\n\n\"pd.concat([df5, df6], join='inner')\")\n\nOut[14]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\nA1\n\nB1\n\nC1..."
          ],
          [
           "B2\n\nC2\n\ndf6\n\nB\n\nC\n\nD\n\n3\n\nB3\n\nC3\n\nD3\n\n4\n\nB4\n\nC4\n\nD4\n\npd.concat([df5, df6], join_axes=[df5.columns])\n\n..."
          ],
          [
           "B3\n\n4\n\nA4\n\nB4\n\ndf1.append(df2)\n\nA\n\nB\n\n1\n\nA1\n\nB1\n\n2\n\nA2\n\nB2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nKeep in mind that ..."
          ],
          [
           "Combining Datasets: Merge and Join\n\n< Combining Datasets: Concat and Append | Contents | Aggregation..."
          ],
          [
           "def __repr__(self): return '\\n\\n'.join(a + '\\n' + repr(eval(a)) for a in self.args)\n\nRelational Alge..."
          ],
          [
           "Out[2]:\n\ndf1\n\nemployee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSu..."
          ],
          [
           "Many\n\nto\n\none joins¶\n\nMany-to-one joins are joins in which one of the two key columns contains dupli..."
          ],
          [
           "HR\n\n2014\n\nSteve\n\nThe resulting DataFrame has an aditional column with the \"supervisor\" information, ..."
          ],
          [
           "HR\n\nspreadsheets\n\n5\n\nHR\n\norganization\n\npd.merge(df1, df5)\n\nemployee\n\ngroup\n\nskills\n\n0\n\nBob\n\nAccounti..."
          ],
          [
           "Out[6]:\n\ndf1\n\nemployee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSu..."
          ],
          [
           "Out[7]:\n\ndf1\n\nemployee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSu..."
          ],
          [
           "Jake\n\nEngineering\n\n80000\n\n2\n\nLisa\n\nEngineering\n\n120000\n\n3\n\nSue\n\nHR\n\n90000\n\nThe left_index and right_..."
          ],
          [
           "df2a\n\nhire_date\n\nemployee\n\nLisa\n\n2004\n\nBob\n\n2008\n\nJake\n\n2012\n\nSue\n\n2014\n\npd.merge(df1a, df2a, left_i..."
          ],
          [
           "2014\n\nIf you'd like to mix indices and columns, you can combine left_index with right_on or left_on ..."
          ],
          [
           "In [13]:\n\ndf6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'], 'food': ['fish', 'beans', 'bread']}..."
          ],
          [
           "wine\n\nOther options for the how keyword are 'outer', 'left', and 'right'. An outer join returns a jo..."
          ],
          [
           "beans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary\n\nwine\n\n1\n\nJoseph\n\nbeer\n\npd.merge(df6, df7, how='lef..."
          ],
          [
           "3\n\n3\n\nSue\n\n4\n\ndf9\n\nname\n\nrank\n\n0\n\nBob\n\n3\n\n1\n\nJake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"..."
          ],
          [
           "3\n\n1\n\nJake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n\nname\n\nra..."
          ],
          [
           "Let's take a look at the three datasets, using the Pandas read_csv() function:\n\nIn [20]:\n\npop = pd.r..."
          ],
          [
           "state\n\nabbreviation\n\n0\n\nAlabama\n\nAL\n\n1\n\nAlaska\n\nAK\n\n2\n\nArizona\n\nAZ\n\n3\n\nArkansas\n\nAR\n\n4\n\nCalifornia\n\n..."
          ],
          [
           "4785570.0\n\nAlabama\n\n4\n\nAL\n\nunder18\n\n2011\n\n1125763.0\n\nAlabama\n\nLet's double-check whether there were ..."
          ],
          [
           "In [24]:\n\nmerged.loc[merged['state'].isnull(), 'state/region'].unique()\n\nOut[24]:\n\narray(['PR', 'USA..."
          ],
          [
           "2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\nAlabama\n\n52423.0\n\n3\n\nAL\n\ntotal\n\n2010\n\n4785570.0\n\nAlabama\n\n52423.0\n\n..."
          ],
          [
           "0\n\nAL\n\nunder18\n\n2012\n\n1117489.0\n\nAlabama\n\n52423.0\n\n1\n\nAL\n\ntotal\n\n2012\n\n4817528.0\n\nAlabama\n\n52423.0\n\n..."
          ],
          [
           "Alaska\n\n656425.0\n\n101\n\nAZ\n\ntotal\n\n2010\n\n6408790.0\n\nArizona\n\n114006.0\n\n189\n\nAR\n\ntotal\n\n2010\n\n2922280...."
          ],
          [
           "state South Dakota    10.583512 North Dakota     9.537565 Montana          6.736171 Wyoming         ..."
          ],
          [
           "For convenience, we'll use the same display magic function that we've seen in previous sections:\n\nIn..."
          ],
          [
           "0\n\nRadial Velocity\n\n1\n\n269.300\n\n7.10\n\n77.40\n\n2006\n\n1\n\nRadial Velocity\n\n1\n\n874.774\n\n2.21\n\n56.95\n\n2008..."
          ],
          [
           "Out[6]:\n\n0.56238509834163142\n\nFor a DataFrame, by default the aggregates return results within each ..."
          ],
          [
           "In [10]:\n\nplanets.dropna().describe()\n\nOut[10]:\n\nnumber\n\norbital_period\n\nmass\n\ndistance\n\nyear\n\ncount..."
          ],
          [
           "max\n\n6.00000\n\n17337.500000\n\n25.000000\n\n354.000000\n\n2014.000000\n\nThis can be a useful way to begin un..."
          ],
          [
           "Split, apply, combine¶A canonical example of this split-apply-combine operation, where the \"apply\" i..."
          ],
          [
           "5\n\nThe most basic split-apply-combine operation can be computed with the groupby() method of DataFra..."
          ],
          [
           "Column indexing¶The GroupBy object supports column indexing in the same way as the DataFrame, and re..."
          ],
          [
           "for (method, group) in planets.groupby('method'): print(\"{0:30s} shape={1}\".format(method, group.sha..."
          ],
          [
           "2010.0\n\n2011.00\n\n2012.0\n\nImaging\n\n38.0\n\n2009.131579\n\n2.781901\n\n2004.0\n\n2008.00\n\n2009.0\n\n2011.00\n\n201..."
          ],
          [
           "2002.0\n\n2010.00\n\n2012.0\n\n2013.00\n\n2014.0\n\nTransit Timing Variations\n\n4.0\n\n2012.500000\n\n1.290994\n\n201..."
          ],
          [
           "data1\n\ndata2\n\n0\n\nA\n\n0\n\n5\n\n1\n\nB\n\n1\n\n0\n\n2\n\nC\n\n2\n\n3\n\n3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\nAggregation¶We..."
          ],
          [
           "'data2': 'max'})\n\nOut[21]:\n\ndata1\n\ndata2\n\nkey\n\nA\n\n0\n\n5\n\nB\n\n1\n\n7\n\nC\n\n2\n\n9\n\nFiltering¶A filtering oper..."
          ],
          [
           "4.242641\n\ndf.groupby('key').filter(filter_func)\n\nkey\n\ndata1\n\ndata2\n\n1\n\nB\n\n1\n\n0\n\n2\n\nC\n\n2\n\n3\n\n4\n\nB\n\n4\n..."
          ],
          [
           "In [24]:\n\ndef norm_by_data2(x): # x is a DataFrame of group values x['data1'] /= x['data2'].sum() re..."
          ],
          [
           "9\n\napply() within a GroupBy is quite flexible: the only criterion is that the function takes a DataF..."
          ],
          [
           "display('df', \"df.groupby(df['key']).sum()\")\n\nOut[26]:\n\ndf\n\nkey\n\ndata1\n\ndata2\n\n0\n\nA\n\n0\n\n5\n\n1\n\nB\n\n1\n\n..."
          ],
          [
           "3\n\nA\n\n3\n\n3\n\nB\n\n4\n\n7\n\nC\n\n5\n\n9\n\ndf2.groupby(mapping).sum()\n\ndata1\n\ndata2\n\nconsonant\n\n12\n\n19\n\nvowel\n\n3\n..."
          ],
          [
           "data1\n\ndata2\n\na\n\nvowel\n\n1.5\n\n4.0\n\nb\n\nconsonant\n\n2.5\n\n3.5\n\nc\n\nconsonant\n\n3.5\n\n6.0\n\nGrouping example¶A..."
          ],
          [
           "0.0\n\n1.0\n\n0.0\n\nRadial Velocity\n\n1.0\n\n52.0\n\n475.0\n\n424.0\n\nTransit\n\n0.0\n\n0.0\n\n64.0\n\n712.0\n\nTransit Tim..."
          ],
          [
           "Pivot Tables\n\n< Aggregation and Grouping | Contents | Vectorized String Operations >\n\nWe have seen h..."
          ],
          [
           "Southampton\n\nno\n\nFalse\n\n1\n\n1\n\n1\n\nfemale\n\n38.0\n\n1\n\n0\n\n71.2833\n\nC\n\nFirst\n\nwoman\n\nFalse\n\nC\n\nCherbourg\n\n..."
          ],
          [
           "titanic.groupby('sex')[['survived']].mean()\n\nOut[3]:\n\nsurvived\n\nsex\n\nfemale\n\n0.742038\n\nmale\n\n0.18890..."
          ],
          [
           "titanic.pivot_table('survived', index='sex', columns='class')\n\nOut[5]:\n\nclass\n\nFirst\n\nSecond\n\nThird\n..."
          ],
          [
           "0.800000\n\n0.600000\n\n0.215686\n\n(18, 80]\n\n0.375000\n\n0.071429\n\n0.133663\n\nWe can apply the same strategy..."
          ],
          [
           "0.098039\n\n0.125000\n\n0.391304\n\n0.030303\n\n0.192308\n\nThe result is a four-dimensional aggregation with ..."
          ],
          [
           "Third\n\nsex\n\nfemale\n\n106.125798\n\n21.970121\n\n16.118810\n\n91.0\n\n70.0\n\n72.0\n\nmale\n\n67.226127\n\n19.741782\n\n..."
          ],
          [
           "Example: Birthrate Data¶As a more interesting example, let's take a look at the freely available dat..."
          ],
          [
           "In [13]:\n\nbirths['decade'] = 10\n\n(births['year'] // 10)\n\nbirths.pivot_table('births', index='decade'..."
          ],
          [
           "With a simple pivot table and plot() method, we can immediately see the annual trend in births by ge..."
          ],
          [
           "In [17]:\n\n# set 'day' column to integer; it originally was a string due to nulls births['day'] = bir..."
          ],
          [
           "[births.index.month, births.index.day])\n\nbirths_by_date.head()\n\nOut[20]:\n\n1  1    4009.225 2    4247..."
          ],
          [
           "In [22]:\n\n# Plot the results fig, ax = plt.subplots(figsize=(12, 4)) births_by_date.plot(ax=ax);\n\nIn..."
          ],
          [
           "Introducing Pandas String Operations¶We saw in previous sections how tools like NumPy and Pandas gen..."
          ],
          [
           "<ipython-input-3-fc1d891ab539> in <listcomp>(.0) 1 data = ['peter', 'Paul', None, 'MARY', 'gUIDO'] -..."
          ],
          [
           "len()\n\nlower()\n\ntranslate()\n\nislower()\n\nljust()\n\nupper()\n\nstartswith()\n\nisupper()\n\nrjust()\n\nfind()\n\n..."
          ],
          [
           "Still others return lists or other compound values for each element:\n\nIn [10]:\n\nmonte.str.split()\n\nO..."
          ],
          [
           "In [12]:\n\nmonte.str.findall(r'^[^AEIOU].\n\n[^aeiou]$')\n\nOut[12]:\n\n0    [Graham Chapman] 1            ..."
          ],
          [
           "monte.str[0:3]\n\nOut[13]:\n\n0    Gra 1    Joh 2    Ter 3    Eri 4    Ter 5    Mic dtype: object\n\nIndex..."
          ],
          [
           "B|D\n\nEric Idle\n\n4\n\nB|C\n\nTerry Jones\n\n5\n\nB|C|D\n\nMichael Palin\n\nThe get_dummies() routine lets you qui..."
          ],
          [
           "Example: Recipe Database¶These vectorized string operations become most useful in the process of cle..."
          ],
          [
           "line = f.readline()\n\npd.read_json(line).shape\n\nOut[19]:\n\n(2, 12)\n\nYes, apparently each line is a val..."
          ],
          [
           "There is a lot of information there, but much of it is in a very messy form, as is typical of data s..."
          ],
          [
           "In [27]:\n\nrecipes.ingredients.str.contains('[Cc]inamon').sum()\n\nOut[27]:\n\n11\n\nThis is the type of es..."
          ],
          [
           "False\n\nFalse\n\nFalse\n\nTrue\n\nFalse\n\nFalse\n\nFalse\n\n1\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\n..."
          ],
          [
           "In [31]:\n\nrecipes.name[selection.index]\n\nOut[31]:\n\n2069      All cremat with a Little Gem, dandelion..."
          ],
          [
           "Working with Time Series\n\n< Vectorized String Operations | Contents | High-Performance Pandas: eval(..."
          ],
          [
           "In [1]:\n\nfrom datetime import datetime\n\ndatetime(year=2015, month=7, day=4)\n\nOut[1]:\n\ndatetime.datet..."
          ],
          [
           "In [4]:\n\nimport numpy as np\n\ndate = np.array('2015\n\n07\n\n04', dtype=np.datetime64)\n\ndate\n\nOut[4]:\n\nar..."
          ],
          [
           "07\n\n13', '2015\n\n07\n\n14', '2015\n\n07\n\n15'], dtype='datetime64[D]')\n\nBecause of the uniform type in Num..."
          ],
          [
           "In [8]:\n\nnp.datetime64('2015\n\n07\n\n04 12:59:59.50', 'ns')\n\nOut[8]:\n\nnumpy.datetime64('2015\n\n07\n\n04T12..."
          ],
          [
           "us\n\nMicrosecond\n\n± 2.9e6 years\n\n[290301 BC, 294241 AD]\n\nns Nanosecond ± 292 years [ 1678 AD, 2262 AD..."
          ],
          [
           "04 00:00:00')\n\nIn [10]:\n\ndate.strftime('%A')\n\nOut[10]:\n\n'Saturday'\n\nAdditionally, we can do NumPy-st..."
          ],
          [
           "Out[12]:\n\n2014-07-04    0 2014-08-04    1 2015-07-04    2 2015-08-04    3 dtype: int64\n\nNow that we ..."
          ],
          [
           "The most fundamental of these date/time objects are the Timestamp and DatetimeIndex objects. While t..."
          ],
          [
           "In [17]:\n\ndates\n\ndates[0]\n\nOut[17]:\n\nTimedeltaIndex(['0 days', '1 days', '3 days', '4 days', '5 days..."
          ],
          [
           "In [19]:\n\npd.date_range('2015\n\n07\n\n03', periods=8)\n\nOut[19]:\n\nDatetimeIndex(['2015\n\n07\n\n03', '2015\n\n..."
          ],
          [
           "07\n\n03 07:00:00'],\n\ndtype='datetime64[ns]', freq='H')\n\nTo create regular sequences of Period or Time..."
          ],
          [
           "Code\n\nDescription\n\nCode\n\nDescription\n\nD\n\nCalendar day\n\nB\n\nBusiness day\n\nW\n\nWeekly\n\nM\n\nMonth end\n\nBM\n..."
          ],
          [
           "W\n\nSUN, W\n\nMON, W\n\nTUE, W\n\nWED, etc.\n\nOn top of this, codes can be combined with numbers to specify ..."
          ],
          [
           "For more discussion of the use of frequencies and offsets, see the \"DateOffset\" section of the Panda..."
          ],
          [
           "2004\n\n08\n\n24\n\n55.56\n\n55.74\n\n51.73\n\n52.38\n\nNaN\n\n2004\n\n08\n\n25\n\n52.43\n\n53.95\n\n51.89\n\n52.95\n\nNaN\n\nFor si..."
          ],
          [
           "');\n\nplt.legend(['input', 'resample', 'asfreq'],\n\nloc='upper left');\n\nNotice the difference: at each..."
          ],
          [
           "The top panel is the default: non-business days are left as NA values and do not appear on the plot...."
          ],
          [
           "ax[2].legend(['tshift(900)'], loc=2) ax[2].get_xticklabels()[1].set(weight='heavy', color='red') ax[..."
          ],
          [
           "'one\n\nyear rolling_std': rolling.std()})\n\nax = data.plot(style=['\n\n', '-\n\n', ':'])\n\nax.lines[0].set_..."
          ],
          [
           "Once this dataset is downloaded, we can use Pandas to read the CSV output into a DataFrame. We will ..."
          ],
          [
           "35752.000000\n\nmean\n\n61.470267\n\n54.410774\n\n115.881042\n\nstd\n\n82.588484\n\n77.659796\n\n145.392385\n\nmin\n\n0...."
          ],
          [
           "weekly.plot(style=[':', '-\n\n', '\n\n'])\n\nplt.ylabel('Weekly bicycle count');\n\nThis shows us some inter..."
          ],
          [
           "In [43]:\n\nby_time = data.groupby(data.index.time).mean()\n\nhourly_ticks = 4\n\n60\n\n60\n\nnp.arange(6)\n\nby..."
          ],
          [
           "Now we'll use some of the Matplotlib tools described in Multiple Subplots to plot two panels side by..."
          ],
          [
           "High-Performance Pandas: eval() and query()\n\n< Working with Time Series | Contents | Further Resourc..."
          ],
          [
           "1 loop, best of 3: 266 ms per loop\n\nBut this abstraction can become less efficient when computing co..."
          ],
          [
           "In [6]:\n\nimport pandas as pd nrows, ncols = 100000, 100 rng = np.random.RandomState(42) df1, df2, df..."
          ],
          [
           "Arithmetic operators¶pd.eval() supports all arithmetic operators. For example:\n\nIn [11]:\n\nresult1 = ..."
          ],
          [
           "Out[14]:\n\nTrue\n\nObject attributes and indices¶pd.eval() supports access to object attributes via the..."
          ],
          [
           "3\n\n0.264038\n\n0.808055\n\n0.347197\n\n4\n\n0.589161\n\n0.252418\n\n0.557789\n\nUsing pd.eval() as above, we can c..."
          ],
          [
           "0.069087\n\n0.235615\n\n0.154374\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n3\n\n0.264038\n\n0.808055\n\n0.347197\n\n4\n\n0..."
          ],
          [
           "In [21]:\n\ndf.eval('D = (A\n\nB) / C', inplace=True)\n\ndf.head()\n\nOut[21]:\n\nA\n\nB\n\nC\n\nD\n\n0\n\n0.375506\n\n0.4..."
          ],
          [
           "Out[22]:\n\nTrue\n\nThe @ character here marks a variable name rather than a column name, and lets you e..."
          ],
          [
           "Out[25]:\n\nTrue\n\nPerformance: When to Use These Functions¶When considering whether to use these funct..."
          ],
          [
           "< Working with Time Series | Contents | Further Resources >\n\nFurther Resources | Python Data Science..."
          ],
          [
           "Pandas on PyVideo: From PyCon to SciPy to PyData, many conferences have featured tutorials from Pand..."
          ],
          [
           "Visualization with Matplotlib\n\n< Further Resources | Contents | Simple Line Plots >\n\nWe'll now take ..."
          ],
          [
           "In recent years, however, the interface and style of Matplotlib have begun to show their age. Newer ..."
          ],
          [
           "In [2]:\n\nplt.style.use('classic')\n\nThroughout this section, we will adjust this style as needed. Not..."
          ],
          [
           "plt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x))\n\nplt.show()\n\nYou can then run this script from the co..."
          ],
          [
           "Plotting from an IPython notebook¶The IPython notebook is a browser-based interactive data analysis ..."
          ],
          [
           "In [6]:\n\n!ls\n\nlh my_figure.png\n\nrw\n\nr\n\n--r\n\n--  1 jakevdp  staff    16K Aug 11 10:59 my_figure.png\n\n..."
          ],
          [
           "MATLAB-style Interface¶Matplotlib was originally written as a Python alternative for MATLAB users, a..."
          ],
          [
           "# Call plot() method on the appropriate object ax[0].plot(x, np.sin(x)) ax[1].plot(x, np.cos(x));\n\nF..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhitegrid')\n\ni..."
          ],
          [
           "In [5]:\n\nplt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x));\n\nThat's all there is to plotting simple fun..."
          ],
          [
           "If no color is specified, Matplotlib will automatically cycle through a set of default colors for mu..."
          ],
          [
           "Adjusting the Plot: Axes Limits¶Matplotlib does a decent job of choosing default axes limits for you..."
          ],
          [
           "In [13]:\n\nplt.plot(x, np.sin(x))\n\nplt.axis('equal');\n\nFor more information on axis limits and the ot..."
          ],
          [
           "plt.axis('equal')\n\nplt.legend();\n\nAs you can see, the plt.legend() function keeps track of the line ..."
          ],
          [
           "< Visualization with Matplotlib | Contents | Simple Scatter Plots >\n\nSimple Scatter Plots | Python D..."
          ],
          [
           "In [3]:\n\nrng = np.random.RandomState(0) for marker in ['o', '. ', ',', 'x', '+', 'v', '^', '<', '>',..."
          ],
          [
           "In [6]:\n\nplt.scatter(x, y, marker='o');\n\nThe primary difference of plt.scatter from plt.plot is that..."
          ],
          [
           "s=100\n\nfeatures[3], c=iris.target, cmap='viridis')\n\nplt.xlabel(iris.feature_names[0])\n\nplt.ylabel(ir..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "plt.errorbar(x, y, yerr=dy, fmt='.k');\n\nHere the fmt is a format code controlling the appearance of ..."
          ],
          [
           "# Compute the Gaussian process fit gp = GaussianProcess(corr='cubic', theta0=1e-2, thetaL=1e-4, thet..."
          ],
          [
           "dyfit, yfit + dyfit,\n\ncolor='gray', alpha=0.2)\n\nplt.xlim(0, 10);\n\nNote what we've done here with the..."
          ],
          [
           "Density and Contour Plots\n\n< Visualizing Errors | Contents | Histograms, Binnings, and Density >\n\nSo..."
          ],
          [
           "X, Y = np.meshgrid(x, y) Z = f(X, Y)\n\nNow let's look at this with a standard line-only contour plot:..."
          ],
          [
           "In [6]:\n\nplt.contourf(X, Y, Z, 20, cmap='RdGy') plt.colorbar();\n\nThe colorbar makes it clear that th..."
          ],
          [
           "In [8]:\n\ncontours = plt.contour(X, Y, Z, 3, colors='black') plt.clabel(contours, inline=True, fontsi..."
          ],
          [
           "%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhi..."
          ],
          [
           "In [5]:\n\ncounts, bin_edges = np.histogram(data, bins=5) print(counts)\n\n[ 12 190 468 301  29]\n\nTwo-Di..."
          ],
          [
           "For the generalization of this histogram binning in dimensions higher than two, see the np.histogram..."
          ],
          [
           "# Plot the result as an image plt.imshow(Z.reshape(Xgrid.shape), origin='lower', aspect='auto', exte..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\nIn [2]:\n\n%matplotlib inline\n\nimp..."
          ],
          [
           "fig\n\nOut[6]:\n\nFor more information on available legend options, see the plt.legend docstring.\n\nChoos..."
          ],
          [
           "In [9]:\n\nimport pandas as pd\n\ncities = pd.read_csv('data/california_cities.csv')\n\n# Extract the data..."
          ],
          [
           "plt.title('California Cities: Area and Population');\n\nThe legend will always reference some object t..."
          ],
          [
           "# specify the lines and labels of the first legend ax.legend(lines[:2], ['line A', 'line B'], loc='u..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\nIn [2]:\n\n%matplotlib inline\n\nimp..."
          ],
          [
           "Sequential colormaps: These are made up of one continuous sequence of colors (e.g., binary or viridi..."
          ],
          [
           "cmap = grayscale_cmap(cmap)\n\ngrayscale = cmap(np.arange(cmap.N))\n\nfig, ax = plt.subplots(2, figsize=..."
          ],
          [
           "In [9]:\n\nview_colormap('RdBu')\n\nWe'll see examples of using some of these color maps as we continue...."
          ],
          [
           "plt.colorbar(extend='both')\n\nplt.clim(\n\n1, 1);\n\nNotice that in the left panel, the default color lim..."
          ],
          [
           "Because each digit is defined by the hue of its 64 pixels, we can consider each digit to be a point ..."
          ],
          [
           "< Customizing Plot Legends | Contents | Multiple Subplots >\n\nMultiple Subplots | Python Data Science..."
          ],
          [
           "In [2]:\n\nax1 = plt.axes()  # standard axes ax2 = plt.axes([0.65, 0.65, 0.2, 0.2])\n\nThe equivalent of..."
          ],
          [
           "The command plt.subplots_adjust can be used to adjust the spacing between these plots. The following..."
          ],
          [
           "In [6]:\n\nfig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\n\nNote that by specifying sharex an..."
          ],
          [
           "plt.subplot(grid[1, :2])\n\nplt.subplot(grid[1, 2]);\n\nThis type of flexible grid alignment has a wide ..."
          ],
          [
           "< Customizing Colorbars | Contents | Text and Annotation >\n\nText and Annotation | Python Data Scienc..."
          ],
          [
           "In [2]:\n\nbirths = pd.read_csv('data/births.csv')\n\nquartiles = np.percentile(births['births'], [25, 5..."
          ],
          [
           "# Add labels to the plot style = dict(size=10, color='gray')\n\nax.text('2012-1-1', 3950, \"New Year's ..."
          ],
          [
           "Transforms and Text Position¶In the previous example, we have anchored our text annotations to data ..."
          ],
          [
           "Note that by default, the text is aligned above and to the left of the specified coordinates: here t..."
          ],
          [
           "x = np.linspace(0, 20, 1000) ax.plot(x, np.cos(x)) ax.axis('equal')\n\nax.annotate('local maximum', xy..."
          ],
          [
           "bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\"),\n\nxytext=(10,\n\n40), textcoords='offset points', ha..."
          ],
          [
           "25', 4500),  xycoords='data',\n\nxytext=(\n\n120,\n\n60), textcoords='offset points',\n\nbbox=dict(boxstyle=..."
          ],
          [
           "ax.set_ylim(3600, 5400);\n\nYou'll notice that the specifications of the arrows and text boxes are ver..."
          ],
          [
           "Customizing Ticks\n\n< Text and Annotation | Contents | Customizing Matplotlib: Configurations and Sty..."
          ],
          [
           "In [3]:\n\nprint(ax.xaxis.get_major_locator())\n\nprint(ax.xaxis.get_minor_locator())\n\n<matplotlib.ticke..."
          ],
          [
           "ax.xaxis.set_major_formatter(plt.NullFormatter())\n\nNotice that we've removed the labels (but kept th..."
          ],
          [
           "In [7]:\n\nfig, ax = plt.subplots(4, 4, sharex=True, sharey=True)\n\nParticularly for the x ticks, the n..."
          ],
          [
           "# Set up grid, legend, and limits ax.grid(True) ax.legend(frameon=False) ax.axis('equal') ax.set_xli..."
          ],
          [
           "ax.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n\nfig\n\nOut[11]:\n\nThis is much better! No..."
          ],
          [
           "IndexFormatter Set the strings from a list of labels\n\nFixedFormatter Set the strings manually for th..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\nimport numpy as np\n\n%matplotlib ..."
          ],
          [
           "Changing the Defaults: rcParams¶Each time Matplotlib loads, it defines a runtime configuration (rc) ..."
          ],
          [
           "plt.hist(x);\n\nLet's see what simple line plots look like with these rc parameters:\n\nIn [7]:\n\nfor i i..."
          ],
          [
           "Let's create a function that will make two basic types of plot:\n\nIn [9]:\n\ndef hist_and_lines(): np.r..."
          ],
          [
           "In [13]:\n\nwith plt.style.context('ggplot'):\n\nhist_and_lines()\n\nBayesian Methods for Hackers( style¶T..."
          ],
          [
           "< Customizing Ticks | Contents | Three-Dimensional Plotting in Matplotlib >\n\nThree-Dimensional Plott..."
          ],
          [
           "Three-dimensional Points and Lines¶The most basic three-dimensional plot is a line or collection of ..."
          ],
          [
           "In [5]:\n\ndef f(x, y):\n\nreturn np.sin(np.sqrt(x *\n\n2 + y *\n\n2))\n\nx = np.linspace(\n\n6, 6, 30)\n\ny = np...."
          ],
          [
           "fig = plt.figure()\n\nax = plt.axes(projection='3d')\n\nax.plot_wireframe(X, Y, Z, color='black')\n\nax.se..."
          ],
          [
           "In [11]:\n\ntheta = 2\n\nnp.pi\n\nnp.random.random(1000)\n\nr = 6\n\nnp.random.random(1000)\n\nx = np.ravel(r\n\nn..."
          ],
          [
           "Example: Visualizing a Möbius strip¶A Möbius strip is similar to a strip of paper glued into a loop ..."
          ],
          [
           "np.cos(theta))\n\ny = np.ravel(r\n\nnp.sin(theta))\n\nz = np.ravel(w\n\nnp.sin(phi))\n\nFinally, to plot the o..."
          ],
          [
           "Geographic Data with Basemap\n\n< Three-Dimensional Plotting in Matplotlib | Contents | Visualization ..."
          ],
          [
           "The meaning of the arguments to Basemap will be discussed momentarily. The useful thing is that the ..."
          ],
          [
           "Map Projections¶The first thing to decide when using maps is what projection to use. You're probably..."
          ],
          [
           "# cycle through these lines and set the desired style for line in all_lines: line.set(linestyle='-',..."
          ],
          [
           "In [6]:\n\nfig = plt.figure(figsize=(8, 6), edgecolor='w') m = Basemap(projection='moll', resolution=N..."
          ],
          [
           "m = Basemap(projection='ortho', resolution=None,\n\nlat_0=50, lon_0=0)\n\ndraw_map(m);\n\nConic projection..."
          ],
          [
           "Drawing a Map Background¶Earlier we saw the bluemarble() and shadedrelief() methods for projecting g..."
          ],
          [
           "For the boundary-based features, you must set the desired resolution when creating a Basemap image. ..."
          ],
          [
           "Plotting Data on Maps¶Perhaps the most useful piece of the Basemap toolkit is the ability to over-pl..."
          ],
          [
           "Next, we set up the map projection, scatter the data, and then create a colorbar and legend:\n\nIn [11..."
          ],
          [
           "Example: Surface Temperature Data¶As an example of visualizing some more continuous geographic data,..."
          ],
          [
           "Finally, we'll use the pcolormesh() method to draw a color mesh of the data. We'll look at North Ame..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\n%matplotlib inline\n\nimport numpy..."
          ],
          [
           "Ah, much better!\n\nExploring Seaborn Plots¶The main idea of Seaborn is that it provides high-level co..."
          ],
          [
           "In [9]:\n\nsns.kdeplot(data);\n\nWe can see the joint distribution and the marginal distributions togeth..."
          ],
          [
           "4.7\n\n3.2\n\n1.3\n\n0.2\n\nsetosa\n\n3\n\n4.6\n\n3.1\n\n1.5\n\n0.2\n\nsetosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nVisualizin..."
          ],
          [
           "23.68\n\n3.31\n\nMale\n\nNo\n\nSun\n\nDinner\n\n2\n\n4\n\n24.59\n\n3.61\n\nFemale\n\nNo\n\nSun\n\nDinner\n\n4\n\nIn [15]:\n\ntips['t..."
          ],
          [
           "In [18]:\n\nsns.jointplot(\"total_bill\", \"tip\", data=tips, kind='reg');\n\nBar plots¶Time series can be p..."
          ],
          [
           "We can learn more by looking at the method of discovery of each of these planets:\n\nIn [21]:\n\nwith sn..."
          ],
          [
           "02:10:42\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nBy default, Pandas loaded the ..."
          ],
          [
           "4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nIn [26]:\n\ndata.dtypes\n\nOut[26]:\n\nage                 int64 gender     ..."
          ],
          [
           "02:13:59\n\n3992.0\n\n8039.0\n\nTo get an idea of what the data looks like, we can plot a jointplot over t..."
          ],
          [
           "02:09:28\n\n3986.0\n\n7768.0\n\n0.026262\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n4009.0\n\n7842.0\n\n0.022443\n\n3\n\n38\n\nM..."
          ],
          [
           "It looks like the split fraction does not correlate particularly with age, but does correlate with t..."
          ],
          [
           "Out[35]:\n\nage\n\ngender\n\nsplit\n\nfinal\n\nsplit_sec\n\nfinal_sec\n\nsplit_frac\n\nage_dec\n\n0\n\n33\n\nM\n\n01:05:38\n\n..."
          ],
          [
           "split=True, inner=\"quartile\",\n\npalette=[\"lightblue\", \"lightpink\"]);\n\nLooking at this, we can see whe..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "Other Python Graphics Libraries¶Although Matplotlib is the most prominent Python visualization libra..."
          ],
          [
           "Machine Learning\n\n< Further Resources | Contents | What Is Machine Learning? >\n\nIn many ways, machin..."
          ],
          [
           "< Further Resources | Contents | What Is Machine Learning? >\n\nPython Data Science Handbook | Python ..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "Categories of Machine Learning¶At the most fundamental level, machine learning can be categorized in..."
          ],
          [
           "figure source in Appendix\n\nHere we have two-dimensional data: that is, we have two features for each..."
          ],
          [
           "feature 1, feature 2, etc. $\\to$ normalized counts of important words or phrases (\"Viagra\", \"Nigeria..."
          ],
          [
           "figure source in Appendix\n\nNotice that the feature 1-feature 2 plane here is the same as in the two-..."
          ],
          [
           "Clustering: Inferring labels on unlabeled data¶The classification and regression illustrations we ju..."
          ],
          [
           "figure source in Appendix\n\nVisually, it is clear that there is some structure in this data: it is dr..."
          ],
          [
           "Clustering: Models that detect and identify distinct groups in the data Dimensionality reduction: Mo..."
          ],
          [
           "Data Representation in Scikit\n\nLearn¶\n\nMachine learning is about creating models from data: for that..."
          ],
          [
           "0.2\n\nsetosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nHere each row of the data refers to a single observed fl..."
          ],
          [
           "Target array¶In addition to the feature matrix X, we also generally work with a label or target arra..."
          ],
          [
           "figure source in Appendix\n\nWith this data properly formatted, we can move on to consider the estimat..."
          ],
          [
           "We will now step through several simple examples of applying supervised and unsupervised learning me..."
          ],
          [
           "These are examples of the important choices that must be made once the model class is selected. Thes..."
          ],
          [
           "In [9]:\n\nmodel.fit(X, y)\n\nOut[9]:\n\nLinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, norma..."
          ],
          [
           "In [12]:\n\nxfit = np.linspace(\n\n1, 11)\n\nAs before, we need to coerce these x values into a [n_samples..."
          ],
          [
           "With the data arranged, we can follow our recipe to predict the labels:\n\nIn [16]:\n\nfrom sklearn.naiv..."
          ],
          [
           "Now let's plot the results. A quick way to do this is to insert the results into the original Iris D..."
          ],
          [
           "sns.lmplot(\"PCA1\", \"PCA2\", data=iris, hue='species',\n\ncol='cluster', fit_reg=False);\n\nBy splitting t..."
          ],
          [
           "for i, ax in enumerate(axes.flat): ax.imshow(digits.images[i], cmap='binary', interpolation='nearest..."
          ],
          [
           "data_projected = iso.transform(digits.data)\n\ndata_projected.shape\n\nOut[26]:\n\n(1797, 2)\n\nWe see that ..."
          ],
          [
           "In [29]:\n\nfrom sklearn.naive_bayes import GaussianNB\n\nmodel = GaussianNB()\n\nmodel.fit(Xtrain, ytrain..."
          ],
          [
           "test_images = Xtest.reshape(\n\n1, 8, 8)\n\nfor i, ax in enumerate(axes.flat): ax.imshow(test_images[i],..."
          ],
          [
           "Hyperparameters and Model Validation\n\n< Introducing Scikit-Learn | Contents | Feature Engineering >\n..."
          ],
          [
           "Then we train the model, and use it to predict labels for data we already know:\n\nIn [3]:\n\nmodel.fit(..."
          ],
          [
           "# evaluate the model on the second set of data y2_model = model.predict(X2) accuracy_score(y2, y2_mo..."
          ],
          [
           "Out[6]:\n\n(0.95999999999999996, 0.90666666666666662)\n\nWhat comes out are two accuracy scores, which w..."
          ],
          [
           "In [8]:\n\nfrom sklearn.cross_validation import LeaveOneOut scores = cross_val_score(model, X, y, cv=L..."
          ],
          [
           "from sklearn.cross_validation import LeaveOneOut scores = cross_val_score(model, X, y, cv=LeaveOneOu..."
          ],
          [
           "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and th..."
          ],
          [
           "The Bias-variance trade-off¶Fundamentally, the question of \"the best model\" is about finding a sweet..."
          ],
          [
           "If we imagine that we have some ability to tune the model complexity, we would expect the training s..."
          ],
          [
           "In [10]:\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.linear_model import Lin..."
          ],
          [
           "The knob controlling model complexity in this case is the degree of the polynomial, which can be any..."
          ],
          [
           "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n\nplt.plot(X_test.ravel(), y_test);\n\nplt.a..."
          ],
          [
           "The solid lines show the new results, while the fainter dashed lines show the results of the previou..."
          ],
          [
           "In [17]:\n\nfrom sklearn.learning_curve import learning_curve\n\nfig, ax = plt.subplots(1, 2, figsize=(1..."
          ],
          [
           "ax[i].set_title('degree = {0}'.format(degree), size=14)\n\nax[i].legend(loc='best')\n\nThis is a valuabl..."
          ],
          [
           "from sklearn.grid_search import GridSearchCV\n\nparam_grid = {'polynomialfeatures__degree': np.arange(..."
          ],
          [
           "Summary¶In this section, we have begun to explore the concept of model validation and hyperparameter..."
          ],
          [
           "Categorical Features¶One common type of non-numerical data is categorical data. For example, imagine..."
          ],
          [
           "vec = DictVectorizer(sparse=False, dtype=int)\n\nvec.fit_transform(data)\n\nOut[3]:\n\narray([[     0,    ..."
          ],
          [
           "Text Features¶Another common need in feature engineering is to convert text to a set of representati..."
          ],
          [
           "0\n\n0\n\n0\n\n1\n\n2\n\n0\n\n1\n\n0\n\n1\n\n0\n\nThere are some issues with this approach, however: the raw word counts..."
          ],
          [
           "0.605349\n\n0.000000\n\nFor an example of using TF-IDF in a classification problem, see In Depth: Naive ..."
          ],
          [
           "yfit = model.predict(X)\n\nplt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nIt's clear that we need a more sophi..."
          ],
          [
           "In [14]:\n\nfrom numpy import nan X = np.array([[ nan, 0,   3  ], [ 3,   7,   9  ], [ 3,   5,   2  ], ..."
          ],
          [
           "array([ 13.14869292,  14.3784627 ,  -1.15539732,  10.96606197,  -5.33782027])\n\nFeature Pipelines¶Wit..."
          ],
          [
           "In Depth: Naive Bayes Classification | Python Data Science Handbook\n\nPython Data Science Handbook\n\nA..."
          ],
          [
           "Bayesian Classification¶Naive Bayes classifiers are built on Bayesian classification methods. These ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import numpy as np import matplotlib.pyplot as plt import seaborn as sns..."
          ],
          [
           "model = GaussianNB()\n\nmodel.fit(X, y);\n\nNow let's generate some new data and predict the label:\n\nIn ..."
          ],
          [
           "The columns give the posterior probabilities of the first and second label, respectively. If you are..."
          ],
          [
           "windows.misc',\n\n'comp.sys.ibm.pc.hardware',\n\n'comp.sys.mac.hardware',\n\n'comp.windows.x',\n\n'misc.fors..."
          ],
          [
           "Fact or rumor....? Madalyn Murray O'Hare an atheist who eliminated the use of the bible reading and ..."
          ],
          [
           "Evidently, even this very simple classifier can successfully separate space talk from computer talk,..."
          ],
          [
           "They are extremely fast for both training and prediction They provide straightforward probabilistic ..."
          ],
          [
           "In Depth: Linear Regression\n\n< In Depth: Naive Bayes Classification | Contents | In-Depth: Support V..."
          ],
          [
           "model = LinearRegression(fit_intercept=True)\n\nmodel.fit(x[:, np.newaxis], y)\n\nxfit = np.linspace(0, ..."
          ],
          [
           "model.fit(X, y)\n\nprint(model.intercept_)\n\nprint(model.coef_)\n\n0.5 [ 1.5 -2. 1. ]\n\nHere the $y$ data ..."
          ],
          [
           "Polynomial basis functions¶This polynomial projection is useful enough that it is built into Scikit-..."
          ],
          [
           "plt.plot(xfit, yfit);\n\nOur linear model, through the use of 7th-order polynomial basis functions, ca..."
          ],
          [
           "def transform(self, X): return self._gauss_basis(X[:, :, np.newaxis], self.centers_, self.width_, ax..."
          ],
          [
           "plt.xlim(0, 10)\n\nplt.ylim(\n\n1.5, 1.5);\n\nWith the data projected to the 30-dimensional basis, the mod..."
          ],
          [
           "Ridge regression ($L_2$ Regularization)¶Perhaps the most common form of regularization is known as r..."
          ],
          [
           "from sklearn.linear_model import Lasso\n\nmodel = make_pipeline(GaussianFeatures(30), Lasso(alpha=0.00..."
          ],
          [
           "o FremontBridge.csv https://data.seattle.gov/api/views/65db\n\nxm6k/rows.csv?accessType=DOWNLOAD\n\nIn [..."
          ],
          [
           "We also might suspect that the hours of daylight would affect how many people ride; let's use the st..."
          ],
          [
           "daily = daily.join(weather[['PRCP', 'Temp (C)', 'dry day']])\n\nFinally, let's add a counter that incr..."
          ],
          [
           "13.60\n\n1.0\n\n0.002740\n\n2012\n\n10\n\n05\n\n3148.0\n\n0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n0.0\n\n11.161038\n\n0.0\n\n..."
          ],
          [
           "In [23]:\n\n# Drop any rows with null values daily.dropna(axis=0, how='any', inplace=True)\n\ncolumn_nam..."
          ],
          [
           "These numbers are difficult to interpret without some measure of their uncertainty. We can compute t..."
          ],
          [
           "We first see that there is a relatively stable trend in the weekly baseline: there are many more rid..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom scipy import ..."
          ],
          [
           "In [3]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plt.plo..."
          ],
          [
           "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]: yfit = m * xfit + b plt.plot(x..."
          ],
          [
           "To better visualize what's happening here, let's create a quick convenience function that will plot ..."
          ],
          [
           "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plot_svc_decision_function(model);\n\nThis is ..."
          ],
          [
           "ax = ax or plt.gca() ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') ax.set_xlim(-1, 4) ax.se..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets.samples_generator import make_circles X, y = make_circles(100, facto..."
          ],
          [
           "90, 90], azip=(\n\n180, 180),\n\nX=fixed(X), y=fixed(y));\n\nWe can see that with this additional dimensio..."
          ],
          [
           "max_iter=\n\n1, probability=False, random_state=None, shrinking=True,\n\ntol=0.001, verbose=False)\n\nIn [..."
          ],
          [
           "In [17]:\n\nX, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.8)\n\nfig, ax = pl..."
          ],
          [
           "faces = fetch_lfw_people(min_faces_per_person=60)\n\nprint(faces.target_names)\n\nprint(faces.images.sha..."
          ],
          [
           "For the sake of testing our classifier output, we will split the data into a training and testing se..."
          ],
          [
           "yfit = model.predict(Xtest)\n\nLet's take a look at a few of the test images along with their predicte..."
          ],
          [
           "avg / total       0.85      0.85      0.85       337\n\nWe might also display the confusion matrix bet..."
          ],
          [
           "However, SVMs have several disadvantages as well:\n\nThe scaling with the number of samples $N$ is $\\m..."
          ],
          [
           "In-Depth: Decision Trees and Random Forests\n\n< In-Depth: Support Vector Machines | Contents | In Dep..."
          ],
          [
           "Creating a decision tree¶Consider the following two-dimensional data, which has one of four class la..."
          ],
          [
           "In [4]:\n\ndef visualize_classifier(model, X, y, ax=None, cmap='rainbow'): ax = ax or plt.gca()\n\n# Plo..."
          ],
          [
           "If you're running this notebook live, you can use the helpers script included in The Online Appendix..."
          ],
          [
           "Just as using information from two trees improves our results, we might expect that using informatio..."
          ],
          [
           "In [9]:\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estim..."
          ],
          [
           "from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(200)\n\nforest.fit(..."
          ],
          [
           "# plot the digits: each image is 8x8 pixels for i in range(64): ax = fig.add_subplot(8, 8, i + 1, xt..."
          ],
          [
           "avg / total       0.98      0.98      0.98       450\n\nAnd for good measure, plot the confusion matri..."
          ],
          [
           "In Depth: Principal Component Analysis\n\n< In-Depth: Decision Trees and Random Forests | Contents | I..."
          ],
          [
           "By eye, it is clear that there is a nearly linear relationship between the x and y variables. This i..."
          ],
          [
           "# plot data plt.scatter(X[:, 0], X[:, 1], alpha=0.2) for length, vector in zip(pca.explained_varianc..."
          ],
          [
           "The transformed data has been reduced to a single dimension. To understand the effect of this dimens..."
          ],
          [
           "In [10]:\n\npca = PCA(2)  # project from 64 to 2 dimensions projected = pca.fit_transform(digits.data)..."
          ],
          [
           "What do the components mean?¶We can go a bit further here, and begin to ask what the reduced dimensi..."
          ],
          [
           "But the pixel-wise representation is not the only choice of basis. We can also use other basis funct..."
          ],
          [
           "plt.xlabel('number of components')\n\nplt.ylabel('cumulative explained variance');\n\nThis curve quantif..."
          ],
          [
           "In [14]:\n\nnp.random.seed(42)\n\nnoisy = np.random.normal(digits.data, 4)\n\nplot_digits(noisy)\n\nIt's cle..."
          ],
          [
           "Let's take a look at the principal axes that span this dataset. Because this is a large dataset, we ..."
          ],
          [
           "In [20]:\n\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\n\nplt.xlabel('number of components')\n\npl..."
          ],
          [
           "dim\\ninput')\n\nax[1, 0].set_ylabel('150\n\ndim\\nreconstruction');\n\nThe top row here shows the input ima..."
          ],
          [
           "RandomizedPCA, which we saw earlier, uses a non-deterministic method to quickly approximate the firs..."
          ],
          [
           "In\n\nDepth: Manifold Learning\n\n< In Depth: Principal Component Analysis | Contents | In Depth: k-Mean..."
          ],
          [
           "In [2]:\n\ndef make_hello(N=1000, rseed=42): # Make a plot with \"HELLO\" text; save as PNG fig, ax = pl..."
          ],
          [
           "The output is two dimensional, and consists of points drawn in the shape of the word, \"HELLO\". This ..."
          ],
          [
           "Out[5]:\n\n(1000, 1000)\n\nAs promised, for our N=1,000 points, we obtain a 1000×1000 matrix, which can ..."
          ],
          [
           "The MDS algorithm recovers one of the possible two-dimensional coordinate representations of our dat..."
          ],
          [
           "This is essentially the goal of a manifold learning estimator: given high-dimensional embedded data,..."
          ],
          [
           "In [14]:\n\nfrom sklearn.manifold import MDS model = MDS(n_components=2, random_state=2) outS = model...."
          ],
          [
           "In [15]:\n\nfrom sklearn.manifold import LocallyLinearEmbedding model = LocallyLinearEmbedding(n_neigh..."
          ],
          [
           "With all that on the table, the only clear advantage of manifold learning methods over PCA is their ..."
          ],
          [
           "faces = fetch_lfw_people(min_faces_per_person=30)\n\nfaces.data.shape\n\nOut[16]:\n\n(2370, 2914)\n\nWe have..."
          ],
          [
           "In [19]:\n\nfrom sklearn.manifold import Isomap\n\nmodel = Isomap(n_components=2)\n\nproj = model.fit_tran..."
          ],
          [
           "Calling this function now, we see the result:\n\nIn [21]:\n\nfig, ax = plt.subplots(figsize=(10, 10)) pl..."
          ],
          [
           "This gives us an idea of the variety of handwriting styles in the dataset. Let's compute a manifold ..."
          ],
          [
           "The result gives you an idea of the variety of forms that the number \"1\" can take within the dataset..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import matplotlib.pyplot as plt import seaborn as sns; sns.set()  # for ..."
          ],
          [
           "Let's visualize the results by plotting the data colored by these labels. We will also plot the clus..."
          ],
          [
           "Guess some cluster centers Repeat until converged E-Step: assign points to the nearest cluster cente..."
          ],
          [
           "# 2c. Check for convergence if np.all(centers == new_centers): break centers = new_centers\n\nreturn c..."
          ],
          [
           "Whether the result is meaningful is a question that is difficult to answer definitively; one approac..."
          ],
          [
           "In [10]:\n\nfrom sklearn.cluster import SpectralClustering model = SpectralClustering(n_clusters=2, af..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.data.shape\n\nOut[1..."
          ],
          [
           "Now we can check how accurate our unsupervised clustering was in finding similar digits within the d..."
          ],
          [
           "# Compute the clusters\n\nkmeans = KMeans(n_clusters=10, random_state=0)\n\nclusters = kmeans.fit_predic..."
          ],
          [
           "In [19]:\n\nchina.shape\n\nOut[19]:\n\n(427, 640, 3)\n\nOne way we can view this set of pixels is as a cloud..."
          ],
          [
           "fig.suptitle(title, size=20);\n\nIn [22]:\n\nplot_pixels(data, title='Input color space: 16 million poss..."
          ],
          [
           "Some detail is certainly lost in the rightmost panel, but the overall image is still easily recogniz..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import matplotlib.pyplot as plt import seaborn as sns; sns.set() import ..."
          ],
          [
           "From an intuitive standpoint, we might expect that the clustering assignment for some points is more..."
          ],
          [
           "In [5]:\n\nkmeans = KMeans(n_clusters=4, random_state=0)\n\nplot_kmeans(kmeans, X)\n\nAn important observa..."
          ],
          [
           "Generalizing E–M: Gaussian Mixture Models¶A Gaussian mixture model (GMM) attempts to find a mixture ..."
          ],
          [
           "Under the hood, a Gaussian mixture model is very similar to k-means: it uses an expectation–maximiza..."
          ],
          [
           "# Draw the Ellipse for nsig in range(1, 4): ax.add_patch(Ellipse(position, nsig * width, nsig * heig..."
          ],
          [
           "This makes clear that GMM addresses the two main practical issues with k-means encountered before.\n\n..."
          ],
          [
           "If we try to fit this with a two-component GMM viewed as a clustering model, the results are not par..."
          ],
          [
           "plt.scatter(Xnew[:, 0], Xnew[:, 1]);\n\nGMM is convenient as a flexible means of modeling an arbitrary..."
          ],
          [
           "The optimal number of clusters is the value that minimizes the AIC or BIC, depending on which approx..."
          ],
          [
           "We have nearly 1,800 digits in 64 dimensions, and we can build a GMM on top of these to generate mor..."
          ],
          [
           "data_new = gmm.sample(100, random_state=0)\n\ndata_new.shape\n\nOut[23]:\n\n(100, 41)\n\nFinally, we can use..."
          ],
          [
           "In\n\nDepth: Kernel Density Estimation\n\n< In Depth: Gaussian Mixture Models | Contents | Application: ..."
          ],
          [
           "x = rand.randn(N)\n\nx[int(f\n\nN):] += 5\n\nreturn x\n\nx = make_data(1000)\n\nWe have previously seen that t..."
          ],
          [
           "In [5]:\n\nx = make_data(20)\n\nbins = np.linspace(\n\n5, 10, 10)\n\nIn [6]:\n\nfig, ax = plt.subplots(1, 2, f..."
          ],
          [
           "Out[7]:\n\n(\n\n0.2, 8)\n\nThe problem with our two binnings stems from the fact that the height of the bl..."
          ],
          [
           "plt.fill_between(x_d, density, alpha=0.5)\n\nplt.plot(x, np.full_like(x,\n\n0.1), '|k', markeredgewidth=..."
          ],
          [
           "In [10]:\n\nfrom sklearn.neighbors import KernelDensity\n\n# instantiate and fit the KDE model kde = Ker..."
          ],
          [
           "Out[10]:\n\n(\n\n0.02, 0.22)\n\nThe result here is normalized such that the area under the curve is equal ..."
          ],
          [
           "{'bandwidth': bandwidths},\n\ncv=LeaveOneOut(len(x)))\n\ngrid.fit(x[:, None]);\n\nNow we can find the choi..."
          ],
          [
           "With this data loaded, we can use the Basemap toolkit (mentioned previously in Geographic Data with ..."
          ],
          [
           "In [15]:\n\n# Set up the data grid for the contour plot X, Y = np.meshgrid(xgrid[::5], ygrid[::5][::-1..."
          ],
          [
           "# plot contours of the density levels = np.linspace(0, Z.max(), 25) axi.contourf(X, Y, Z, levels=lev..."
          ],
          [
           "In [16]:\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\nclass KDEClassifier(BaseEstimator..."
          ],
          [
           "Parameters ---------- bandwidth : float the kernel bandwidth within each class kernel : str the kern..."
          ],
          [
           "Here we find the unique classes in the training data, train a KernelDensity model for each class, an..."
          ],
          [
           "In [17]:\n\nfrom sklearn.datasets import load_digits\n\nfrom sklearn.grid_search import GridSearchCV\n\ndi..."
          ],
          [
           "Out[19]:\n\n0.81860038035501381\n\nOne benefit of such a generative classifier is interpretability of re..."
          ],
          [
           "Application: A Face Detection Pipeline\n\n< In-Depth: Kernel Density Estimation | Contents | Further M..."
          ],
          [
           "HOG Features¶The Histogram of Gradients is a straightforward feature extraction procedure that was d..."
          ],
          [
           "Obtain a set of image thumbnails of faces to constitute \"positive\" training samples. Obtain a set of..."
          ],
          [
           "In [5]:\n\nfrom sklearn.feature_extraction.image import PatchExtractor\n\ndef extract_patches(img, N, sc..."
          ],
          [
           "from itertools import chain\n\nX_train = np.array([feature.hog(im)\n\nfor im in chain(positive_patches,\n..."
          ],
          [
           "In [10]:\n\nfrom sklearn.svm import LinearSVC from sklearn.grid_search import GridSearchCV grid = Grid..."
          ],
          [
           "test_image = skimage.transform.rescale(test_image, 0.5)\n\ntest_image = test_image[:160, 40:180]\n\nplt...."
          ],
          [
           "In [16]:\n\nfig, ax = plt.subplots()\n\nax.imshow(test_image, cmap='gray')\n\nax.axis('off')\n\nNi, Nj = pos..."
          ],
          [
           "In fact, the sliding_window() utility used here is already built with this in mind. We should combin..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "General Machine Learning¶Of course, machine learning is much broader than just the Python world. The..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport seaborn as ..."
          ],
          [
           "x, y = xy\n\nif 1 in edges: ax.plot([x, x + size], [y + size, y + size], **kwargs) if 2 in edges: ax.p..."
          ],
          [
           "label_kwargs = {}\n\nax.text(x + 0.5\n\nsize, y + 0.5\n\nsize, label,\n\nha='center', va='center', *\n\nlabel_..."
          ],
          [
           "draw_cube(ax, (12, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '5', **solid) draw_cube(ax, (13, 10), 1, de..."
          ],
          [
           "draw_cube(ax, (1, 6.5), 1, depth, [2, 3, 4], '1', **solid) draw_cube(ax, (2, 6.5), 1, depth, [2, 3],..."
          ],
          [
           "draw_cube(ax, (6, 5.5), 1, depth, [2, 3, 4, 7, 8, 10, 11, 12], '0', **dotted) draw_cube(ax, (7, 5.5)..."
          ],
          [
           "ax.text(5, 7.0, '+', size=12, ha='center', va='center') ax.text(10.5, 7.0, '=', size=12, ha='center'..."
          ],
          [
           "draw_cube(ax, (3, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted) draw_cube(ax, (3, 2), 1, ..."
          ],
          [
           "# third block draw_cube(ax, (12, 3), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid) draw_cube(ax, (1..."
          ],
          [
           "ax.set_ylim(0.5, 12.5)\n\nfig.savefig('figures/02.05\n\nbroadcasting.png')\n\nAggregation and Grouping¶Fig..."
          ],
          [
           "# Create column labels for i in range(ncols - 1): plt.text(x + (i + 1.5) * dx, y + (nrows - 0.5) * d..."
          ],
          [
           "ax.axis('off')\n\ndraw_dataframe(df, [0, 0])\n\nfor y, ind in zip([3, 1, -1], 'ABC'): split = df[df.inde..."
          ],
          [
           "plt.annotate('', (3.8, 3.8), (3.2, 3.8), arrowprops=arrowprops) plt.annotate('', (3.8, 1.75), (3.2, ..."
          ],
          [
           "In [6]:\n\nfrom sklearn.datasets.samples_generator import make_blobs\n\nfrom sklearn.svm import SVC\n\n# c..."
          ],
          [
           "# plot points and model fig, ax = plt.subplots(figsize=(8, 6)) line_style = dict(levels = [-1.0, 0.0..."
          ],
          [
           "fig.savefig('figures/05.01\n\nclassification\n\n3.png')\n\nRegression Example Figures¶Figure Context The f..."
          ],
          [
           "# plot points in 3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.scatter(X[:, 0]..."
          ],
          [
           "regression\n\n2.png')\n\nRegression Example Figure 3¶\n\nIn [13]:\n\nfrom matplotlib.collections import Line..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='viridis', norm=pts.norm) ax[1].axis([-4, 4, -3, ..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Learned Cluster Labels')\n\nfig.savefig('figures/05.01\n\nclustering..."
          ],
          [
           "fig.savefig('figures/05.01\n\ndimesionality\n\n2.png')\n\nIntroducing Scikit\n\nLearn¶\n\nFeatures and Labels ..."
          ],
          [
           "2)\n\nfig.savefig('figures/05.02\n\nsamples\n\nfeatures.png')\n\nHyperparameters and Model Validation¶\n\nCros..."
          ],
          [
           "fig.savefig('figures/05.03\n\n5\n\nfold\n\nCV.png')\n\nOverfitting and Underfitting¶\n\nIn [24]:\n\nimport numpy..."
          ],
          [
           "ax[0].scatter(X.ravel(), y, s=40) ax[0].plot(xfit.ravel(), model1.predict(xfit), color='gray') ax[0]..."
          ],
          [
           "X2, y2 = make_data(10, rseed=42)\n\nax[0].scatter(X.ravel(), y, s=40, c='blue') ax[0].plot(xfit.ravel(..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40, c='blue') ax[1].plot(xfit.ravel(), model20.predict(xfit), color='g..."
          ],
          [
           "ax.text(0.15, 0.2, \"training score\", rotation=45, size=16, color='blue') ax.text(0.2, -0.05, \"valida..."
          ],
          [
           "fig, ax = plt.subplots() ax.plot(x, y1, lw=10, alpha=0.5, color='blue') ax.plot(x, y2, lw=10, alpha=..."
          ],
          [
           "from sklearn.datasets import make_blobs X, y = make_blobs(100, 2, centers=2, random_state=2, cluster..."
          ],
          [
           "fig.savefig('figures/05.05\n\ngaussian\n\nNB.png')\n\nLinear Regression¶Gaussian Basis Functions¶Figure Co..."
          ],
          [
           "LinearRegression())\n\ngauss_model.fit(x[:, np.newaxis], y)\n\nyfit = gauss_model.predict(xfit[:, np.new..."
          ],
          [
           "def visualize_tree(estimator, X, y, boundaries=True, xlim=None, ylim=None, ax=None): ax = ax or plt...."
          ],
          [
           "ax.plot([tree.threshold[i], tree.threshold[i]], ylim, '\n\nk', zorder=2)\n\nplot_boundaries(tree.childre..."
          ],
          [
           "def fit_randomized_tree(random_state=0):\n\nclf = DecisionTreeClassifier(max_depth=15)\n\ni = np.arange(..."
          ],
          [
           "text(ax, 0.5, 0.9, \"How big is\\nthe animal? \", 20) text(ax, 0.3, 0.6, \"Does the animal\\nhave horns? ..."
          ],
          [
           "text(ax, 0.66, 0.45, \"yes\", 12, alpha=0.4) text(ax, 0.79, 0.45, \"no\", 12, alpha=0.4)\n\nax.plot([0.3, ..."
          ],
          [
           "X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0)\n\nfor axi, depth in zip(..."
          ],
          [
           "In [38]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T pca = PCA(n..."
          ],
          [
           "fig.savefig('figures/05.09\n\nPCA\n\nrotation.png')\n\nDigits Pixel Components¶\n\nIn [39]:\n\ndef plot_pca_co..."
          ],
          [
           "for i in range(n_components): approx = approx + coefficients[i] * components[i] show(0, i + counter,..."
          ],
          [
           "digits\n\npca\n\ncomponents.png')\n\nManifold Learning¶\n\nLLE vs MDS Linkages¶\n\nIn [42]:\n\ndef make_hello(N=..."
          ],
          [
           "z = np.sign(t)\n\n(np.cos(t)\n\n1)\n\nreturn np.vstack((x, y, z)).T\n\nX = make_hello(1000) XS = make_hello_..."
          ],
          [
           "for axi, title, lines in zip(ax, titles, [lines_MDS, lines_LLE]): axi.scatter3D(XS[:, 0], XS[:, 1], ..."
          ],
          [
           "def make_ax(fig, gs):\n\nax = fig.add_subplot(gs)\n\nax.xaxis.set_major_formatter(plt.NullFormatter())\n\n..."
          ],
          [
           "# Finish iteration centers = new_centers ax1.text(0.95, 0.95, \"E-Step\", transform=ax1.transAxes, ha=..."
          ],
          [
           "def plot_points(X, labels, n_clusters): plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis'..."
          ],
          [
           "plt.xlim(\n\n4, 4)\n\nplt.ylim(\n\n2, 10)\n\nif frame % 3 == 1: plt.text(3.8, 9.5, \"1. Reassign points to ne..."
          ],
          [
           "# Draw the Ellipse for nsig in range(1, 4): ax.add_patch(Ellipse(position, nsig * width, nsig * heig..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          3.039576,
          4.208349,
          4.577313,
          3.177655,
          3.1163917,
          2.8447776,
          2.7645013,
          3.50026,
          2.7313995,
          -16.367151,
          -16.393837,
          3.1913717,
          2.830396,
          -16.365208,
          -16.379086,
          -16.355389,
          -16.319044,
          -16.372473,
          -16.386171,
          -16.379755,
          -16.37824,
          -16.38455,
          -16.383492,
          -16.356213,
          -7.3356943,
          -16.376125,
          -16.33606,
          -16.39213,
          -16.383133,
          -16.324448,
          -16.374,
          -16.356071,
          -16.36462,
          -16.422638,
          -16.43212,
          -16.423538,
          -16.413143,
          -16.436934,
          -16.411963,
          -7.3718038,
          -7.1211243,
          -7.309532,
          -7.3739085,
          -7.4180255,
          -7.2767625,
          -7.182943,
          2.815855,
          2.8980186,
          -5.9712133,
          2.7549655,
          3.1441836,
          -6.367231,
          -7.0302114,
          -6.923522,
          -6.8378477,
          -5.9111924,
          -5.594265,
          -5.657529,
          -6.27136,
          -6.747179,
          -5.5010347,
          -5.5825853,
          -5.4061007,
          -5.2403827,
          -4.9039087,
          -5.015534,
          -4.8939123,
          -4.817501,
          -4.8920374,
          -5.1240735,
          -5.1230187,
          -5.693029,
          -7.0487247,
          -5.512578,
          -5.4157495,
          -5.446766,
          -5.3719964,
          -5.361188,
          -5.3391786,
          -5.2529655,
          -4.862535,
          -5.225976,
          -5.364981,
          -5.381425,
          -6.093698,
          -5.3603487,
          -5.787329,
          -5.318757,
          -2.4039814,
          -5.330644,
          -4.7678504,
          -4.619522,
          -4.667309,
          -4.711632,
          -4.93665,
          -4.736365,
          2.7837908,
          -4.59226,
          -4.621208,
          -5.2802825,
          -5.3309336,
          -5.23173,
          -4.942885,
          -4.9495363,
          -4.9568434,
          -4.486086,
          -5.4811997,
          -5.469284,
          -5.4299936,
          -5.188946,
          -5.0039935,
          -5.459836,
          -5.370263,
          -5.24425,
          1.1598564,
          1.1626952,
          -5.8710084,
          -5.9519696,
          -5.686736,
          -5.3811245,
          -5.329047,
          -4.7780952,
          -5.1025677,
          -4.466018,
          -6.23918,
          -6.4822345,
          -7.218984,
          -7.580875,
          -7.6638236,
          -7.2998986,
          -6.9212575,
          -7.1756864,
          -5.5985394,
          2.7407844,
          2.954454,
          3.815159,
          -10.050647,
          -9.90207,
          -10.463712,
          -10.2144575,
          -10.556915,
          -10.700669,
          -10.530831,
          -9.019662,
          -9.869233,
          -9.09503,
          -9.946284,
          -9.505863,
          -10.065254,
          -10.11127,
          -10.032046,
          -10.758973,
          -10.691069,
          -10.79758,
          -2.2931426,
          -10.4311075,
          -10.300989,
          -11.209564,
          -10.751745,
          -8.39221,
          -7.26733,
          -8.999085,
          -8.178694,
          -7.2510896,
          -8.077155,
          -8.126005,
          3.0352318,
          -8.324122,
          -8.028691,
          -6.704988,
          -5.9072003,
          -8.098927,
          -8.349961,
          -8.268196,
          -8.411301,
          -8.304311,
          -8.355919,
          -8.476299,
          -10.73184,
          -10.799562,
          -10.581669,
          -10.539392,
          -10.554041,
          -10.669805,
          -10.127146,
          -9.995236,
          -9.784302,
          -10.495088,
          -10.32636,
          -9.534914,
          -9.81618,
          -9.825398,
          -10.185999,
          -11.0048685,
          -9.936047,
          -2.6865613,
          -9.0267515,
          -16.7556,
          -16.610716,
          -16.64143,
          -16.728424,
          -16.686602,
          -16.69598,
          -16.637863,
          -16.881199,
          -16.741724,
          -16.712784,
          -16.652077,
          -16.531723,
          -17.19686,
          -17.692024,
          -17.600016,
          -17.58467,
          -17.616657,
          -17.812634,
          -17.672691,
          -17.72532,
          -17.688822,
          -17.730766,
          -17.571983,
          -17.59585,
          -17.67709,
          -17.657787,
          -17.212803,
          -11.784887,
          -11.743601,
          -11.552375,
          -11.748808,
          -11.63261,
          -11.689146,
          -11.610627,
          -11.632569,
          -3.8363142,
          -4.3986015,
          -4.1313562,
          -3.8794916,
          -4.7868137,
          -5.418858,
          -5.4798183,
          -4.7497606,
          -4.046501,
          -3.5423484,
          -4.166466,
          -5.831788,
          -5.929284,
          -5.7445297,
          -5.9986987,
          -5.7137427,
          -5.6211305,
          -5.765331,
          -4.0264235,
          -3.9236875,
          -2.5918424,
          -2.1994395,
          -2.3995466,
          -2.2200427,
          -2.1633716,
          -2.4267397,
          -2.1436665,
          -2.2832532,
          -1.322465,
          -1.3591602,
          -1.1271319,
          -1.1441618,
          -1.1708419,
          -7.909289,
          -8.078761,
          -8.18788,
          -8.251767,
          -8.071782,
          -8.222334,
          -7.956809,
          -7.9229283,
          -7.6611013,
          -7.687033,
          -7.847221,
          -7.800834,
          -7.85576,
          -2.8891094,
          -2.8973413,
          -2.8836987,
          -2.910792,
          -2.8849294,
          -2.9068577,
          -2.8991053,
          -2.8888056,
          -2.900309,
          -2.9243238,
          -2.9064505,
          -2.8894997,
          -2.7736568,
          -2.8956103,
          -2.8105974,
          -2.7036047,
          -2.5288706,
          -2.5092666,
          -2.7255487,
          -2.7107038,
          -2.4911125,
          -2.4439604,
          -2.4798834,
          -2.4888937,
          -2.3866906,
          -6.814055,
          -5.514587,
          -6.925398,
          -6.5185943,
          -6.804461,
          -7.00449,
          -7.4274845,
          -6.8231883,
          -7.1251955,
          -6.736983,
          -2.8565087,
          2.9678917,
          2.3131278,
          2.4009955,
          2.6914437,
          2.6900048,
          2.1454368,
          2.4217625,
          2.603824,
          2.4744625,
          3.5716026,
          2.5387676,
          2.9302747,
          3.2080212,
          2.3620124,
          2.9127593,
          3.2169545,
          2.4199882,
          2.956318,
          2.7784324,
          1.8224478,
          1.843045,
          2.7639806,
          9.904792,
          9.287211,
          3.1181257,
          3.2331173,
          3.3486242,
          2.6059887,
          1.2530053,
          1.3275776,
          1.4331411,
          1.7458508,
          3.2849267,
          3.5326047,
          4.6519084,
          4.3296394,
          3.705362,
          3.1456437,
          3.626397,
          3.537348,
          3.356201,
          3.45246,
          6.7657204,
          2.107591,
          2.2046802,
          1.8979115,
          2.0456455,
          1.8364706,
          -0.12587008,
          -0.54348326,
          0.028282033,
          1.9264382,
          1.8259851,
          0.7473771,
          5.8214126,
          0.06319833,
          1.6500618,
          1.7464949,
          1.5069867,
          1.8494436,
          1.9253116,
          1.5904493,
          1.4129659,
          1.9422014,
          1.80276,
          2.6743479,
          2.783634,
          2.9079173,
          2.7361095,
          3.137024,
          3.2199554,
          3.0529726,
          3.2017343,
          3.1813447,
          3.1425648,
          3.2609622,
          4.878796,
          5.021824,
          5.02818,
          4.9995365,
          5.011786,
          5.029718,
          5.030629,
          5.106475,
          4.9706416,
          4.742617,
          -2.569795,
          4.4662027,
          2.339741,
          2.3432884,
          1.6103889,
          0.9744774,
          -1.477712,
          -1.14496,
          -3.7299237,
          -3.136957,
          -2.8161535,
          -2.115147,
          -2.0563834,
          -1.9980294,
          -1.8666924,
          -1.4678344,
          -1.9687991,
          2.2793581,
          1.9699732,
          4.486499,
          3.1555507,
          4.5044036,
          5.3797593,
          6.6962333,
          5.8643894,
          6.257454,
          5.52911,
          5.515251,
          4.5141573,
          6.608136,
          6.5322967,
          7.323293,
          7.6612835,
          5.9992604,
          8.158582,
          8.712187,
          7.963087,
          7.0966434,
          7.165013,
          7.4960556,
          7.0921793,
          7.076949,
          7.655387,
          7.8613358,
          8.066789,
          8.186802,
          8.833748,
          9.014938,
          9.229443,
          8.994746,
          8.951823,
          10.300544,
          9.539699,
          9.45414,
          9.53951,
          9.2806015,
          9.372848,
          9.474445,
          9.413462,
          9.073361,
          5.3737617,
          5.9635844,
          5.773839,
          5.769924,
          5.784484,
          6.0608225,
          8.983141,
          -8.305562,
          8.6240015,
          5.7424173,
          6.401625,
          6.8959336,
          7.274136,
          6.2669187,
          5.5934553,
          5.757017,
          5.8657146,
          6.324541,
          8.665721,
          9.034128,
          9.02794,
          9.298338,
          9.144282,
          9.201565,
          9.562113,
          9.807167,
          9.520118,
          -2.5085824,
          -2.5026212,
          -2.5415611,
          -2.3797596,
          -2.4876206,
          -2.649127,
          -2.4078166,
          7.547396,
          8.445139,
          8.989589,
          9.431693,
          9.127229,
          9.003909,
          8.90107,
          8.904153,
          9.035305,
          8.919603,
          7.2830625,
          8.336784,
          7.8109283,
          7.563616,
          9.045558,
          11.358884,
          11.709457,
          11.54424,
          11.657394,
          11.163075,
          10.375957,
          10.773178,
          7.326265,
          9.713299,
          5.42195,
          5.8802266,
          5.750723,
          5.8802977,
          6.300333,
          5.7947493,
          5.909117,
          5.9242563,
          6.134131,
          5.8578744,
          5.929887,
          5.6642365,
          5.3334274,
          5.4106727,
          6.138678,
          6.293905,
          5.4287324,
          5.479134,
          5.2858377,
          5.4602995,
          5.5406594,
          5.3732677,
          5.6141777,
          6.5634365,
          5.891021,
          6.780369,
          6.8746376,
          8.3312845,
          8.294914,
          8.181401,
          8.12436,
          8.417258,
          8.304659,
          8.201493,
          7.2863197,
          8.128581,
          3.6138134,
          7.969902,
          8.0803795,
          8.142123,
          8.378899,
          8.255555,
          7.9186387,
          7.9662194,
          7.68726,
          7.9097505,
          7.6736455,
          7.751917,
          7.6801853,
          7.4642725,
          7.099341,
          7.37266,
          1.2360332,
          1.2046509,
          1.4273689,
          1.5987136,
          7.673109,
          7.5788794,
          7.605093,
          4.852217,
          5.217043,
          6.781212,
          7.4747853,
          7.7413807,
          7.4383616,
          8.021871,
          7.137298,
          7.1246367,
          6.9936943,
          7.2911487,
          7.28505,
          7.5009866,
          7.599499,
          7.2366753,
          7.203854,
          7.03053,
          4.2954364,
          4.4712543,
          5.761098,
          5.9280033,
          5.916987,
          5.9955807,
          5.9113917,
          5.913558,
          5.9666457,
          5.9695773,
          5.9556746,
          5.3104005,
          5.6474295,
          5.401668,
          9.3856535,
          9.154211,
          9.385621,
          9.4018345,
          6.0190415,
          9.422914,
          7.689447,
          7.4483576,
          8.969237,
          9.422769,
          9.619329,
          9.426686,
          9.546285,
          9.481246,
          9.485853,
          9.51713,
          7.1718326,
          9.7409,
          11.1986,
          11.389642,
          11.56872,
          11.548535,
          5.6314745,
          11.615642,
          11.586182,
          6.33698,
          6.45315,
          6.436432,
          6.386689,
          6.604606,
          7.4334316,
          6.394336,
          8.0120325,
          7.4976482,
          7.5897956,
          6.6079535,
          4.580429
         ],
         "xaxis": "x",
         "y": [
          -6.6663046,
          -6.153275,
          -5.9703574,
          -6.81377,
          -6.778126,
          -7.033234,
          -7.094472,
          -6.5335207,
          -7.118231,
          10.479329,
          10.508723,
          -6.641513,
          -7.0074964,
          10.4805565,
          10.496414,
          10.471116,
          10.4350605,
          10.485853,
          10.49869,
          10.493714,
          10.493886,
          10.5002365,
          10.500558,
          10.469327,
          -2.3516583,
          10.489849,
          10.451321,
          10.510951,
          10.493042,
          10.434387,
          10.48467,
          10.46782,
          10.477702,
          10.543339,
          10.555505,
          10.545432,
          10.535405,
          10.560198,
          10.532044,
          -2.4275205,
          -2.4634044,
          -2.333366,
          -2.4864717,
          -2.5419588,
          -2.380157,
          -2.2728872,
          -6.967413,
          -6.982259,
          -0.86119866,
          -7.0607533,
          -6.677703,
          -0.79209876,
          -0.98032457,
          -1.3278604,
          -0.94031376,
          -1.4456927,
          -1.6755158,
          -1.1350994,
          -1.1241202,
          -0.6248845,
          -1.4606462,
          -1.5316763,
          -1.8601953,
          -1.8644335,
          -1.857777,
          -1.7828709,
          -1.6605079,
          -1.8436753,
          -1.3433405,
          -1.8506826,
          -1.8774563,
          0.20863426,
          -1.7009231,
          0.647916,
          0.7265321,
          0.78279346,
          0.8415709,
          0.1335371,
          0.67637426,
          0.6898406,
          0.48103768,
          0.2317965,
          0.44277832,
          0.9564672,
          -0.49429703,
          1.2493719,
          1.1653664,
          1.6743547,
          4.3750153,
          0.18437353,
          -0.56582296,
          -0.9623851,
          -0.91335934,
          -0.86436206,
          -0.18646096,
          -0.36405262,
          3.2712345,
          2.1463046,
          2.1898918,
          1.6449279,
          1.2841392,
          1.5854614,
          1.9515839,
          1.8390204,
          1.9254757,
          2.4452896,
          1.4363711,
          1.5771848,
          -1.8326478,
          -1.5895098,
          -1.7143342,
          -1.9459994,
          -1.9529222,
          -0.08451703,
          3.4227712,
          3.4278154,
          -1.5109426,
          -1.8409178,
          -1.9329666,
          -1.937922,
          -2.1289618,
          -2.1973364,
          -2.4148507,
          -2.677671,
          -1.8979027,
          -1.0599736,
          0.14681791,
          0.7956589,
          1.2710016,
          -0.31855083,
          -0.67317396,
          -0.2911253,
          -0.54518294,
          -7.032348,
          -6.782051,
          -6.320948,
          1.1068407,
          1.1319886,
          1.1447552,
          1.1141589,
          0.9941297,
          1.0759041,
          1.014446,
          1.0440906,
          0.9495631,
          0.36268735,
          0.75741404,
          1.2384063,
          1.2044489,
          1.156155,
          0.9699598,
          0.96397066,
          0.95277864,
          0.8086761,
          4.7132897,
          0.8861208,
          0.8936649,
          0.62054616,
          0.90046316,
          1.2449808,
          0.44668424,
          1.1685197,
          1.1289562,
          1.5031883,
          1.4693048,
          1.2516109,
          -6.1036654,
          0.8919292,
          0.6143288,
          0.99303997,
          0.37275946,
          0.9138576,
          0.87310535,
          0.95259666,
          0.8048672,
          0.8733223,
          0.95616865,
          0.79537296,
          0.68791866,
          0.22188868,
          0.39331427,
          0.28267762,
          0.34467283,
          0.1643537,
          0.20241755,
          0.30258402,
          0.38917977,
          0.4528377,
          0.30835298,
          0.40521967,
          0.4482839,
          0.45879397,
          0.45081732,
          0.34124658,
          0.33885616,
          4.768475,
          0.50131917,
          -3.9330592,
          -3.8798268,
          -3.89601,
          -3.9313502,
          -3.9132779,
          -3.9139884,
          -3.8952003,
          -3.9889297,
          -3.936246,
          -3.9231608,
          -3.8961668,
          -3.8356955,
          -4.0947785,
          -4.296927,
          -4.257081,
          -4.24981,
          -4.262513,
          -4.3418107,
          -4.283,
          -4.308222,
          -4.291291,
          -4.3075585,
          -4.24371,
          -4.258734,
          -4.284859,
          -4.2668147,
          -4.0817738,
          0.3705601,
          0.33295062,
          0.40009022,
          0.36831647,
          0.4424079,
          0.35423467,
          0.49443778,
          0.4719862,
          4.260056,
          3.6345878,
          3.8856466,
          4.206045,
          3.2050426,
          3.432418,
          3.3948371,
          3.8443244,
          4.068789,
          5.1630125,
          4.078593,
          3.2600493,
          3.286608,
          3.42356,
          3.2151775,
          3.4161065,
          3.4271977,
          3.3876662,
          4.19034,
          4.2004266,
          3.7475445,
          3.738783,
          3.8553095,
          4.021096,
          3.7942495,
          3.817548,
          3.9915588,
          4.663466,
          4.767893,
          5.008028,
          5.251986,
          5.156118,
          5.2358465,
          1.694245,
          2.2458262,
          2.317876,
          2.3037894,
          2.0993488,
          2.0060804,
          2.0265205,
          2.247844,
          2.3947468,
          2.26788,
          2.4836123,
          2.3538945,
          2.2650845,
          8.09969,
          8.257002,
          8.25575,
          8.263693,
          8.204033,
          8.259802,
          8.289659,
          8.178016,
          8.295394,
          8.335764,
          8.255528,
          8.132239,
          7.4919333,
          8.208903,
          7.675959,
          7.050876,
          6.83713,
          7.034973,
          7.216408,
          7.159236,
          5.6843743,
          5.9923887,
          6.2195873,
          6.048299,
          6.1741614,
          1.4060743,
          1.588084,
          2.2950647,
          2.152387,
          2.370456,
          2.263331,
          1.8533864,
          2.4331825,
          2.316402,
          2.11843,
          7.331884,
          -6.8262863,
          4.899089,
          4.858752,
          5.4020243,
          5.4668703,
          5.0800643,
          5.176606,
          5.5846457,
          4.5671,
          -6.458888,
          5.3096433,
          5.3795624,
          5.022605,
          5.7739034,
          5.7921767,
          5.2906213,
          4.2373447,
          4.3215213,
          4.012776,
          4.512886,
          3.138285,
          3.11259,
          -4.166879,
          -4.3408666,
          3.334679,
          3.3843822,
          3.6734834,
          3.557027,
          3.7208748,
          3.61154,
          3.370487,
          3.1695912,
          5.408083,
          5.3113685,
          3.4110827,
          4.3553514,
          5.505983,
          4.6565495,
          4.2633414,
          4.0942674,
          4.2011523,
          4.030042,
          -2.2926838,
          5.299282,
          5.755582,
          5.9483323,
          5.6644244,
          5.557208,
          5.1292405,
          5.2287064,
          5.537926,
          5.6424623,
          5.7832503,
          5.389659,
          2.054211,
          5.20384,
          5.7648354,
          5.8980007,
          5.9507327,
          5.861061,
          5.8979464,
          5.9483266,
          5.9296713,
          5.4687414,
          4.841824,
          5.2308064,
          5.1435094,
          5.206058,
          5.0011616,
          3.7155128,
          3.3609083,
          3.3350406,
          3.2265816,
          3.1473467,
          3.1484256,
          3.207599,
          4.137088,
          4.0871463,
          4.0797796,
          4.0054445,
          4.123612,
          4.0791755,
          4.101412,
          4.087406,
          4.1331573,
          3.6987553,
          4.6103244,
          3.997066,
          4.866103,
          5.1219044,
          4.1823974,
          3.8564134,
          4.4952073,
          4.55333,
          4.1803293,
          4.4806123,
          7.8728642,
          4.937449,
          5.0936027,
          4.8612103,
          4.7550535,
          4.687624,
          5.080199,
          5.1427217,
          4.7897525,
          -5.993731,
          -6.7376924,
          -5.9308167,
          -5.398746,
          -4.7047124,
          -5.0648465,
          -3.8058739,
          -4.293091,
          -2.7145493,
          -5.836136,
          -4.708064,
          -3.6938596,
          -4.4526772,
          -5.2784786,
          -5.1368504,
          -5.082143,
          -4.7799935,
          -5.3342614,
          -4.9911447,
          -4.069652,
          -2.0370998,
          -2.4853926,
          -2.5455565,
          -5.344844,
          -5.551121,
          -5.463568,
          -5.8640223,
          -5.5277877,
          -5.589536,
          -5.2977905,
          -4.2352333,
          -5.5759764,
          -6.2577224,
          -5.624677,
          -4.142617,
          -5.381966,
          -5.6880536,
          -5.7081957,
          -2.6161487,
          -5.3845115,
          -4.7178097,
          -5.4255857,
          -5.0632167,
          -4.962768,
          -4.9426928,
          -4.957664,
          -5.3625274,
          -4.0618453,
          0.60725224,
          -4.5463057,
          -5.4568357,
          -5.3762765,
          -5.0098867,
          -5.009673,
          -5.0040207,
          -5.132469,
          -5.049249,
          -5.2006364,
          -5.3031263,
          -4.446987,
          -4.3205237,
          -4.351839,
          -4.2691255,
          -4.093677,
          -4.0461097,
          -4.1220007,
          -5.6348934,
          -5.3528233,
          6.2889037,
          6.187645,
          5.9878235,
          6.145698,
          6.0570116,
          5.8947453,
          5.8077674,
          -4.2163553,
          -3.2744727,
          -3.4518747,
          -3.5989122,
          -3.493682,
          -3.5656366,
          -3.4743288,
          -3.5866442,
          -3.6050801,
          -3.594199,
          -6.5160637,
          -5.3638663,
          -5.7033663,
          -6.3912406,
          -5.190916,
          -5.9788604,
          -4.5672927,
          -4.250333,
          -4.8135514,
          -6.0060325,
          -5.7818813,
          -5.666555,
          -3.5842953,
          -5.682799,
          -2.964724,
          -2.510929,
          -2.3498797,
          -2.2997925,
          -2.2615979,
          -2.5846088,
          -2.18845,
          -2.1829922,
          -2.1909306,
          -2.08795,
          -1.9447243,
          -2.404212,
          -2.9968631,
          -2.7404099,
          1.0456574,
          -3.3679175,
          -2.9456198,
          -2.647835,
          -2.4304116,
          -2.4080021,
          -2.443002,
          -2.5030131,
          -2.3551493,
          -1.3797597,
          -2.4437215,
          -2.229507,
          -2.3901665,
          0.22806485,
          0.29741013,
          0.3150941,
          0.45520607,
          0.22021665,
          0.2447451,
          -0.022131827,
          -1.9832952,
          -0.2504792,
          3.9918888,
          0.23994547,
          -0.21519144,
          0.0803759,
          0.22696018,
          0.24253488,
          -0.36226165,
          -0.24750192,
          -0.08381686,
          -0.24935764,
          -0.6097302,
          -0.58385575,
          -0.86632746,
          -1.2806218,
          -1.8706486,
          -5.9102798,
          3.3980186,
          3.7226057,
          3.420287,
          3.3308232,
          -5.7067657,
          -6.022272,
          -5.954421,
          3.068812,
          2.3990846,
          -4.9077806,
          -5.932854,
          -5.7110963,
          -5.6875978,
          -5.699586,
          -6.1881213,
          -6.8061805,
          -7.045879,
          -7.010015,
          -7.0123997,
          -6.5678797,
          -6.569612,
          -7.1417217,
          -6.9377174,
          -7.1719394,
          -6.0918245,
          -6.1418843,
          1.9215796,
          1.8975849,
          2.0963373,
          2.1189106,
          2.177708,
          2.127869,
          2.0891676,
          2.125108,
          2.0996463,
          2.327291,
          2.0901713,
          2.2828312,
          -1.8930666,
          -2.9631824,
          -2.165259,
          -2.3033786,
          1.3963329,
          -2.3833992,
          0.25038552,
          -0.65878266,
          -1.8597238,
          -2.332224,
          -2.8007917,
          -2.1848373,
          -2.490389,
          -2.3051336,
          -2.249726,
          -2.0968237,
          0.24966462,
          -2.9560978,
          -4.1070523,
          -4.0185966,
          -4.262713,
          -4.094141,
          2.2118828,
          -4.21744,
          -4.3213577,
          -0.9296323,
          -0.79925364,
          -1.140429,
          -1.1922507,
          0.634035,
          0.5003838,
          0.9191382,
          0.2982804,
          0.4482951,
          0.108908415,
          0.2810934,
          -5.9345536
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay hello welcome to uh week 11's lecture uh it's been a little while since we\n\ntalked about some o..."
          ],
          [
           "all right and so uh what we're gonna do is we're gonna build our models off of this training set all..."
          ],
          [
           "you right here the answer is probably not right to a certain extent they they will but it's importan..."
          ],
          [
           "in a classification standpoint all right so we're doing all classification here i'll talk about regr..."
          ],
          [
           "outputs so the idea is that they're they can't they'll predict hard classes right these ones are zer..."
          ],
          [
           "think back to what i just said about the 75 25 scenario all right\n\nand let's be more discreet about ..."
          ],
          [
           "and true positive are good all right so we want these numbers here we've talked about this before to..."
          ],
          [
           "all the way up to all the way up to 100 right so now nothing is fraud\n\neverybody becomes rich throug..."
          ],
          [
           "this true positive true positive false negative i think we walked through this so i'm going to spend..."
          ],
          [
           "positive and false positive rate and those just become data points on a axis you just graph them\n\non..."
          ],
          [
           "all right what this means is that your your your classifier is contributing absolutely nothing right..."
          ],
          [
           "precision and recall okay it's particularly useful if you have unbalanced data sets right\n\nif you ha..."
          ],
          [
           "that wrong log loss takes that into account okay all right so if we see a log loss\n\nof one can be ex..."
          ],
          [
           "right but basically the way you calculate this is that you know say we had you know and that's good ..."
          ],
          [
           "substantial agreement so we've got two that agree here right that's how campo works it's just\n\nthat ..."
          ],
          [
           "so there's different metrics that you would use to assess a continuous variable right kind of in a r..."
          ],
          [
           "right but this is not going to be in the language of the dependent root mean squared error will be a..."
          ],
          [
           "i bring this up because it's associated with thresholding because if you want to adjust the threshol..."
          ],
          [
           "would see over here right all right this one here is going to have high bias\n\nokay it's going to be ..."
          ],
          [
           "this second white circle right but it is on target okay so we've introduced a bunch of\n\nconcept here..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week7-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          11.341541,
          11.594384,
          11.869741,
          12.026055,
          11.968558,
          11.897332,
          11.993067,
          11.936038,
          11.9411125,
          11.847492,
          11.937236,
          11.830659,
          11.942079,
          12.061202,
          12.14209,
          12.049467,
          11.682589,
          11.055296,
          11.165616,
          11.655713
         ],
         "xaxis": "x",
         "y": [
          -8.211438,
          -8.287862,
          -8.53222,
          -8.600857,
          -8.749706,
          -8.747798,
          -8.649298,
          -8.771586,
          -8.853851,
          -8.762725,
          -8.677511,
          -8.645315,
          -8.6703,
          -8.363583,
          -8.282194,
          -8.199857,
          -7.6316824,
          -7.1251574,
          -7.347524,
          -8.21426
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay all right so let me pop this up here\n\nbigger i can do that there we go all right so we've been ..."
          ],
          [
           "way and so here what we see this is our this is our root note up here all right this is the old clas..."
          ],
          [
           "what's your favorite music you know if you don't know this one i guess it depends on your your\n\nyour..."
          ],
          [
           "hurdle and now you're on to what music do you like right and so\n\nhere you know it might be that you ..."
          ],
          [
           "okay excuse me and then we get more specific right based off the type of\n\nmusic that people are inte..."
          ],
          [
           "the model is is built such that a sequence of ordered decisions concerning the value result and you ..."
          ],
          [
           "individual node those individual internal leaves okay all right\n\nand it will consider every possible..."
          ],
          [
           "tree all right it was first uh introduced here by 1984 with these four\n\nresearchers all right it can..."
          ],
          [
           "and then even when you get up to ensemble models with random force they also become a little a littl..."
          ],
          [
           "small variations in the data because of the nature of how they're how they're designed all right so\n..."
          ],
          [
           "compared to predict the class and these are the two common ones for classification they're really ve..."
          ],
          [
           "here so what we see here right it's just a total you know kind of one class example obviously we we ..."
          ],
          [
           "date which makes sense all right so they yes all right the people the no date uh stop right there al..."
          ],
          [
           "i guess it was pedal width right so at a certain numerical range 1.75\n\nor greater or was it less any..."
          ],
          [
           "that could be gained uh and specific to to the um this is the you know when on a date\n\ncategory so w..."
          ],
          [
           "right and then when we look across what we see is we have two nodes and one yes all right so it does..."
          ],
          [
           "when we do this weighted average obvious this is all going to be zero just like i said before it's g..."
          ],
          [
           "um you just have a you know a tree with the depth of just one split and that's it okay\n\nso that's en..."
          ],
          [
           "when we do when we did enthalpy here we see it's 0.5 which kind of represents a perfect\n\nsplit okay ..."
          ],
          [
           "variable at that particular split and then it will include the variable that reduces the mean square..."
          ],
          [
           "and one solution is we can tune those hyper parameters all right so another solution is built to ens..."
          ],
          [
           "are available all right are ones that have not been used uh anywhere higher all right\n\ninside the sp..."
          ],
          [
           "test is you know basically they compete against each other all right as the training set gets\n\nbigge..."
          ],
          [
           "okay so um let's take a look at overfitting all\n\nright um again uh we've talked about well you guys ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week9-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          12.064694,
          12.627394,
          12.935403,
          12.880381,
          12.542723,
          12.579493,
          12.326441,
          12.344388,
          11.397198,
          11.820726,
          12.597457,
          12.87492,
          12.9252405,
          12.636266,
          12.680161,
          12.887224,
          12.674423,
          12.787982,
          12.575473,
          12.32638,
          11.944366,
          12.278737,
          11.403662,
          11.6092
         ],
         "xaxis": "x",
         "y": [
          -6.40835,
          -7.098782,
          -7.2027926,
          -7.1849165,
          -6.79477,
          -7.0848117,
          -6.5828047,
          -6.769564,
          -6.416095,
          -6.3685117,
          -7.93104,
          -7.4431734,
          -7.5375385,
          -7.651556,
          -7.169082,
          -7.5459332,
          -7.9014597,
          -7.338873,
          -7.5656543,
          -7.033152,
          -6.5721807,
          -6.882689,
          -7.0542564,
          -6.6058097
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "What is a decision tree?"
          ]
         ],
         "hovertemplate": "source=User query<br>symbol=star<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "User query, star",
         "marker": {
          "color": "black",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           100
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "User query, star",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          12.151521
         ],
         "xaxis": "x",
         "y": [
          -6.1746836
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "itemsizing": "constant",
         "title": {
          "text": "<b>Chunk source</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>2D Projection of Chunk Embeddings via PaCMAP</b>"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vistualize pca projection\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"x\": documents_projected[i, 0],\n",
    "            \"y\": documents_projected[i, 1],\n",
    "            \"source\": docs_processed[i].metadata[\"source\"][\"source\"],#.split(\"/\")[1],\n",
    "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
    "            \"symbol\": \"circle\",\n",
    "            \"size_col\": 4,\n",
    "        }\n",
    "        for i in range(len(docs_processed))\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"x\": documents_projected[-1, 0],\n",
    "            \"y\": documents_projected[-1, 1],\n",
    "            \"source\": \"User query\",\n",
    "            \"extract\": user_query,\n",
    "            \"size_col\": 100,\n",
    "            \"symbol\": \"star\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the embedding\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"source\",\n",
    "    hover_data=\"extract\",\n",
    "    size=\"size_col\",\n",
    "    symbol=\"symbol\",\n",
    "    color_discrete_map={\"User query\": \"black\"},\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"<b>Chunk source</b>\",\n",
    "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
