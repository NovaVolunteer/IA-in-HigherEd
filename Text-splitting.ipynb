{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playing with chunking/embedding code from https://huggingface.co/learn/cookbook/advanced_rag on PythonDSHandbook.txt, Week7-lecture.txt, Week9-lecture.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from tqdm.notebook import tqdm #progress bar\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Tuple #type hinting\n",
    "# from datasets import Dataset #to load in premade example datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # This will be helpful when visualizing retriever outputs\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter #splitter\n",
    "\n",
    "#load in Documents\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter #alt import\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# embedding and searching\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "#plotting\n",
    "import pacmap\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKDOWN_SEPARATORS = [\n",
    "    \"\\n#{1,6} \",\n",
    "    \"```\\n\",\n",
    "    \"\\n\\\\*\\\\*\\\\*+\\n\",\n",
    "    \"\\n---+\\n\",\n",
    "    \"\\n___+\\n\",\n",
    "    \"\\n\\n\",\n",
    "    \"\\n\",\n",
    "    \" \",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:31<00:00, 22.85s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defdd05787d34ff8b51a67e472179e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load in docs (must be in IA-in-HigherEd dir)\n",
    "loader = DirectoryLoader('./RAG-docs/processed/', glob=\"**/*.txt\", show_progress = True) #all .txt files in processed folder\n",
    "docs = loader.load()\n",
    "docs\n",
    "\n",
    "# save as LC docs\n",
    "RAW_KNOWLEDGE_BASE = [\n",
    "    LangchainDocument(page_content=doc.page_content, metadata={\"source\": doc.metadata}) for doc in tqdm(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129d0a90ed784ab9b7cf34de3234b319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/827 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split (chunk) docs with chunk size <512\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base: List[LangchainDocument],\n",
    "    tokenizer_name: Optional[str] = EMBEDDING_MODEL_NAME,\n",
    ") -> List[LangchainDocument]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks of maximum size `chunk_size` tokens and return a list of documents.\n",
    "    \"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=int(chunk_size / 10),\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        separators=MARKDOWN_SEPARATORS,\n",
    "    )\n",
    "\n",
    "    docs_processed = []\n",
    "    for doc in knowledge_base:\n",
    "        docs_processed += text_splitter.split_documents([doc])\n",
    "\n",
    "    # Remove duplicates\n",
    "    unique_texts = {}\n",
    "    docs_processed_unique = []\n",
    "    for doc in docs_processed:\n",
    "        if doc.page_content not in unique_texts:\n",
    "            unique_texts[doc.page_content] = True\n",
    "            docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique\n",
    "\n",
    "\n",
    "docs_processed = split_documents(\n",
    "    512,  # We choose a chunk size adapted to our model\n",
    "    RAW_KNOWLEDGE_BASE,\n",
    "    tokenizer_name=EMBEDDING_MODEL_NAME,\n",
    ")\n",
    "\n",
    "# Let's visualize the chunk sizes we would have in tokens from a common model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "lengths = [len(tokenizer.encode(doc.page_content)) for doc in tqdm(docs_processed)]\n",
    "fig = pd.Series(lengths).hist()\n",
    "plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning:\n",
      "\n",
      "`resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create embeddings for docs \n",
    "## Takes a while to run loacally (~6 min w/ PythonDS, Week7, Week9)\n",
    "\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    "    multi_process=True,\n",
    "    # model_kwargs={\"device\": \"cuda\"}, #using cpu when running locally - change if connecting to GPU for more speed\n",
    "    encode_kwargs={\"normalize_embeddings\": True},  # Set `True` for cosine similarity\n",
    ")\n",
    "\n",
    "#edit distance strategy for use case\n",
    "KNOWLEDGE_VECTOR_DATABASE = FAISS.from_documents(\n",
    "    docs_processed, embedding_model, distance_strategy=DistanceStrategy.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed a user query in the same space\n",
    "user_query = \"What is One-Hot encoding?\"\n",
    "query_vector = embedding_model.embed_query(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wat6sv\\AppData\\Local\\miniconda3\\Lib\\site-packages\\pacmap\\pacmap.py:822: UserWarning:\n",
      "\n",
      "Warning: random state is set to 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create pca projection of embeddings for visualization\n",
    "\n",
    "embedding_projector = pacmap.PaCMAP(n_components=2, n_neighbors=None, MN_ratio=0.5, FP_ratio=2.0, random_state=1)\n",
    "\n",
    "embeddings_2d = [\n",
    "    list(KNOWLEDGE_VECTOR_DATABASE.index.reconstruct_n(idx, 1)[0]) for idx in range(len(docs_processed))\n",
    "] + [query_vector]\n",
    "\n",
    "# Fit the data (the index of transformed data corresponds to the index of the original data)\n",
    "documents_projected = embedding_projector.fit_transform(np.array(embeddings_2d), init=\"pca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "Preface - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nSign In\n\nTry No..."
          ],
          [
           "Who Should Read This Book This book is for current and aspiring machine learning practitioners looki..."
          ],
          [
           "Chapters 2 and 3 describe the actual machine learning algorithms that are most widely used in practi..."
          ],
          [
           "Constant width bold\n\nShows commands or other text that should be typed literally by the user.\n\nConst..."
          ],
          [
           "O’Reilly Safari Note Safari (formerly Safari Books Online) is a membership-based training and refere..."
          ],
          [
           "Acknowledgments\n\nFrom Andreas Without the help and support of a large group of people, this book wou..."
          ],
          [
           "Get Introduction to Machine Learning with Python now with the O’Reilly learning platform. O’Reilly m..."
          ],
          [
           "Try Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCo..."
          ],
          [
           "1.1 Why Machine Learning?\n\nIn the early days of “intelligent” applications, many systems used handco..."
          ],
          [
           "1.1.1 Problems Machine Learning Can Solve\n\nThe most successful kinds of machine learning algorithms ..."
          ],
          [
           "Detecting fraudulent activity in credit card transactions\n\nHere the input is a record of the credit ..."
          ],
          [
           "Detecting abnormal access patterns to a website\n\nTo identify abuse or bugs, it is often helpful to f..."
          ],
          [
           "1.1.2 Knowing Your Task and Knowing Your Data\n\nQuite possibly the most important part in the machine..."
          ],
          [
           "1.2 Why Python?\n\nPython has become the lingua franca for many data science applications. It combines..."
          ],
          [
           "Anaconda\n\nA Python distribution made for large-scale data processing, predictive analytics, and scie..."
          ],
          [
           "1.4.1 Jupyter Notebook\n\nThe Jupyter Notebook is an interactive environment for running code in the b..."
          ],
          [
           "1.4.3 SciPy\n\nSciPy is a collection of functions for scientific computing in Python. It provides, amo..."
          ],
          [
           "# Create a 2D NumPy array with a diagonal of ones, and zeros everywhere else eye = np.eye(4) print(\"..."
          ],
          [
           "1.4.4 matplotlib matplotlib is the primary scientific plotting library in Python. It provides functi..."
          ],
          [
           "Figure 1-1. Simple line plot of the sine function using matplotlib\n\n1.4.5 pandas pandas is a Python ..."
          ],
          [
           "Paris\n\nAnna\n\n2\n\n53\n\nBerlin\n\nPeter\n\n3\n\n33\n\nLondon\n\nLinda\n\nThere are several possible ways to query th..."
          ],
          [
           "2\n\n53\n\nBerlin\n\nPeter\n\n3\n\n33\n\nLondon\n\nLinda\n\n1.4.6 mglearn\n\nThis book comes with accompanying code, w..."
          ],
          [
           "1.5 Python 2 Versus Python 3\n\nThere are two major versions of Python that are widely used at the mom..."
          ],
          [
           "print(\"SciPy version:\", sp.__version__)\n\nimport IPython\n\nprint(\"IPython version:\", IPython.__version..."
          ],
          [
           "Now that we have everything set up, let’s dive into our first application of machine learning.\n\n1.7 ..."
          ],
          [
           "1.7.1 Meet the Data\n\nThe data we will use for this example is the Iris dataset, a classical dataset ..."
          ],
          [
           "Iris Plants Database\n\n====================\n\nNotes ---- Data Set Characteristics: :Number of Instance..."
          ],
          [
           "We see that the array contains measurements for 150 different flowers. Remember that the individual ..."
          ],
          [
           "The target array contains the species of each of the flowers that were measured, also as a NumPy arr..."
          ],
          [
           "Unfortunately, we cannot use the data we used to build the model to evaluate it. This is because our..."
          ],
          [
           "Before making the split, the train_test_split function shuffles the dataset using a pseudorandom num..."
          ],
          [
           "One of the best ways to inspect data is to visualize it. One way to do this is by using a scatter pl..."
          ],
          [
           "1.7.4 Building Your First Model: k-Nearest Neighbors\n\nNow we can start building the actual machine l..."
          ],
          [
           "The knn object encapsulates the algorithm that will be used to build the model from the training dat..."
          ],
          [
           "In the remainder of this book, we will not usually show the output of fit because it doesn’t contain..."
          ],
          [
           "This is where the test set that we created earlier comes in. This data was not used to build the mod..."
          ],
          [
           "1.8 Summary and Outlook\n\nLet’s summarize what we learned in this chapter. We started with a brief in..."
          ],
          [
           "This gave us the confidence to apply the model to new data (in our example, new flower measurements)..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "Start your free trial\n\nChapter 1. Introduction\n\nMachine learning is about extracting knowledge from ..."
          ],
          [
           "Designing rules requires a deep understanding of how a decision should be made by a human expert.\n\nO..."
          ],
          [
           "Examples of supervised machine learning tasks include:\n\nIdentifying the zip code from handwritten di..."
          ],
          [
           "Identifying topics in a set of blog posts\n\nIf you have a large collection of text data, you might wa..."
          ],
          [
           "Each entity or row here is known as a sample (or data point) in machine learning, while the columns—..."
          ],
          [
           "How will I measure success in my application?\n\nHow will the machine learning solution interact with ..."
          ],
          [
           "1.3 scikit-learn scikit-learn is an open source project, meaning that it is free to use and distribu..."
          ],
          [
           "Enthought Canopy\n\nAnother Python distribution for scientific computing. This comes with NumPy, SciPy..."
          ],
          [
           "Support\n\nContact us\n\nNewsletters\n\nPrivacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAust..."
          ],
          [
           "Start your free trial\n\nChapter 2. Supervised Learning\n\nAs we mentioned earlier, supervised machine l..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "Start your free trial\n\nChapter 3. Unsupervised Learning and Preprocessing\n\nThe second family of mach..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "Start your free trial\n\nChapter 4. Representing Data and Engineering Features\n\nSo far, we’ve assumed ..."
          ],
          [
           "4.1 Categorical Variables\n\nAs an example, we will use the dataset of adult incomes in the United Sta..."
          ],
          [
           "<=50K\n\n5\n\n37\n\nPrivate\n\nMasters\n\nFemale\n\n40\n\nExec\n\nmanagerial\n\n<=50K\n\n6\n\n49\n\nPrivate\n\n9th\n\nFemale\n\n16..."
          ],
          [
           "ŷ = w[0] * x[0] + w[1] * x[1] + ... + w[p] * x[p] + b > 0\n\nwhere w[i] and b are coefficients learned..."
          ],
          [
           "workclass\n\nGovernment Employee\n\nPrivate Employee\n\nSelf Employed\n\nSelf Employed Incorporated\n\nGovernm..."
          ],
          [
           "There are two ways to convert your data to a one-hot encoding of categorical variables, using either..."
          ],
          [
           "not\n\ninc\n\nBachelors\n\nMale\n\n13\n\nExec\n\nmanagerial\n\n<=50K\n\n2\n\n38\n\nPrivate\n\nHS\n\ngrad\n\nMale\n\n40\n\nHandlers..."
          ],
          [
           "The get_dummies function automatically transforms all columns that have object type (like strings) o..."
          ],
          [
           "age\n\nhours\n\nper\n\nweek\n\nworkclass_ ?\n\nworkclass_ Federal\n\ngov\n\nworkclass_\n\nLocal\n\ngov\n\n…\n\noccupation_..."
          ],
          [
           "0.0\n\n0.0\n\n…\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n5 rows × 46 columns We can now use the values attribute to convert ..."
          ],
          [
           "In this case, we extract only the columns containing features—that is, all columns from age to occup..."
          ],
          [
           "In this example, we called get_dummies on a DataFrame containing both the training and the test data..."
          ],
          [
           "4.1.2 Numbers Can Encode Categoricals\n\nIn the example of the adult dataset, the categorical variable..."
          ],
          [
           "Table 4-4. DataFrame containing categorical string features and integer features\n\nCategorical Featur..."
          ],
          [
           "Integer Feature_0\n\nInteger Feature_1\n\nInteger Feature_2\n\nCategorical Feature_box\n\nCategorical Featur..."
          ],
          [
           "3\n\n0.0\n\n1.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n4.2 OneHotEncoder and ColumnTransformer: Categorical Variables with..."
          ],
          [
           "This is where the ColumnTransformer class comes in handy: it allows you to apply different transform..."
          ],
          [
           "|0 |39 |State-gov |Bachelors |Male |40 |Adm-clerical |<=50K |1 |50 |Self-emp-not-inc |Bachelors |Mal..."
          ],
          [
           "the categorical variables, we might also want to scale the continuous variables age and hours-per-we..."
          ],
          [
           "Each transformer is applied to the corresponding columns, and the result of the transformations are ..."
          ],
          [
           "X_test_trans = ct.transform(X_test) print(\"Test score: {:.2f}\".format(logreg.score(X_test_trans, y_t..."
          ],
          [
           "4.4 Binning, Discretization, Linear Models, and Trees\n\nThe best way to represent data depends not on..."
          ],
          [
           "Figure 4-1. Comparing linear regression and a decision tree on the wave dataset\n\nWe imagine a partit..."
          ],
          [
           "In[21]: X_binned = kb.transform(X) X_binned Out[21]: <120x10 sparse matrix of type '<class 'numpy.fl..."
          ],
          [
           "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0. ], [0., 0., 0., 0., 0., 0., 0., 0., 0., 1. ], [0., 0...."
          ],
          [
           "[1., 0., 0., 0., 0., 0., 0., 0., 0., 0. ], [0., 0., 0., 0., 0., 0., 0., 0., 1., 0. ], [0., 0., 0., 0..."
          ],
          [
           "and so on. What we did here is transform the single continuous input feature in the wave dataset int..."
          ],
          [
           "= kb.transform(X) Now we build a new linear regression model and a new decision tree model on the on..."
          ],
          [
           "reg = LinearRegression().fit(X_binned, y) plt.plot(line, reg.predict(line_binned), label='linear reg..."
          ],
          [
           "Figure 4-2. Comparing linear regression and decision tree regression on binned features\n\n4.5 Interac..."
          ],
          [
           "Figure 4-3. Linear regression using binned features and a single global slope\n\nIn this example, the ..."
          ],
          [
           "Figure 4-4. Linear regression with a separate slope per bin\n\nAs you can see, now each bin has its ow..."
          ],
          [
           "20918.278] [    1.392     1.938     2.697     3.754     5.226     7.274    10.125 14.094    19.618  ..."
          ],
          [
           "Figure 4-5. Linear regression with tenth-degree polynomial features\n\nAs you can see, polynomial feat..."
          ],
          [
           "boston = load_boston() X_train, X_test, y_train, y_test = train_test_split( boston.data, boston.targ..."
          ],
          [
           "The exact correspondence between input and output features can be found using the get_feature_names ..."
          ],
          [
           "x12', 'x1^2', 'x1 x2', 'x1 x3', 'x1 x4', 'x1 x5', 'x1 x6', 'x1 x7', 'x1 x8', 'x1 x9', 'x1 x10', 'x1 ..."
          ],
          [
           "'x3 x11', 'x3 x12', 'x4^2', 'x4 x5', 'x4 x6', 'x4 x7', 'x4 x8', 'x4 x9', 'x4 x10', 'x4 x11', 'x4 x12..."
          ],
          [
           "'x8^2', 'x8 x9', 'x8 x10', 'x8 x11', 'x8 x12', 'x9^2', 'x9 x10', 'x9 x11', 'x9 x12', 'x10^2', 'x10 x..."
          ],
          [
           "Let’s compare the performance using Ridge on the data with and without interactions: In[38]: from sk..."
          ],
          [
           "4.6 Univariate Nonlinear Transformations\n\nWe just saw that adding squared or cubed features can help..."
          ],
          [
           "X = rnd.poisson(10 * np.exp(X_org)) y = np.dot(X_org, w) Let’s look at the first 10 entries of the f..."
          ],
          [
           "Figure 4-7. Histogram of feature values for X[0]\n\nFeatures X[:, 1] and X[:, 2] have similar properti..."
          ],
          [
           "Figure 4-8. Histogram of feature values for X[0] after logarithmic transformation\n\nBuilding a ridge ..."
          ],
          [
           "4.7 Automatic Feature Selection\n\nWith so many ways to create new features, you might get tempted to ..."
          ],
          [
           "To use univariate feature selection in scikit-learn, you need to choose a test, usually either f_cla..."
          ],
          [
           "print(\"X_train_selected.shape: {}\".format(X_train_selected.shape))\n\nOut[47]:\n\nX_train.shape: (284, 8..."
          ],
          [
           "# transform test data\n\nX_test_selected = select.transform(X_test)\n\nlr = LogisticRegression() lr.fit(..."
          ],
          [
           "To use model-based feature selection, we need to use the SelectFromModel transformer: In[50]: from s..."
          ],
          [
           "Figure 4-10. Features selected by SelectFromModel using the RandomForestClassifier\n\nThis time, all b..."
          ],
          [
           "select.fit(X_train, y_train) # visualize the selected features: mask = select.get_support() plt.mats..."
          ],
          [
           "4.8 Utilizing Expert Knowledge\n\nFeature engineering is often an important place to use expert knowle..."
          ],
          [
           "We resample the data into three-hour intervals to obtain the main trends for each day: In[57]: citib..."
          ],
          [
           "Figure 4-12. Number of bike rentals over time for a selected Citi Bike station\n\nLooking at the data,..."
          ],
          [
           "# function to evaluate and plot a regressor on a given feature set def eval_on_features(features, ta..."
          ],
          [
           "plt.plot(range(n_train, len(y_test) + n_train), y_pred, '--', label=\"prediction test\") plt.legend(lo..."
          ],
          [
           "Figure 4-13. Predictions made by a random forest using only the POSIX time\n\nThe predictions on the t..."
          ],
          [
           "Figure 4-14. Predictions made by a random forest using only the hour of the day\n\nThe R2 is already m..."
          ],
          [
           "Figure 4-16. Predictions made by linear regression using day of week and hour of day as features\n\nLi..."
          ],
          [
           "Figure 4-18. Predictions made by linear regression using a product of the day of week and hour of da..."
          ],
          [
           "Figure 4-19. Coefficients of the linear regression model using a product of hour and day\n\n4.9 Summar..."
          ],
          [
           "Privacy policy\n\nlinkedin\n\nlogo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & T..."
          ],
          [
           "Start your free trial\n\nChapter 5. Model Evaluation and Improvement\n\nHaving discussed the fundamental..."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "All features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reportin..."
          ],
          [
           "# create a synthetic dataset X, y = make_blobs(random_state=0) # split data and labels into a traini..."
          ],
          [
           "© 2024, O’Reilly Media, Inc. All trademarks and registered trademarks appearing on oreilly.com are t..."
          ],
          [
           "To evaluate our supervised models, so far we have split our dataset into a training set and a test s..."
          ],
          [
           "logo\n\nyoutube\n\nlogo\n\nInternational\n\nAustralia & New Zealand\n\nHong Kong & Taiwan\n\nIndia\n\nIndonesia\n\nJ..."
          ],
          [
           "About O’Reilly\n\nTeach/write/train\n\nCareers\n\nPress releases\n\nMedia coverage\n\nCommunity partners\n\nAffi..."
          ],
          [
           "All features\n\nCourses\n\nCertifications\n\nInteractive learning\n\nLive events\n\nAnswers\n\nInsights reportin..."
          ],
          [
           "# compute minimum and maximum on the training ...\n\nGet Introduction to Machine Learning with Python ..."
          ],
          [
           "Skip to main content\n\nSign In\n\nTry Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividu..."
          ],
          [
           "# load and split the data cancer = load_breast_cancer() X_train, X_test, y_train, y_test = train_tes..."
          ],
          [
           "Close\n\n6. Algorithm Chains and Pipelines - Introduction to Machine Learning with Python [Book]\n\nSkip..."
          ],
          [
           "Close\n\n7. Working with Text Data - Introduction to Machine Learning with Python [Book]\n\nSkip to main..."
          ],
          [
           "7.1 Types of Data Represented as Strings Before we dive into the processing steps that go into repre..."
          ],
          [
           "7.1 Types of Data Represented as Strings Before we dive into the processing steps that go into repre..."
          ],
          [
           "Close\n\n8. Wrapping Up - Introduction to Machine Learning with Python [Book]\n\nSkip to main content\n\nS..."
          ],
          [
           "Get Introduction to Machine Learning with Python now with the O’Reilly learning platform. O’Reilly m..."
          ],
          [
           "Try Now\n\nTeams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCo..."
          ],
          [
           "Get Introduction to Machine Learning with Python now with the O’Reilly learning platform. O’Reilly m..."
          ],
          [
           "Teams\n\nFor business\n\nFor government\n\nFor higher ed\n\nIndividuals\n\nFeatures\n\nAll features\n\nCourses\n\nCe..."
          ],
          [
           "Get Introduction to Machine Learning with Python now with the O’Reilly learning platform. O’Reilly m..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "marker": {
          "color": "#EF553B",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\IntroToMLwithPython-MullerGuido.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -5.892846,
          -5.662276,
          -5.2753167,
          -4.901284,
          -6.2338157,
          -4.2984066,
          -6.200375,
          -5.9526796,
          -5.5104976,
          -5.626482,
          -5.8345623,
          -5.6167173,
          -5.4990296,
          -4.287335,
          -3.980609,
          -3.8835948,
          -4.5201015,
          9.316514,
          1.2566835,
          1.1592017,
          10.500289,
          -4.236435,
          -3.9249933,
          -5.8535147,
          -6.2847285,
          -7.35537,
          -7.591013,
          -7.4296875,
          -7.3946614,
          -6.9215035,
          -6.3589835,
          -7.4580245,
          -6.3277926,
          -6.24952,
          -6.6362085,
          -7.2630963,
          -6.953839,
          -6.9185033,
          -6.970172,
          -5.7387376,
          -5.558056,
          -5.5827045,
          -5.621643,
          -5.4996123,
          -5.5660186,
          -4.6594214,
          -4.0755954,
          -6.9822116,
          -5.582194,
          -6.9777465,
          -6.9776163,
          -5.5375276,
          -6.9664364,
          -6.988551,
          -4.6834826,
          -2.0681734,
          -2.004194,
          -2.15862,
          -1.9967706,
          -2.068976,
          -1.9559041,
          -2.3273134,
          -1.8017113,
          -2.1209073,
          -4.511525,
          -2.3279154,
          -2.3567686,
          -2.231629,
          -2.0251591,
          -2.8288062,
          -2.212657,
          -1.9572929,
          -2.0427365,
          -3.1888294,
          -3.2325828,
          -3.4405754,
          -3.5217173,
          -3.0150423,
          -0.29710847,
          -2.6550877,
          -3.124891,
          -3.1131237,
          -3.4655213,
          -3.4329467,
          -3.2078922,
          -3.4848647,
          -4.795967,
          -4.7261276,
          -4.1971664,
          -4.29492,
          -0.7829609,
          -0.84538925,
          -2.754036,
          -4.174854,
          -2.9378195,
          -2.4082417,
          -3.2306373,
          -3.6662374,
          -4.2896757,
          -4.2929497,
          -3.986685,
          -3.99502,
          -4.1050673,
          -4.133828,
          -3.994603,
          -5.000085,
          5.3762293,
          4.393511,
          -5.9423165,
          -4.050148,
          3.8390517,
          4.3324833,
          4.3383713,
          4.1563907,
          4.43896,
          -7.0188193,
          -6.5353656,
          -6.920666,
          -5.6875057,
          -6.0678897,
          -5.9568205,
          -6.7225738,
          -6.9533243,
          -6.855035,
          -5.616181,
          -6.270318,
          -5.574522,
          -5.6994615,
          -5.589764,
          -5.2464976,
          -4.8113294,
          -5.016095,
          -5.9091916,
          -6.291328,
          -5.8143845,
          -6.230496,
          -5.7099195,
          -6.611256
         ],
         "xaxis": "x",
         "y": [
          -5.323653,
          -5.060164,
          -4.49057,
          -4.5837393,
          -5.944283,
          -5.8586035,
          -5.7988677,
          -5.2434406,
          -3.5363529,
          -3.5713995,
          -3.4097443,
          -3.5344825,
          -4.07808,
          -5.6465087,
          -5.920227,
          -5.7654357,
          -1.2764549,
          -4.1694436,
          6.0193534,
          6.19599,
          -0.60228395,
          -5.4995317,
          -5.904125,
          -3.0875843,
          -2.3376174,
          -2.1784127,
          -2.0837061,
          -2.2874827,
          -2.1140504,
          -1.2261044,
          -1.1892287,
          -1.870192,
          -1.4454818,
          -0.80866283,
          -1.4500737,
          -1.5300771,
          -1.727904,
          -1.7247787,
          -6.9971013,
          -4.5881867,
          -3.2172601,
          -3.5398383,
          -3.244141,
          -3.3035438,
          -4.583428,
          -5.447303,
          -5.8011656,
          -6.989771,
          -3.6005363,
          -6.956038,
          -6.969319,
          -3.5899808,
          -6.982709,
          -7.0204906,
          -2.618427,
          -0.9042948,
          -0.804161,
          -0.84457016,
          -0.7210507,
          -0.79740405,
          -0.80116874,
          -0.7066202,
          -0.56926703,
          -0.8130896,
          0.047612958,
          -0.69177604,
          -0.9326569,
          -0.65830475,
          0.7277306,
          -0.36711377,
          -0.8459778,
          -0.8106911,
          -0.55202436,
          -0.11595649,
          -0.30312675,
          1.1329615,
          1.5708128,
          0.38763183,
          1.937299,
          1.9204261,
          1.199508,
          0.9586151,
          1.2283098,
          1.1860163,
          1.200103,
          1.2821283,
          1.2919046,
          1.5550356,
          1.0147605,
          1.2525012,
          1.5590657,
          1.5919057,
          1.0480342,
          0.24241656,
          0.90204746,
          1.6873077,
          1.2524691,
          0.21771465,
          -1.4020898,
          -0.70319456,
          -0.1607473,
          -0.44087076,
          -0.3198357,
          -0.39663726,
          -0.20646764,
          -2.5401318,
          2.4285853,
          1.3838458,
          3.2764359,
          0.14828917,
          1.0549291,
          1.2681026,
          1.3181279,
          1.2846586,
          1.3330756,
          -7.045987,
          -1.3285193,
          -6.8975143,
          -4.335475,
          -1.161812,
          -5.3895664,
          -0.7818977,
          -6.945859,
          -6.8119955,
          -4.567636,
          -5.834345,
          -4.228722,
          -4.1130886,
          -4.6837764,
          -3.1609292,
          -2.869456,
          -2.8339834,
          -5.285921,
          -5.856734,
          -5.015286,
          -5.875307,
          -4.951747,
          -6.4079294
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Archives | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nArchive\n\nArchives and ..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "data\n\nscience\n\nvenn\n\ndiagram). Used by permission.)\n\nWhile some of the intersection labels are a bit..."
          ],
          [
           "Who Is This Book For?¶In my teaching both at the University of Washington and at various tech-focuse..."
          ],
          [
           "Python 2 vs Python 3¶This book uses the syntax of Python 3, which contains language enhancements tha..."
          ],
          [
           "Using Code Examples¶Supplemental material (code examples, figures, etc.) is available for download a..."
          ],
          [
           "Anaconda includes both Python and conda, and additionally bundles a suite of other pre-installed pac..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "IPython: Beyond Normal Python\n\n< Preface | Contents | Help and Documentation in IPython >\n\nThere are..."
          ],
          [
           "Shell or Notebook?¶There are two primary means of using IPython that we'll discuss in this chapter: ..."
          ],
          [
           "Launching the Jupyter Notebook¶The Jupyter notebook is a browser-based graphical interface to the IP..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "Here we'll discuss IPython's tools to quickly access this information, namely the ? character to exp..."
          ],
          [
           "Importantly, this will even work for functions or other objects you create yourself! Here we'll defi..."
          ],
          [
           "Return the number of items of a sequence or mapping.\n\nUsing ? and/or ? ? gives a powerful and quick ..."
          ],
          [
           "For brevity, we've only shown the first couple lines of the output. Most of these are Python's speci..."
          ],
          [
           "I find this type of flexible wildcard search can be very useful for finding a particular command whe..."
          ],
          [
           "Keyboard Shortcuts in the IPython Shell\n\n< Help and Documentation in IPython | Contents | IPython Ma..."
          ],
          [
           "Ctrl-b or the left arrow key Move cursor back one character\n\nCtrl-f or the right arrow key Move curs..."
          ],
          [
           "Ctrl-n (or the down arrow key) Access next command in history\n\nCtrl\n\nr\n\nReverse\n\nsearch through comm..."
          ],
          [
           "Keystroke\n\nAction\n\nCtrl\n\nl\n\nClear terminal screen\n\nCtrl\n\nc\n\nInterrupt current Python command\n\nCtrl\n\n..."
          ],
          [
           "Pasting Code Blocks: %paste and %cpaste¶When working in the IPython interpreter, one common gotcha i..."
          ],
          [
           "These magic commands, like others we'll see, make available functionality that would be difficult or..."
          ],
          [
           "The benefit of %timeit is that for short commands it will automatically perform multiple runs in ord..."
          ],
          [
           "Input and Output History\n\n< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nPrevio..."
          ],
          [
           "Out[5]: {2: 0.9092974268256817, 3:\n\n0.4161468365471424}\n\nThe In object is a list, which keeps track ..."
          ],
          [
           "In [11]: print(___)\n\n0.9092974268256817\n\nIPython stops there: more than three underscores starts to ..."
          ],
          [
           "< IPython Magic Commands | Contents | IPython and Shell Commands >\n\nIPython and Shell Commands | Pyt..."
          ],
          [
           "Quick Introduction to the Shell¶A full intro to using the shell/terminal/command-line is well beyond..."
          ],
          [
           "osx:projects $ pwd\n\n/home/jake/projects\n\nosx:projects $ ls datasci_book   mpld3   myproject.txt\n\nosx..."
          ],
          [
           "['myproject.txt']\n\nIn [6]: directory = !pwd\n\nIn [7]: print(directory)\n\n['/Users/jakevdp/notebooks/tm..."
          ],
          [
           "In fact, by default you can even use this without the % sign: In [15]: cd myproject /home/jake/proje..."
          ],
          [
           "Controlling Exceptions: %xmode¶Most of the time when a Python script fails, it will raise an Excepti..."
          ],
          [
           "ZeroDivisionError: division by zero\n\nCalling func2 results in an error, and reading the printed trac..."
          ],
          [
           "In [5]:\n\n%xmode Verbose\n\nException reporting mode: Verbose\n\nIn [6]:\n\nfunc2(1)\n\n---------------------..."
          ],
          [
           "Debugging: When Reading Tracebacks Is Not Enough¶The standard Python tool for interactive debugging ..."
          ],
          [
           "ipdb> print(x)\n\n1\n\nipdb> up\n\n> <ipython\n\ninput\n\n6\n\nb2e110f6fc8f>(1)<module>()\n\n---\n\n> 1 func2(1)\n\nip..."
          ],
          [
           "ipdb> print(b)\n\n0\n\nipdb> quit\n\nFinally, if you have a script that you'd like to run from the beginni..."
          ],
          [
           "Profiling and Timing Code\n\n< Errors and Debugging | Contents | More IPython Resources >\n\nIn the proc..."
          ],
          [
           "In [2]:\n\n%%timeit\n\ntotal = 0\n\nfor i in range(1000):\n\nfor j in range(1000):\n\ntotal += i\n\n(\n\n1) *\n\nj\n\n..."
          ],
          [
           "sorting an already sorted list: CPU times: user 8.18 ms, sys: 10 µs, total: 8.19 ms Wall time: 8.24 ..."
          ],
          [
           "Now we can call %prun with a function call to see the profiled results:\n\nIn [8]:\n\n%prun sum_of_lists..."
          ],
          [
           "In [9]:\n\n%load_ext line_profiler\n\nNow the %lprun command will do a line-by-line profiling of any fun..."
          ],
          [
           "Profiling Memory Use: %memit and %mprun¶Another aspect of profiling is the amount of memory an opera..."
          ],
          [
           "In [15]:\n\nfrom mprun_demo import sum_of_lists\n\n%mprun\n\nf sum_of_lists sum_of_lists(1000000)\n\nThe res..."
          ],
          [
           "< Errors and Debugging | Contents | More IPython Resources >\n\nMore IPython Resources | Python Data S..."
          ],
          [
           "Books¶ Python for Data Analysis: Wes McKinney's book includes a chapter that covers using IPython as..."
          ],
          [
           "Introduction to NumPy\n\n< More IPython Resources | Contents | Understanding Data Types in Python >\n\nT..."
          ],
          [
           "In [1]:\n\nimport numpy\n\nnumpy.__version__\n\nOut[1]:\n\n'1.11.1'\n\nFor the pieces of the package discussed..."
          ],
          [
           "Table of Contents¶Preface¶1. IPython: Beyond Normal Python¶ Help and Documentation in IPython Keyboa..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "This sort of flexibility is one piece that makes Python and other dynamically-typed languages conven..."
          ],
          [
           "This means that there is some overhead in storing an integer in Python as compared to an integer in ..."
          ],
          [
           "In [5]:\n\nL3 = [True, \"2\", 3.0, 4] [type(item) for item in L3]\n\nOut[5]:\n\n[bool, str, float, int]\n\nBut..."
          ],
          [
           "A\n\nOut[6]:\n\narray('i', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nHere 'i' is a type code indicating the conte..."
          ],
          [
           "Finally, unlike Python lists, NumPy arrays can explicitly be multi-dimensional; here's one way of in..."
          ],
          [
           "In [15]:\n\n# Create an array filled with a linear sequence # Starting at 0, ending at 20, stepping by..."
          ],
          [
           "# Create a 3x3 array of random integers in the interval [0, 10) np.random.randint(0, 10, (3, 3))\n\nOu..."
          ],
          [
           "int8\n\nByte (\n\n128 to 127)\n\nint16\n\nInteger (\n\n32768 to 32767)\n\nint32\n\nInteger (\n\n2147483648 to 214748..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "Each array has attributes ndim (the number of dimensions), shape (the size of each dimension), and s..."
          ],
          [
           "In [6]:\n\nx1[0]\n\nOut[6]:\n\n5\n\nIn [7]:\n\nx1[4]\n\nOut[7]:\n\n7\n\nTo index from the end of the array, you can ..."
          ],
          [
           "In [15]:\n\nx1[0] = 3.14159  # this will be truncated! x1\n\nOut[15]:\n\narray([3, 0, 3, 3, 7, 9])\n\nArray ..."
          ],
          [
           "In [21]:\n\nx[1::2]  # every other element, starting at index 1\n\nOut[21]:\n\narray([1, 3, 5, 7, 9])\n\nA p..."
          ],
          [
           "In [27]:\n\nx2[::\n\n1, ::\n\n1]\n\nOut[27]:\n\narray([[ 7,  7,  6,  1], [ 8,  8,  6,  7], [ 4,  2,  5, 12]])\n..."
          ],
          [
           "Now if we modify this subarray, we'll see that the original array is changed! Observe:\n\nIn [33]:\n\nx2..."
          ],
          [
           "In [38]:\n\ngrid = np.arange(1, 10).reshape((3, 3)) print(grid)\n\n[[1 2 3]\n\n[4 5 6]\n\n[7 8 9]]\n\nNote tha..."
          ],
          [
           "array([[1],\n\n[2],\n\n[3]])\n\nWe will see this type of transformation often throughout the remainder of ..."
          ],
          [
           "[4, 5, 6],\n\n[1, 2, 3],\n\n[4, 5, 6]])\n\nIn [47]:\n\n# concatenate along the second axis (zero-indexed) np..."
          ],
          [
           "[1 2 3] [99 99] [3 2 1]\n\nNotice that N split-points, leads to N + 1 subarrays. The related functions..."
          ],
          [
           "Computation on NumPy Arrays: Universal Functions\n\n< The Basics of NumPy Arrays | Contents | Aggregat..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nnp.random.seed(0)\n\ndef compute_reciprocals(values): output = np.empty(l..."
          ],
          [
           "Introducing UFuncs¶For many types of operations, NumPy provides a convenient interface into just thi..."
          ],
          [
           "2 *\n\nx\n\nOut[6]:\n\narray([[  1,   2,   4], [  8,  16,  32], [ 64, 128, 256]])\n\nComputations using vect..."
          ],
          [
           "x     =  [ 0\n\n1\n\n2\n\n3] x\n\n** 2 =  [0 1 4 9] x % 2  =  [0 1 0 1]\n\nIn addition, these can be strung to..."
          ],
          [
           "% np.mod Modulus/remainder (e.g., 9 % 4 = 1)\n\nAdditionally there are Boolean/bitwise operators; we w..."
          ],
          [
           "theta = np.linspace(0, np.pi, 3)\n\nNow we can compute some trigonometric functions on these values:\n\n..."
          ],
          [
           "Exponents and logarithms¶Another common type of operation available in a NumPy ufunc are the exponen..."
          ],
          [
           "exp(x) - 1 = [ 0. 0.0010005   0.01005017  0.10517092] log(1 + x) = [ 0. 0.0009995   0.00995033  0.09..."
          ],
          [
           "In [23]:\n\n# Error function (integral of Gaussian) # its complement, and its inverse x = np.array([0,..."
          ],
          [
           "In [25]:\n\ny = np.zeros(10)\n\nnp.power(2, x, out=y[::2])\n\nprint(y)\n\n[  1. 0. 2. 0. 4. 0. 8. 0. 16. 0.]..."
          ],
          [
           "In [29]:\n\nnp.multiply.accumulate(x)\n\nOut[29]:\n\narray([  1,   2,   6,  24, 120])\n\nNote that for these..."
          ],
          [
           "Aggregations: Min, Max, and Everything In Between | Python Data Science Handbook\n\nPython Data Scienc..."
          ],
          [
           "In [4]:\n\nbig_array = np.random.rand(1000000)\n\n%timeit sum(big_array)\n\n%timeit np.sum(big_array)\n\n10 ..."
          ],
          [
           "In [8]:\n\nprint(big_array.min(), big_array.max(), big_array.sum())\n\n1.17171281366e\n\n06 0.999997678497..."
          ],
          [
           "In [12]:\n\nM.max(axis=1)\n\nOut[12]:\n\narray([ 0.8967576 ,  0.99196818,  0.6687194 ])\n\nThe way the axis ..."
          ],
          [
           "np.argmax np.nanargmax Find index of maximum value\n\nnp.median\n\nnp.nanmedian\n\nCompute median of eleme..."
          ],
          [
           "Now that we have this data array, we can compute a variety of summary statistics:\n\nIn [15]:\n\nprint(\"..."
          ],
          [
           "< Computation on NumPy Arrays: Universal Functions | Contents | Computation on Arrays: Broadcasting ..."
          ],
          [
           "In [3]:\n\na + 5\n\nOut[3]:\n\narray([5, 6, 7])\n\nWe can think of this as an operation that stretches or du..."
          ],
          [
           "Out[7]:\n\narray([[0, 1, 2],\n\n[1, 2, 3],\n\n[2, 3, 4]])\n\nJust as before we stretched or broadcasted one ..."
          ],
          [
           "M.shape\n\n> (2, 3)\n\na.shape\n\n> (1, 3)\n\nBy rule 2, we now see that the first dimension disagrees, so w..."
          ],
          [
           "[1, 2, 3],\n\n[2, 3, 4]])\n\nBroadcasting example 3¶Now let's take a look at an example in which the two..."
          ],
          [
           "ValueError: operands could not be broadcast together with shapes (3,2) (3,)\n\nNote the potential conf..."
          ],
          [
           "Broadcasting in Practice¶\n\nBroadcasting operations form the core of many examples we'll see througho..."
          ],
          [
           "17,\n\n1.66533454e\n\n17])\n\nTo within machine precision, the mean is now zero.\n\nPlotting a two\n\ndimensio..."
          ],
          [
           "Comparisons, Masks, and Boolean Logic\n\n< Computation on Arrays: Broadcasting | Contents | Fancy Inde..."
          ],
          [
           "In [3]:\n\nplt.hist(inches, 40);\n\nThis histogram gives us a general idea of what the data looks like: ..."
          ],
          [
           "x < 3  # less than\n\nOut[5]:\n\narray([ True,  True, False, False, False], dtype=bool)\n\nIn [6]:\n\nx > 3 ..."
          ],
          [
           "Operator\n\nEquivalent ufunc\n\nOperator\n\nEquivalent ufunc\n\n==\n\nnp.equal\n\n!=\n\nnp.not_equal\n\n<\n\nnp.less\n\n..."
          ],
          [
           "In [15]:\n\n# how many values less than 6? np.count_nonzero(x < 6)\n\nOut[15]:\n\n8\n\nWe see that there are..."
          ],
          [
           "In [22]:\n\n# are all values in each row less than 8? np.all(x < 8, axis=1)\n\nOut[22]:\n\narray([ True, F..."
          ],
          [
           "In [24]:\n\nnp.sum(~( (inches <= 0.5) | (inches >= 1) ))\n\nOut[24]:\n\n29\n\nCombining comparison operators..."
          ],
          [
           "x\n\nOut[26]:\n\narray([[5, 0, 3, 3],\n\n[7, 9, 3, 5],\n\n[2, 4, 7, 6]])\n\nWe can obtain a Boolean array for ..."
          ],
          [
           "Median precip on rainy days in 2014 (inches):    0.194881889764 Median precip on summer days in 2014..."
          ],
          [
           "'0b111011'\n\nIn [35]:\n\nbin(42 & 59)\n\nOut[35]:\n\n'0b101010'\n\nIn [36]:\n\nbin(42 | 59)\n\nOut[36]:\n\n'0b11101..."
          ],
          [
           "Similarly, when doing a Boolean expression on a given array, you should use | or & rather than or or..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "When using fancy indexing, the shape of the result reflects the shape of the index arrays rather tha..."
          ],
          [
           "Here, each row value is matched with each column vector, exactly as we saw in broadcasting of arithm..."
          ],
          [
           "[ 4,  6],\n\n[ 8, 10]])\n\nAll of these indexing options combined lead to a very flexible set of operati..."
          ],
          [
           "(20, 2)\n\nNow to see which points were selected, let's over-plot large circles at the locations of th..."
          ],
          [
           "In [21]:\n\ni = [2, 3, 3, 4, 4, 4] x[i] += 1 x\n\nOut[21]:\n\narray([ 6.,  0.,  1.,  1.,  1.,  0.,  0.,  0..."
          ],
          [
           "In [23]:\n\nnp.random.seed(42)\n\nx = np.random.randn(100)\n\n# compute a histogram by hand bins = np.lins..."
          ],
          [
           "NumPy routine: 10000 loops, best of 3: 97.6 µs per loop Custom routine: 10000 loops, best of 3: 19.5..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "Out[2]:\n\narray([1, 2, 3, 4, 5])\n\nAs any first-year computer science major will tell you, the selecti..."
          ],
          [
           "Fast Sorting in NumPy: np.sort and np.argsort¶Although Python has built-in sort and sorted functions..."
          ],
          [
           "A useful feature of NumPy's sorting algorithms is the ability to sort along specific rows or columns..."
          ],
          [
           "In [12]:\n\nx = np.array([7, 2, 3, 1, 6, 5, 4]) np.partition(x, 3)\n\nOut[12]:\n\narray([2, 1, 3, 4, 6, 5,..."
          ],
          [
           "Now we'll compute the distance between each pair of points. Recall that the squared-distance between..."
          ],
          [
           "Out[20]:\n\narray([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n\nIt checks out! With the pairwis..."
          ],
          [
           "plt.scatter(X[:, 0], X[:, 1], s=100)\n\n# draw lines from each point to its two nearest neighbors K = ..."
          ],
          [
           "Aside: Big-O Notation¶Big-O notation is a means of describing how the number of operations required ..."
          ],
          [
           "When trying to analyze billions or trillions of samples, the difference between $\\mathcal{O}[N]$ and..."
          ],
          [
           "Structured Data: NumPy's Structured Arrays\n\n< Sorting Arrays | Contents | Data Manipulation with Pan..."
          ],
          [
           "[('name', '<U10'), ('age', '<i4'), ('weight', '<f8')]\n\nHere 'U10' translates to \"Unicode string of m..."
          ],
          [
           "Out[8]:\n\n'Doug'\n\nUsing Boolean masking, this even allows you to do some more sophisticated operation..."
          ],
          [
           "A compound type can also be specified as a list of tuples:\n\nIn [12]:\n\nnp.dtype([('name', 'S10'), ('a..."
          ],
          [
           "'c'\n\nComplex floating point\n\nnp.dtype('c16') == np.complex128\n\n'S', 'a'\n\nString\n\nnp.dtype('S5')\n\n'U'..."
          ],
          [
           "RecordArrays: Structured Arrays with a Twist¶NumPy also provides the np.recarray class, which is alm..."
          ],
          [
           "< Sorting Arrays | Contents | Data Manipulation with Pandas >\n\nData Manipulation with Pandas | Pytho..."
          ],
          [
           "In this chapter, we will focus on the mechanics of using Series, DataFrame, and related structures e..."
          ],
          [
           "Python Data Science Handbook | Python Data Science Handbook\n\nPython Data Science Handbook\n\nAbout\n\nAr..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "In [2]:\n\ndata = pd.Series([0.25, 0.5, 0.75, 1.0]) data\n\nOut[2]:\n\n0    0.25 1    0.50 2    0.75 3    ..."
          ],
          [
           "As we will see, though, the Pandas Series is much more general and flexible than the one-dimensional..."
          ],
          [
           "In [10]:\n\ndata[5]\n\nOut[10]:\n\n0.5\n\nSeries as specialized dictionary¶In this way, you can think of a P..."
          ],
          [
           "California    38332521 Florida       19552860 Illinois      12882135 dtype: int64\n\nWe'll discuss som..."
          ],
          [
           "Out[17]:\n\n3    c 2    a dtype: object\n\nNotice that in this case, the Series is populated only with t..."
          ],
          [
           "California\n\n423967\n\n38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n14129..."
          ],
          [
           "Out[22]:\n\nCalifornia    423967 Florida       170312 Illinois      149995 New York      141297 Texas ..."
          ],
          [
           "2\n\n2\n\n4\n\nEven if some keys in the dictionary are missing, Pandas will fill them in with NaN (i.e., \"..."
          ],
          [
           "Out[27]:\n\nfoo\n\nbar\n\na\n\n0.865257\n\n0.213169\n\nb\n\n0.442759\n\n0.108267\n\nc\n\n0.047110\n\n0.905718\n\nFrom a NumP..."
          ],
          [
           "In [30]:\n\nind = pd.Index([2, 3, 5, 7, 11]) ind\n\nOut[30]:\n\nInt64Index([2, 3, 5, 7, 11], dtype='int64'..."
          ],
          [
           "/Users/jakevdp/anaconda/lib/python3.5/site-packages/pandas/indexes/base.py in __setitem__(self, key,..."
          ],
          [
           "These operations may also be accessed via object methods, for example indA.intersection(indB).\n\n< Da..."
          ],
          [
           "Series as dictionary¶Like a dictionary, the Series object provides a mapping from a collection of ke..."
          ],
          [
           "This easy mutability of the objects is a convenient feature: under the hood, Pandas is making decisi..."
          ],
          [
           "In [11]:\n\ndata = pd.Series(['a', 'b', 'c'], index=[1, 3, 5]) data\n\nOut[11]:\n\n1    a 3    b 5    c dt..."
          ],
          [
           "'b'\n\nIn [17]:\n\ndata.iloc[1:3]\n\nOut[17]:\n\n3    b 5    c dtype: object\n\nA third indexing attribute, ix..."
          ],
          [
           "38332521\n\nFlorida\n\n170312\n\n19552860\n\nIllinois\n\n149995\n\n12882135\n\nNew York\n\n141297\n\n19651127\n\nTexas\n\n..."
          ],
          [
           "In [22]:\n\ndata.pop is data['pop']\n\nOut[22]:\n\nFalse\n\nIn particular, you should avoid the temptation t..."
          ],
          [
           "In [24]:\n\ndata.values\n\nOut[24]:\n\narray([[  4.23967000e+05,   3.83325210e+07,   9.04139261e+01], [  1..."
          ],
          [
           "1.148061e+02\n\n8.588376e+01\n\n1.390767e+02\n\n3.801874e+01\n\nWhen it comes to indexing of DataFrame objec..."
          ],
          [
           "In [29]:\n\ndata.loc[:'Illinois', :'pop']\n\nOut[29]:\n\narea\n\npop\n\nCalifornia\n\n423967\n\n38332521\n\nFlorida\n..."
          ],
          [
           "data\n\nOut[32]:\n\narea\n\npop\n\ndensity\n\nCalifornia\n\n423967\n\n38332521\n\n90.000000\n\nFlorida\n\n170312\n\n195528..."
          ],
          [
           "19552860\n\n114.806121\n\nIllinois\n\n149995\n\n12882135\n\n85.883763\n\nSimilarly, direct masking operations ar..."
          ],
          [
           "Operating on Data in Pandas\n\n< Data Indexing and Selection | Contents | Handling Missing Data >\n\nOne..."
          ],
          [
           "Out[3]:\n\nA\n\nB\n\nC\n\nD\n\n0\n\n6\n\n9\n\n2\n\n6\n\n1\n\n7\n\n4\n\n3\n\n7\n\n2\n\n7\n\n2\n\n5\n\n4\n\nIf we apply a NumPy ufunc on eithe..."
          ],
          [
           "1.224647e\n\n16\n\nAny of the ufuncs discussed in Computation on NumPy Arrays: Universal Functions can b..."
          ],
          [
           "In [9]:\n\nA = pd.Series([2, 4, 6], index=[0, 1, 2]) B = pd.Series([1, 3, 5], index=[1, 2, 3]) A + B\n\n..."
          ],
          [
           "2\n\n9\n\n2\n\n6\n\nIn [13]:\n\nA + B\n\nOut[13]:\n\nA\n\nB\n\nC\n\n0\n\n1.0\n\n15.0\n\nNaN\n\n1\n\n13.0\n\n6.0\n\nNaN\n\n2\n\nNaN\n\nNaN\n\nN..."
          ],
          [
           "truediv(), div(), divide()\n\n//\n\nfloordiv()\n\n%\n\nmod()\n\npow()\n\nUfuncs: Operations Between DataFrame an..."
          ],
          [
           "1\n\n1\n\n2\n\n2\n\n4\n\n2\n\n3\n\n7\n\n1\n\n4\n\nIf you would instead like to operate column-wise, you can use the obje..."
          ],
          [
           "< Data Indexing and Selection | Contents | Handling Missing Data >\n\nHandling Missing Data | Python D..."
          ],
          [
           "Trade-Offs in Missing Data Conventions¶There are a number of schemes that have been developed to ind..."
          ],
          [
           "For example, the R language uses reserved bit patterns within each data type as sentinel values indi..."
          ],
          [
           "In [1]:\n\nimport numpy as np\n\nimport pandas as pd\n\nIn [2]:\n\nvals1 = np.array([1, None, 3, 4]) vals1\n\n..."
          ],
          [
           "/Users/jakevdp/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py in _sum(a, axis, dtype, o..."
          ],
          [
           "In [8]:\n\nvals2.sum(), vals2.min(), vals2.max()\n\nOut[8]:\n\n(nan, nan, nan)\n\nNumPy does provide some sp..."
          ],
          [
           "In [12]:\n\nx[0] = None\n\nx\n\nOut[12]:\n\n0    NaN 1    1.0 dtype: float64\n\nNotice that in addition to cas..."
          ],
          [
           "In [13]:\n\ndata = pd.Series([1, np.nan, 'hello', None])\n\nIn [14]:\n\ndata.isnull()\n\nOut[14]:\n\n0    Fals..."
          ],
          [
           "In [18]:\n\ndf.dropna()\n\nOut[18]:\n\n0\n\n1\n\n2\n\n1\n\n2.0\n\n3.0\n\n5\n\nAlternatively, you can drop NA values alon..."
          ],
          [
           "0\n\n1\n\n2\n\n0\n\n1.0\n\nNaN\n\n2\n\n1\n\n2.0\n\n3.0\n\n5\n\n2\n\nNaN\n\n4.0\n\n6\n\nFor finer-grained control, the thresh param..."
          ],
          [
           "a    1.0 b    0.0 c    2.0 d    0.0 e    3.0 dtype: float64\n\nWe can specify a forward-fill to propag..."
          ],
          [
           "2.0\n\n1\n\n2.0\n\n3.0\n\n5.0\n\n5.0\n\n2\n\nNaN\n\n4.0\n\n6.0\n\n6.0\n\nNotice that if a previous value is not available ..."
          ],
          [
           "In [1]:\n\nimport pandas as pd\n\nimport numpy as np\n\nA Multiply Indexed Series¶Let's start by consideri..."
          ],
          [
           "In [4]:\n\npop[[i for i in pop.index if i[1] == 2010]]\n\nOut[4]:\n\n(California, 2010)    37253956 (New Y..."
          ],
          [
           "Now to access all data for which the second index is 2010, we can simply use the Pandas slicing nota..."
          ],
          [
           "Out[9]:\n\nCalifornia  2000    33871648 2010    37253956 New York    2000    18976457 2010    19378102..."
          ],
          [
           "In [11]:\n\nf_u18 = pop_df['under18'] / pop_df['total'] f_u18.unstack()\n\nOut[11]:\n\n2000\n\n2010\n\nCalifor..."
          ],
          [
           "In [13]:\n\ndata = {('California', 2000): 33871648, ('California', 2010): 37253956, ('Texas', 2000): 2..."
          ],
          [
           "MultiIndex(levels=[['a', 'b'], [1, 2]], labels=[[0, 0, 1, 1], [0, 1, 0, 1]])\n\nYou can even construct..."
          ],
          [
           "In [18]:\n\npop.index.names = ['state', 'year']\n\npop\n\nOut[18]:\n\nstate       year California  2000    3..."
          ],
          [
           "36.7\n\n35.0\n\n37.2\n\n2\n\n44.0\n\n37.7\n\n50.0\n\n35.0\n\n29.0\n\n36.7\n\n2014\n\n1\n\n30.0\n\n37.4\n\n39.0\n\n37.8\n\n61.0\n\n36.9..."
          ],
          [
           "Multiply indexed Series¶Consider the multiply indexed Series of state populations we saw earlier:\n\nI..."
          ],
          [
           "pop[pop > 22000000]\n\nOut[26]:\n\nstate       year California  2000    33871648 2010    37253956 Texas ..."
          ],
          [
           "In [29]:\n\nhealth_data['Guido', 'HR']\n\nOut[29]:\n\nyear  visit 2013  1        32.0 2        50.0 2014  ..."
          ],
          [
           "health_data.loc[(:, 1), (:, 'HR')]\n\n^\n\nSyntaxError: invalid syntax\n\nYou could get around this by bui..."
          ],
          [
           "In [34]:\n\nindex = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]]) data = pd.Series(np.random.r..."
          ],
          [
           "With the index sorted in this way, partial slicing will work as expected:\n\nIn [37]:\n\ndata['a':'b']\n\n..."
          ],
          [
           "Out[40]:\n\nstate       year California  2000    33871648 2010    37253956 New York    2000    1897645..."
          ],
          [
           "33871648\n\n2010\n\n37253956\n\nNew York\n\n2000\n\n18976457\n\n2010\n\n19378102\n\nTexas\n\n2000\n\n20851820\n\n2010\n\n251..."
          ],
          [
           "2\n\n47.0\n\n37.8\n\n48.0\n\n37.3\n\n51.0\n\n36.5\n\nPerhaps we'd like to average-out the measurements in the two ..."
          ],
          [
           "Aside: Panel Data¶Pandas has a few other fundamental data structures that we have not yet discussed,..."
          ],
          [
           "Combining Datasets: Concat and Append\n\n< Hierarchical Indexing | Contents | Combining Datasets: Merg..."
          ],
          [
           "In [3]:\n\nclass display(object): \"\"\"Display HTML representation of multiple objects\"\"\" template = \"\"\"..."
          ],
          [
           "In [5]:\n\nx = [[1, 2],\n\n[3, 4]]\n\nnp.concatenate([x, x], axis=1)\n\nOut[5]:\n\narray([[1, 2, 1, 2],\n\n[3, 4..."
          ],
          [
           "Out[7]:\n\ndf1\n\nA\n\nB\n\n1\n\nA1\n\nB1\n\n2\n\nA2\n\nB2\n\ndf2\n\nA\n\nB\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\npd.concat([df1, df2])\n\nA\n..."
          ],
          [
           "pd.concat([df3, df4], axis='col')\n\nA\n\nB\n\nC\n\nD\n\n0\n\nA0\n\nB0\n\nC0\n\nD0\n\n1\n\nA1\n\nB1\n\nC1\n\nD1\n\nWe could have e..."
          ],
          [
           "B3\n\nNotice the repeated indices in the result. While this is valid within DataFrames, the outcome is..."
          ],
          [
           "B0\n\n1\n\nA1\n\nB1\n\n2\n\nA2\n\nB2\n\n3\n\nA3\n\nB3\n\nAdding MultiIndex keys¶Another option is to use the keys option..."
          ],
          [
           "In [13]:\n\ndf5 = make_df('ABC', [1, 2]) df6 = make_df('BCD', [3, 4]) display('df5', 'df6', 'pd.concat..."
          ],
          [
           "display('df5', 'df6',\n\n\"pd.concat([df5, df6], join='inner')\")\n\nOut[14]:\n\ndf5\n\nA\n\nB\n\nC\n\n1\n\nA1\n\nB1\n\nC1..."
          ],
          [
           "B2\n\nC2\n\ndf6\n\nB\n\nC\n\nD\n\n3\n\nB3\n\nC3\n\nD3\n\n4\n\nB4\n\nC4\n\nD4\n\npd.concat([df5, df6], join_axes=[df5.columns])\n\n..."
          ],
          [
           "B3\n\n4\n\nA4\n\nB4\n\ndf1.append(df2)\n\nA\n\nB\n\n1\n\nA1\n\nB1\n\n2\n\nA2\n\nB2\n\n3\n\nA3\n\nB3\n\n4\n\nA4\n\nB4\n\nKeep in mind that ..."
          ],
          [
           "Combining Datasets: Merge and Join\n\n< Combining Datasets: Concat and Append | Contents | Aggregation..."
          ],
          [
           "def __repr__(self): return '\\n\\n'.join(a + '\\n' + repr(eval(a)) for a in self.args)\n\nRelational Alge..."
          ],
          [
           "Out[2]:\n\ndf1\n\nemployee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSu..."
          ],
          [
           "Many\n\nto\n\none joins¶\n\nMany-to-one joins are joins in which one of the two key columns contains dupli..."
          ],
          [
           "HR\n\n2014\n\nSteve\n\nThe resulting DataFrame has an aditional column with the \"supervisor\" information, ..."
          ],
          [
           "HR\n\nspreadsheets\n\n5\n\nHR\n\norganization\n\npd.merge(df1, df5)\n\nemployee\n\ngroup\n\nskills\n\n0\n\nBob\n\nAccounti..."
          ],
          [
           "Out[6]:\n\ndf1\n\nemployee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSu..."
          ],
          [
           "Out[7]:\n\ndf1\n\nemployee\n\ngroup\n\n0\n\nBob\n\nAccounting\n\n1\n\nJake\n\nEngineering\n\n2\n\nLisa\n\nEngineering\n\n3\n\nSu..."
          ],
          [
           "Jake\n\nEngineering\n\n80000\n\n2\n\nLisa\n\nEngineering\n\n120000\n\n3\n\nSue\n\nHR\n\n90000\n\nThe left_index and right_..."
          ],
          [
           "df2a\n\nhire_date\n\nemployee\n\nLisa\n\n2004\n\nBob\n\n2008\n\nJake\n\n2012\n\nSue\n\n2014\n\npd.merge(df1a, df2a, left_i..."
          ],
          [
           "2014\n\nIf you'd like to mix indices and columns, you can combine left_index with right_on or left_on ..."
          ],
          [
           "In [13]:\n\ndf6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'], 'food': ['fish', 'beans', 'bread']}..."
          ],
          [
           "wine\n\nOther options for the how keyword are 'outer', 'left', and 'right'. An outer join returns a jo..."
          ],
          [
           "beans\n\n2\n\nMary\n\nbread\n\ndf7\n\nname\n\ndrink\n\n0\n\nMary\n\nwine\n\n1\n\nJoseph\n\nbeer\n\npd.merge(df6, df7, how='lef..."
          ],
          [
           "3\n\n3\n\nSue\n\n4\n\ndf9\n\nname\n\nrank\n\n0\n\nBob\n\n3\n\n1\n\nJake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"..."
          ],
          [
           "3\n\n1\n\nJake\n\n1\n\n2\n\nLisa\n\n4\n\n3\n\nSue\n\n2\n\npd.merge(df8, df9, on=\"name\", suffixes=[\"_L\", \"_R\"])\n\nname\n\nra..."
          ],
          [
           "Let's take a look at the three datasets, using the Pandas read_csv() function:\n\nIn [20]:\n\npop = pd.r..."
          ],
          [
           "state\n\nabbreviation\n\n0\n\nAlabama\n\nAL\n\n1\n\nAlaska\n\nAK\n\n2\n\nArizona\n\nAZ\n\n3\n\nArkansas\n\nAR\n\n4\n\nCalifornia\n\n..."
          ],
          [
           "4785570.0\n\nAlabama\n\n4\n\nAL\n\nunder18\n\n2011\n\n1125763.0\n\nAlabama\n\nLet's double-check whether there were ..."
          ],
          [
           "In [24]:\n\nmerged.loc[merged['state'].isnull(), 'state/region'].unique()\n\nOut[24]:\n\narray(['PR', 'USA..."
          ],
          [
           "2\n\nAL\n\nunder18\n\n2010\n\n1130966.0\n\nAlabama\n\n52423.0\n\n3\n\nAL\n\ntotal\n\n2010\n\n4785570.0\n\nAlabama\n\n52423.0\n\n..."
          ],
          [
           "0\n\nAL\n\nunder18\n\n2012\n\n1117489.0\n\nAlabama\n\n52423.0\n\n1\n\nAL\n\ntotal\n\n2012\n\n4817528.0\n\nAlabama\n\n52423.0\n\n..."
          ],
          [
           "Alaska\n\n656425.0\n\n101\n\nAZ\n\ntotal\n\n2010\n\n6408790.0\n\nArizona\n\n114006.0\n\n189\n\nAR\n\ntotal\n\n2010\n\n2922280...."
          ],
          [
           "state South Dakota    10.583512 North Dakota     9.537565 Montana          6.736171 Wyoming         ..."
          ],
          [
           "For convenience, we'll use the same display magic function that we've seen in previous sections:\n\nIn..."
          ],
          [
           "0\n\nRadial Velocity\n\n1\n\n269.300\n\n7.10\n\n77.40\n\n2006\n\n1\n\nRadial Velocity\n\n1\n\n874.774\n\n2.21\n\n56.95\n\n2008..."
          ],
          [
           "Out[6]:\n\n0.56238509834163142\n\nFor a DataFrame, by default the aggregates return results within each ..."
          ],
          [
           "In [10]:\n\nplanets.dropna().describe()\n\nOut[10]:\n\nnumber\n\norbital_period\n\nmass\n\ndistance\n\nyear\n\ncount..."
          ],
          [
           "max\n\n6.00000\n\n17337.500000\n\n25.000000\n\n354.000000\n\n2014.000000\n\nThis can be a useful way to begin un..."
          ],
          [
           "Split, apply, combine¶A canonical example of this split-apply-combine operation, where the \"apply\" i..."
          ],
          [
           "5\n\nThe most basic split-apply-combine operation can be computed with the groupby() method of DataFra..."
          ],
          [
           "Column indexing¶The GroupBy object supports column indexing in the same way as the DataFrame, and re..."
          ],
          [
           "for (method, group) in planets.groupby('method'): print(\"{0:30s} shape={1}\".format(method, group.sha..."
          ],
          [
           "2010.0\n\n2011.00\n\n2012.0\n\nImaging\n\n38.0\n\n2009.131579\n\n2.781901\n\n2004.0\n\n2008.00\n\n2009.0\n\n2011.00\n\n201..."
          ],
          [
           "2002.0\n\n2010.00\n\n2012.0\n\n2013.00\n\n2014.0\n\nTransit Timing Variations\n\n4.0\n\n2012.500000\n\n1.290994\n\n201..."
          ],
          [
           "data1\n\ndata2\n\n0\n\nA\n\n0\n\n5\n\n1\n\nB\n\n1\n\n0\n\n2\n\nC\n\n2\n\n3\n\n3\n\nA\n\n3\n\n3\n\n4\n\nB\n\n4\n\n7\n\n5\n\nC\n\n5\n\n9\n\nAggregation¶We..."
          ],
          [
           "'data2': 'max'})\n\nOut[21]:\n\ndata1\n\ndata2\n\nkey\n\nA\n\n0\n\n5\n\nB\n\n1\n\n7\n\nC\n\n2\n\n9\n\nFiltering¶A filtering oper..."
          ],
          [
           "4.242641\n\ndf.groupby('key').filter(filter_func)\n\nkey\n\ndata1\n\ndata2\n\n1\n\nB\n\n1\n\n0\n\n2\n\nC\n\n2\n\n3\n\n4\n\nB\n\n4\n..."
          ],
          [
           "In [24]:\n\ndef norm_by_data2(x): # x is a DataFrame of group values x['data1'] /= x['data2'].sum() re..."
          ],
          [
           "9\n\napply() within a GroupBy is quite flexible: the only criterion is that the function takes a DataF..."
          ],
          [
           "display('df', \"df.groupby(df['key']).sum()\")\n\nOut[26]:\n\ndf\n\nkey\n\ndata1\n\ndata2\n\n0\n\nA\n\n0\n\n5\n\n1\n\nB\n\n1\n\n..."
          ],
          [
           "3\n\nA\n\n3\n\n3\n\nB\n\n4\n\n7\n\nC\n\n5\n\n9\n\ndf2.groupby(mapping).sum()\n\ndata1\n\ndata2\n\nconsonant\n\n12\n\n19\n\nvowel\n\n3\n..."
          ],
          [
           "data1\n\ndata2\n\na\n\nvowel\n\n1.5\n\n4.0\n\nb\n\nconsonant\n\n2.5\n\n3.5\n\nc\n\nconsonant\n\n3.5\n\n6.0\n\nGrouping example¶A..."
          ],
          [
           "0.0\n\n1.0\n\n0.0\n\nRadial Velocity\n\n1.0\n\n52.0\n\n475.0\n\n424.0\n\nTransit\n\n0.0\n\n0.0\n\n64.0\n\n712.0\n\nTransit Tim..."
          ],
          [
           "Pivot Tables\n\n< Aggregation and Grouping | Contents | Vectorized String Operations >\n\nWe have seen h..."
          ],
          [
           "Southampton\n\nno\n\nFalse\n\n1\n\n1\n\n1\n\nfemale\n\n38.0\n\n1\n\n0\n\n71.2833\n\nC\n\nFirst\n\nwoman\n\nFalse\n\nC\n\nCherbourg\n\n..."
          ],
          [
           "titanic.groupby('sex')[['survived']].mean()\n\nOut[3]:\n\nsurvived\n\nsex\n\nfemale\n\n0.742038\n\nmale\n\n0.18890..."
          ],
          [
           "titanic.pivot_table('survived', index='sex', columns='class')\n\nOut[5]:\n\nclass\n\nFirst\n\nSecond\n\nThird\n..."
          ],
          [
           "0.800000\n\n0.600000\n\n0.215686\n\n(18, 80]\n\n0.375000\n\n0.071429\n\n0.133663\n\nWe can apply the same strategy..."
          ],
          [
           "0.098039\n\n0.125000\n\n0.391304\n\n0.030303\n\n0.192308\n\nThe result is a four-dimensional aggregation with ..."
          ],
          [
           "Third\n\nsex\n\nfemale\n\n106.125798\n\n21.970121\n\n16.118810\n\n91.0\n\n70.0\n\n72.0\n\nmale\n\n67.226127\n\n19.741782\n\n..."
          ],
          [
           "Example: Birthrate Data¶As a more interesting example, let's take a look at the freely available dat..."
          ],
          [
           "In [13]:\n\nbirths['decade'] = 10\n\n(births['year'] // 10)\n\nbirths.pivot_table('births', index='decade'..."
          ],
          [
           "With a simple pivot table and plot() method, we can immediately see the annual trend in births by ge..."
          ],
          [
           "In [17]:\n\n# set 'day' column to integer; it originally was a string due to nulls births['day'] = bir..."
          ],
          [
           "[births.index.month, births.index.day])\n\nbirths_by_date.head()\n\nOut[20]:\n\n1  1    4009.225 2    4247..."
          ],
          [
           "In [22]:\n\n# Plot the results fig, ax = plt.subplots(figsize=(12, 4)) births_by_date.plot(ax=ax);\n\nIn..."
          ],
          [
           "Introducing Pandas String Operations¶We saw in previous sections how tools like NumPy and Pandas gen..."
          ],
          [
           "<ipython-input-3-fc1d891ab539> in <listcomp>(.0) 1 data = ['peter', 'Paul', None, 'MARY', 'gUIDO'] -..."
          ],
          [
           "len()\n\nlower()\n\ntranslate()\n\nislower()\n\nljust()\n\nupper()\n\nstartswith()\n\nisupper()\n\nrjust()\n\nfind()\n\n..."
          ],
          [
           "Still others return lists or other compound values for each element:\n\nIn [10]:\n\nmonte.str.split()\n\nO..."
          ],
          [
           "In [12]:\n\nmonte.str.findall(r'^[^AEIOU].\n\n[^aeiou]$')\n\nOut[12]:\n\n0    [Graham Chapman] 1            ..."
          ],
          [
           "monte.str[0:3]\n\nOut[13]:\n\n0    Gra 1    Joh 2    Ter 3    Eri 4    Ter 5    Mic dtype: object\n\nIndex..."
          ],
          [
           "B|D\n\nEric Idle\n\n4\n\nB|C\n\nTerry Jones\n\n5\n\nB|C|D\n\nMichael Palin\n\nThe get_dummies() routine lets you qui..."
          ],
          [
           "Example: Recipe Database¶These vectorized string operations become most useful in the process of cle..."
          ],
          [
           "line = f.readline()\n\npd.read_json(line).shape\n\nOut[19]:\n\n(2, 12)\n\nYes, apparently each line is a val..."
          ],
          [
           "There is a lot of information there, but much of it is in a very messy form, as is typical of data s..."
          ],
          [
           "In [27]:\n\nrecipes.ingredients.str.contains('[Cc]inamon').sum()\n\nOut[27]:\n\n11\n\nThis is the type of es..."
          ],
          [
           "False\n\nFalse\n\nFalse\n\nTrue\n\nFalse\n\nFalse\n\nFalse\n\n1\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\nFalse\n\n..."
          ],
          [
           "In [31]:\n\nrecipes.name[selection.index]\n\nOut[31]:\n\n2069      All cremat with a Little Gem, dandelion..."
          ],
          [
           "Working with Time Series\n\n< Vectorized String Operations | Contents | High-Performance Pandas: eval(..."
          ],
          [
           "In [1]:\n\nfrom datetime import datetime\n\ndatetime(year=2015, month=7, day=4)\n\nOut[1]:\n\ndatetime.datet..."
          ],
          [
           "In [4]:\n\nimport numpy as np\n\ndate = np.array('2015\n\n07\n\n04', dtype=np.datetime64)\n\ndate\n\nOut[4]:\n\nar..."
          ],
          [
           "07\n\n13', '2015\n\n07\n\n14', '2015\n\n07\n\n15'], dtype='datetime64[D]')\n\nBecause of the uniform type in Num..."
          ],
          [
           "In [8]:\n\nnp.datetime64('2015\n\n07\n\n04 12:59:59.50', 'ns')\n\nOut[8]:\n\nnumpy.datetime64('2015\n\n07\n\n04T12..."
          ],
          [
           "us\n\nMicrosecond\n\n± 2.9e6 years\n\n[290301 BC, 294241 AD]\n\nns Nanosecond ± 292 years [ 1678 AD, 2262 AD..."
          ],
          [
           "04 00:00:00')\n\nIn [10]:\n\ndate.strftime('%A')\n\nOut[10]:\n\n'Saturday'\n\nAdditionally, we can do NumPy-st..."
          ],
          [
           "Out[12]:\n\n2014-07-04    0 2014-08-04    1 2015-07-04    2 2015-08-04    3 dtype: int64\n\nNow that we ..."
          ],
          [
           "The most fundamental of these date/time objects are the Timestamp and DatetimeIndex objects. While t..."
          ],
          [
           "In [17]:\n\ndates\n\ndates[0]\n\nOut[17]:\n\nTimedeltaIndex(['0 days', '1 days', '3 days', '4 days', '5 days..."
          ],
          [
           "In [19]:\n\npd.date_range('2015\n\n07\n\n03', periods=8)\n\nOut[19]:\n\nDatetimeIndex(['2015\n\n07\n\n03', '2015\n\n..."
          ],
          [
           "07\n\n03 07:00:00'],\n\ndtype='datetime64[ns]', freq='H')\n\nTo create regular sequences of Period or Time..."
          ],
          [
           "Code\n\nDescription\n\nCode\n\nDescription\n\nD\n\nCalendar day\n\nB\n\nBusiness day\n\nW\n\nWeekly\n\nM\n\nMonth end\n\nBM\n..."
          ],
          [
           "W\n\nSUN, W\n\nMON, W\n\nTUE, W\n\nWED, etc.\n\nOn top of this, codes can be combined with numbers to specify ..."
          ],
          [
           "For more discussion of the use of frequencies and offsets, see the \"DateOffset\" section of the Panda..."
          ],
          [
           "2004\n\n08\n\n24\n\n55.56\n\n55.74\n\n51.73\n\n52.38\n\nNaN\n\n2004\n\n08\n\n25\n\n52.43\n\n53.95\n\n51.89\n\n52.95\n\nNaN\n\nFor si..."
          ],
          [
           "');\n\nplt.legend(['input', 'resample', 'asfreq'],\n\nloc='upper left');\n\nNotice the difference: at each..."
          ],
          [
           "The top panel is the default: non-business days are left as NA values and do not appear on the plot...."
          ],
          [
           "ax[2].legend(['tshift(900)'], loc=2) ax[2].get_xticklabels()[1].set(weight='heavy', color='red') ax[..."
          ],
          [
           "'one\n\nyear rolling_std': rolling.std()})\n\nax = data.plot(style=['\n\n', '-\n\n', ':'])\n\nax.lines[0].set_..."
          ],
          [
           "Once this dataset is downloaded, we can use Pandas to read the CSV output into a DataFrame. We will ..."
          ],
          [
           "35752.000000\n\nmean\n\n61.470267\n\n54.410774\n\n115.881042\n\nstd\n\n82.588484\n\n77.659796\n\n145.392385\n\nmin\n\n0...."
          ],
          [
           "weekly.plot(style=[':', '-\n\n', '\n\n'])\n\nplt.ylabel('Weekly bicycle count');\n\nThis shows us some inter..."
          ],
          [
           "In [43]:\n\nby_time = data.groupby(data.index.time).mean()\n\nhourly_ticks = 4\n\n60\n\n60\n\nnp.arange(6)\n\nby..."
          ],
          [
           "Now we'll use some of the Matplotlib tools described in Multiple Subplots to plot two panels side by..."
          ],
          [
           "High-Performance Pandas: eval() and query()\n\n< Working with Time Series | Contents | Further Resourc..."
          ],
          [
           "1 loop, best of 3: 266 ms per loop\n\nBut this abstraction can become less efficient when computing co..."
          ],
          [
           "In [6]:\n\nimport pandas as pd nrows, ncols = 100000, 100 rng = np.random.RandomState(42) df1, df2, df..."
          ],
          [
           "Arithmetic operators¶pd.eval() supports all arithmetic operators. For example:\n\nIn [11]:\n\nresult1 = ..."
          ],
          [
           "Out[14]:\n\nTrue\n\nObject attributes and indices¶pd.eval() supports access to object attributes via the..."
          ],
          [
           "3\n\n0.264038\n\n0.808055\n\n0.347197\n\n4\n\n0.589161\n\n0.252418\n\n0.557789\n\nUsing pd.eval() as above, we can c..."
          ],
          [
           "0.069087\n\n0.235615\n\n0.154374\n\n2\n\n0.677945\n\n0.433839\n\n0.652324\n\n3\n\n0.264038\n\n0.808055\n\n0.347197\n\n4\n\n0..."
          ],
          [
           "In [21]:\n\ndf.eval('D = (A\n\nB) / C', inplace=True)\n\ndf.head()\n\nOut[21]:\n\nA\n\nB\n\nC\n\nD\n\n0\n\n0.375506\n\n0.4..."
          ],
          [
           "Out[22]:\n\nTrue\n\nThe @ character here marks a variable name rather than a column name, and lets you e..."
          ],
          [
           "Out[25]:\n\nTrue\n\nPerformance: When to Use These Functions¶When considering whether to use these funct..."
          ],
          [
           "< Working with Time Series | Contents | Further Resources >\n\nFurther Resources | Python Data Science..."
          ],
          [
           "Pandas on PyVideo: From PyCon to SciPy to PyData, many conferences have featured tutorials from Pand..."
          ],
          [
           "Visualization with Matplotlib\n\n< Further Resources | Contents | Simple Line Plots >\n\nWe'll now take ..."
          ],
          [
           "In recent years, however, the interface and style of Matplotlib have begun to show their age. Newer ..."
          ],
          [
           "In [2]:\n\nplt.style.use('classic')\n\nThroughout this section, we will adjust this style as needed. Not..."
          ],
          [
           "plt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x))\n\nplt.show()\n\nYou can then run this script from the co..."
          ],
          [
           "Plotting from an IPython notebook¶The IPython notebook is a browser-based interactive data analysis ..."
          ],
          [
           "In [6]:\n\n!ls\n\nlh my_figure.png\n\nrw\n\nr\n\n--r\n\n--  1 jakevdp  staff    16K Aug 11 10:59 my_figure.png\n\n..."
          ],
          [
           "MATLAB-style Interface¶Matplotlib was originally written as a Python alternative for MATLAB users, a..."
          ],
          [
           "# Call plot() method on the appropriate object ax[0].plot(x, np.sin(x)) ax[1].plot(x, np.cos(x));\n\nF..."
          ],
          [
           "3. Data Manipulation with Pandas¶ Introducing Pandas Objects Data Indexing and Selection Operating o..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhitegrid')\n\ni..."
          ],
          [
           "In [5]:\n\nplt.plot(x, np.sin(x))\n\nplt.plot(x, np.cos(x));\n\nThat's all there is to plotting simple fun..."
          ],
          [
           "If no color is specified, Matplotlib will automatically cycle through a set of default colors for mu..."
          ],
          [
           "Adjusting the Plot: Axes Limits¶Matplotlib does a decent job of choosing default axes limits for you..."
          ],
          [
           "In [13]:\n\nplt.plot(x, np.sin(x))\n\nplt.axis('equal');\n\nFor more information on axis limits and the ot..."
          ],
          [
           "plt.axis('equal')\n\nplt.legend();\n\nAs you can see, the plt.legend() function keeps track of the line ..."
          ],
          [
           "< Visualization with Matplotlib | Contents | Simple Scatter Plots >\n\nSimple Scatter Plots | Python D..."
          ],
          [
           "In [3]:\n\nrng = np.random.RandomState(0) for marker in ['o', '. ', ',', 'x', '+', 'v', '^', '<', '>',..."
          ],
          [
           "In [6]:\n\nplt.scatter(x, y, marker='o');\n\nThe primary difference of plt.scatter from plt.plot is that..."
          ],
          [
           "s=100\n\nfeatures[3], c=iris.target, cmap='viridis')\n\nplt.xlabel(iris.feature_names[0])\n\nplt.ylabel(ir..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "plt.errorbar(x, y, yerr=dy, fmt='.k');\n\nHere the fmt is a format code controlling the appearance of ..."
          ],
          [
           "# Compute the Gaussian process fit gp = GaussianProcess(corr='cubic', theta0=1e-2, thetaL=1e-4, thet..."
          ],
          [
           "dyfit, yfit + dyfit,\n\ncolor='gray', alpha=0.2)\n\nplt.xlim(0, 10);\n\nNote what we've done here with the..."
          ],
          [
           "Density and Contour Plots\n\n< Visualizing Errors | Contents | Histograms, Binnings, and Density >\n\nSo..."
          ],
          [
           "X, Y = np.meshgrid(x, y) Z = f(X, Y)\n\nNow let's look at this with a standard line-only contour plot:..."
          ],
          [
           "In [6]:\n\nplt.contourf(X, Y, Z, 20, cmap='RdGy') plt.colorbar();\n\nThe colorbar makes it clear that th..."
          ],
          [
           "In [8]:\n\ncontours = plt.contour(X, Y, Z, 3, colors='black') plt.clabel(contours, inline=True, fontsi..."
          ],
          [
           "%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn\n\nwhi..."
          ],
          [
           "In [5]:\n\ncounts, bin_edges = np.histogram(data, bins=5) print(counts)\n\n[ 12 190 468 301  29]\n\nTwo-Di..."
          ],
          [
           "For the generalization of this histogram binning in dimensions higher than two, see the np.histogram..."
          ],
          [
           "# Plot the result as an image plt.imshow(Z.reshape(Xgrid.shape), origin='lower', aspect='auto', exte..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\nIn [2]:\n\n%matplotlib inline\n\nimp..."
          ],
          [
           "fig\n\nOut[6]:\n\nFor more information on available legend options, see the plt.legend docstring.\n\nChoos..."
          ],
          [
           "In [9]:\n\nimport pandas as pd\n\ncities = pd.read_csv('data/california_cities.csv')\n\n# Extract the data..."
          ],
          [
           "plt.title('California Cities: Area and Population');\n\nThe legend will always reference some object t..."
          ],
          [
           "# specify the lines and labels of the first legend ax.legend(lines[:2], ['line A', 'line B'], loc='u..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\nIn [2]:\n\n%matplotlib inline\n\nimp..."
          ],
          [
           "Sequential colormaps: These are made up of one continuous sequence of colors (e.g., binary or viridi..."
          ],
          [
           "cmap = grayscale_cmap(cmap)\n\ngrayscale = cmap(np.arange(cmap.N))\n\nfig, ax = plt.subplots(2, figsize=..."
          ],
          [
           "In [9]:\n\nview_colormap('RdBu')\n\nWe'll see examples of using some of these color maps as we continue...."
          ],
          [
           "plt.colorbar(extend='both')\n\nplt.clim(\n\n1, 1);\n\nNotice that in the left panel, the default color lim..."
          ],
          [
           "Because each digit is defined by the hue of its 64 pixels, we can consider each digit to be a point ..."
          ],
          [
           "< Customizing Plot Legends | Contents | Multiple Subplots >\n\nMultiple Subplots | Python Data Science..."
          ],
          [
           "In [2]:\n\nax1 = plt.axes()  # standard axes ax2 = plt.axes([0.65, 0.65, 0.2, 0.2])\n\nThe equivalent of..."
          ],
          [
           "The command plt.subplots_adjust can be used to adjust the spacing between these plots. The following..."
          ],
          [
           "In [6]:\n\nfig, ax = plt.subplots(2, 3, sharex='col', sharey='row')\n\nNote that by specifying sharex an..."
          ],
          [
           "plt.subplot(grid[1, :2])\n\nplt.subplot(grid[1, 2]);\n\nThis type of flexible grid alignment has a wide ..."
          ],
          [
           "< Customizing Colorbars | Contents | Text and Annotation >\n\nText and Annotation | Python Data Scienc..."
          ],
          [
           "In [2]:\n\nbirths = pd.read_csv('data/births.csv')\n\nquartiles = np.percentile(births['births'], [25, 5..."
          ],
          [
           "# Add labels to the plot style = dict(size=10, color='gray')\n\nax.text('2012-1-1', 3950, \"New Year's ..."
          ],
          [
           "Transforms and Text Position¶In the previous example, we have anchored our text annotations to data ..."
          ],
          [
           "Note that by default, the text is aligned above and to the left of the specified coordinates: here t..."
          ],
          [
           "x = np.linspace(0, 20, 1000) ax.plot(x, np.cos(x)) ax.axis('equal')\n\nax.annotate('local maximum', xy..."
          ],
          [
           "bbox=dict(boxstyle=\"round\", fc=\"none\", ec=\"gray\"),\n\nxytext=(10,\n\n40), textcoords='offset points', ha..."
          ],
          [
           "25', 4500),  xycoords='data',\n\nxytext=(\n\n120,\n\n60), textcoords='offset points',\n\nbbox=dict(boxstyle=..."
          ],
          [
           "ax.set_ylim(3600, 5400);\n\nYou'll notice that the specifications of the arrows and text boxes are ver..."
          ],
          [
           "Customizing Ticks\n\n< Text and Annotation | Contents | Customizing Matplotlib: Configurations and Sty..."
          ],
          [
           "In [3]:\n\nprint(ax.xaxis.get_major_locator())\n\nprint(ax.xaxis.get_minor_locator())\n\n<matplotlib.ticke..."
          ],
          [
           "ax.xaxis.set_major_formatter(plt.NullFormatter())\n\nNotice that we've removed the labels (but kept th..."
          ],
          [
           "In [7]:\n\nfig, ax = plt.subplots(4, 4, sharex=True, sharey=True)\n\nParticularly for the x ticks, the n..."
          ],
          [
           "# Set up grid, legend, and limits ax.grid(True) ax.legend(frameon=False) ax.axis('equal') ax.set_xli..."
          ],
          [
           "ax.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n\nfig\n\nOut[11]:\n\nThis is much better! No..."
          ],
          [
           "IndexFormatter Set the strings from a list of labels\n\nFixedFormatter Set the strings manually for th..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\nimport numpy as np\n\n%matplotlib ..."
          ],
          [
           "Changing the Defaults: rcParams¶Each time Matplotlib loads, it defines a runtime configuration (rc) ..."
          ],
          [
           "plt.hist(x);\n\nLet's see what simple line plots look like with these rc parameters:\n\nIn [7]:\n\nfor i i..."
          ],
          [
           "Let's create a function that will make two basic types of plot:\n\nIn [9]:\n\ndef hist_and_lines(): np.r..."
          ],
          [
           "In [13]:\n\nwith plt.style.context('ggplot'):\n\nhist_and_lines()\n\nBayesian Methods for Hackers( style¶T..."
          ],
          [
           "< Customizing Ticks | Contents | Three-Dimensional Plotting in Matplotlib >\n\nThree-Dimensional Plott..."
          ],
          [
           "Three-dimensional Points and Lines¶The most basic three-dimensional plot is a line or collection of ..."
          ],
          [
           "In [5]:\n\ndef f(x, y):\n\nreturn np.sin(np.sqrt(x *\n\n2 + y *\n\n2))\n\nx = np.linspace(\n\n6, 6, 30)\n\ny = np...."
          ],
          [
           "fig = plt.figure()\n\nax = plt.axes(projection='3d')\n\nax.plot_wireframe(X, Y, Z, color='black')\n\nax.se..."
          ],
          [
           "In [11]:\n\ntheta = 2\n\nnp.pi\n\nnp.random.random(1000)\n\nr = 6\n\nnp.random.random(1000)\n\nx = np.ravel(r\n\nn..."
          ],
          [
           "Example: Visualizing a Möbius strip¶A Möbius strip is similar to a strip of paper glued into a loop ..."
          ],
          [
           "np.cos(theta))\n\ny = np.ravel(r\n\nnp.sin(theta))\n\nz = np.ravel(w\n\nnp.sin(phi))\n\nFinally, to plot the o..."
          ],
          [
           "Geographic Data with Basemap\n\n< Three-Dimensional Plotting in Matplotlib | Contents | Visualization ..."
          ],
          [
           "The meaning of the arguments to Basemap will be discussed momentarily. The useful thing is that the ..."
          ],
          [
           "Map Projections¶The first thing to decide when using maps is what projection to use. You're probably..."
          ],
          [
           "# cycle through these lines and set the desired style for line in all_lines: line.set(linestyle='-',..."
          ],
          [
           "In [6]:\n\nfig = plt.figure(figsize=(8, 6), edgecolor='w') m = Basemap(projection='moll', resolution=N..."
          ],
          [
           "m = Basemap(projection='ortho', resolution=None,\n\nlat_0=50, lon_0=0)\n\ndraw_map(m);\n\nConic projection..."
          ],
          [
           "Drawing a Map Background¶Earlier we saw the bluemarble() and shadedrelief() methods for projecting g..."
          ],
          [
           "For the boundary-based features, you must set the desired resolution when creating a Basemap image. ..."
          ],
          [
           "Plotting Data on Maps¶Perhaps the most useful piece of the Basemap toolkit is the ability to over-pl..."
          ],
          [
           "Next, we set up the map projection, scatter the data, and then create a colorbar and legend:\n\nIn [11..."
          ],
          [
           "Example: Surface Temperature Data¶As an example of visualizing some more continuous geographic data,..."
          ],
          [
           "Finally, we'll use the pcolormesh() method to draw a color mesh of the data. We'll look at North Ame..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "In [1]:\n\nimport matplotlib.pyplot as plt\n\nplt.style.use('classic')\n\n%matplotlib inline\n\nimport numpy..."
          ],
          [
           "Ah, much better!\n\nExploring Seaborn Plots¶The main idea of Seaborn is that it provides high-level co..."
          ],
          [
           "In [9]:\n\nsns.kdeplot(data);\n\nWe can see the joint distribution and the marginal distributions togeth..."
          ],
          [
           "4.7\n\n3.2\n\n1.3\n\n0.2\n\nsetosa\n\n3\n\n4.6\n\n3.1\n\n1.5\n\n0.2\n\nsetosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nVisualizin..."
          ],
          [
           "23.68\n\n3.31\n\nMale\n\nNo\n\nSun\n\nDinner\n\n2\n\n4\n\n24.59\n\n3.61\n\nFemale\n\nNo\n\nSun\n\nDinner\n\n4\n\nIn [15]:\n\ntips['t..."
          ],
          [
           "In [18]:\n\nsns.jointplot(\"total_bill\", \"tip\", data=tips, kind='reg');\n\nBar plots¶Time series can be p..."
          ],
          [
           "We can learn more by looking at the method of discovery of each of these planets:\n\nIn [21]:\n\nwith sn..."
          ],
          [
           "02:10:42\n\n3\n\n38\n\nM\n\n01:06:16\n\n02:13:45\n\n4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nBy default, Pandas loaded the ..."
          ],
          [
           "4\n\n31\n\nM\n\n01:06:32\n\n02:13:59\n\nIn [26]:\n\ndata.dtypes\n\nOut[26]:\n\nage                 int64 gender     ..."
          ],
          [
           "02:13:59\n\n3992.0\n\n8039.0\n\nTo get an idea of what the data looks like, we can plot a jointplot over t..."
          ],
          [
           "02:09:28\n\n3986.0\n\n7768.0\n\n0.026262\n\n2\n\n31\n\nM\n\n01:06:49\n\n02:10:42\n\n4009.0\n\n7842.0\n\n0.022443\n\n3\n\n38\n\nM..."
          ],
          [
           "It looks like the split fraction does not correlate particularly with age, but does correlate with t..."
          ],
          [
           "Out[35]:\n\nage\n\ngender\n\nsplit\n\nfinal\n\nsplit_sec\n\nfinal_sec\n\nsplit_frac\n\nage_dec\n\n0\n\n33\n\nM\n\n01:05:38\n\n..."
          ],
          [
           "split=True, inner=\"quartile\",\n\npalette=[\"lightblue\", \"lightpink\"]);\n\nLooking at this, we can see whe..."
          ],
          [
           "The text is released under the CC-BY-NC-ND license, and code is released under the MIT license. If y..."
          ],
          [
           "Other Python Graphics Libraries¶Although Matplotlib is the most prominent Python visualization libra..."
          ],
          [
           "Machine Learning\n\n< Further Resources | Contents | What Is Machine Learning? >\n\nIn many ways, machin..."
          ],
          [
           "< Further Resources | Contents | What Is Machine Learning? >\n\nPython Data Science Handbook | Python ..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ],
          [
           "Categories of Machine Learning¶At the most fundamental level, machine learning can be categorized in..."
          ],
          [
           "figure source in Appendix\n\nHere we have two-dimensional data: that is, we have two features for each..."
          ],
          [
           "feature 1, feature 2, etc. $\\to$ normalized counts of important words or phrases (\"Viagra\", \"Nigeria..."
          ],
          [
           "figure source in Appendix\n\nNotice that the feature 1-feature 2 plane here is the same as in the two-..."
          ],
          [
           "Clustering: Inferring labels on unlabeled data¶The classification and regression illustrations we ju..."
          ],
          [
           "figure source in Appendix\n\nVisually, it is clear that there is some structure in this data: it is dr..."
          ],
          [
           "Clustering: Models that detect and identify distinct groups in the data Dimensionality reduction: Mo..."
          ],
          [
           "Data Representation in Scikit\n\nLearn¶\n\nMachine learning is about creating models from data: for that..."
          ],
          [
           "0.2\n\nsetosa\n\n4\n\n5.0\n\n3.6\n\n1.4\n\n0.2\n\nsetosa\n\nHere each row of the data refers to a single observed fl..."
          ],
          [
           "Target array¶In addition to the feature matrix X, we also generally work with a label or target arra..."
          ],
          [
           "figure source in Appendix\n\nWith this data properly formatted, we can move on to consider the estimat..."
          ],
          [
           "We will now step through several simple examples of applying supervised and unsupervised learning me..."
          ],
          [
           "These are examples of the important choices that must be made once the model class is selected. Thes..."
          ],
          [
           "In [9]:\n\nmodel.fit(X, y)\n\nOut[9]:\n\nLinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, norma..."
          ],
          [
           "In [12]:\n\nxfit = np.linspace(\n\n1, 11)\n\nAs before, we need to coerce these x values into a [n_samples..."
          ],
          [
           "With the data arranged, we can follow our recipe to predict the labels:\n\nIn [16]:\n\nfrom sklearn.naiv..."
          ],
          [
           "Now let's plot the results. A quick way to do this is to insert the results into the original Iris D..."
          ],
          [
           "sns.lmplot(\"PCA1\", \"PCA2\", data=iris, hue='species',\n\ncol='cluster', fit_reg=False);\n\nBy splitting t..."
          ],
          [
           "for i, ax in enumerate(axes.flat): ax.imshow(digits.images[i], cmap='binary', interpolation='nearest..."
          ],
          [
           "data_projected = iso.transform(digits.data)\n\ndata_projected.shape\n\nOut[26]:\n\n(1797, 2)\n\nWe see that ..."
          ],
          [
           "In [29]:\n\nfrom sklearn.naive_bayes import GaussianNB\n\nmodel = GaussianNB()\n\nmodel.fit(Xtrain, ytrain..."
          ],
          [
           "test_images = Xtest.reshape(\n\n1, 8, 8)\n\nfor i, ax in enumerate(axes.flat): ax.imshow(test_images[i],..."
          ],
          [
           "Hyperparameters and Model Validation\n\n< Introducing Scikit-Learn | Contents | Feature Engineering >\n..."
          ],
          [
           "Then we train the model, and use it to predict labels for data we already know:\n\nIn [3]:\n\nmodel.fit(..."
          ],
          [
           "# evaluate the model on the second set of data y2_model = model.predict(X2) accuracy_score(y2, y2_mo..."
          ],
          [
           "Out[6]:\n\n(0.95999999999999996, 0.90666666666666662)\n\nWhat comes out are two accuracy scores, which w..."
          ],
          [
           "In [8]:\n\nfrom sklearn.cross_validation import LeaveOneOut scores = cross_val_score(model, X, y, cv=L..."
          ],
          [
           "from sklearn.cross_validation import LeaveOneOut scores = cross_val_score(model, X, y, cv=LeaveOneOu..."
          ],
          [
           "Because we have 150 samples, the leave one out cross-validation yields scores for 150 trials, and th..."
          ],
          [
           "The Bias-variance trade-off¶Fundamentally, the question of \"the best model\" is about finding a sweet..."
          ],
          [
           "If we imagine that we have some ability to tune the model complexity, we would expect the training s..."
          ],
          [
           "In [10]:\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.linear_model import Lin..."
          ],
          [
           "The knob controlling model complexity in this case is the degree of the polynomial, which can be any..."
          ],
          [
           "y_test = PolynomialRegression(3).fit(X, y).predict(X_test)\n\nplt.plot(X_test.ravel(), y_test);\n\nplt.a..."
          ],
          [
           "The solid lines show the new results, while the fainter dashed lines show the results of the previou..."
          ],
          [
           "In [17]:\n\nfrom sklearn.learning_curve import learning_curve\n\nfig, ax = plt.subplots(1, 2, figsize=(1..."
          ],
          [
           "ax[i].set_title('degree = {0}'.format(degree), size=14)\n\nax[i].legend(loc='best')\n\nThis is a valuabl..."
          ],
          [
           "from sklearn.grid_search import GridSearchCV\n\nparam_grid = {'polynomialfeatures__degree': np.arange(..."
          ],
          [
           "Summary¶In this section, we have begun to explore the concept of model validation and hyperparameter..."
          ],
          [
           "Categorical Features¶One common type of non-numerical data is categorical data. For example, imagine..."
          ],
          [
           "vec = DictVectorizer(sparse=False, dtype=int)\n\nvec.fit_transform(data)\n\nOut[3]:\n\narray([[     0,    ..."
          ],
          [
           "Text Features¶Another common need in feature engineering is to convert text to a set of representati..."
          ],
          [
           "0\n\n0\n\n0\n\n1\n\n2\n\n0\n\n1\n\n0\n\n1\n\n0\n\nThere are some issues with this approach, however: the raw word counts..."
          ],
          [
           "0.605349\n\n0.000000\n\nFor an example of using TF-IDF in a classification problem, see In Depth: Naive ..."
          ],
          [
           "yfit = model.predict(X)\n\nplt.scatter(x, y)\n\nplt.plot(x, yfit);\n\nIt's clear that we need a more sophi..."
          ],
          [
           "In [14]:\n\nfrom numpy import nan X = np.array([[ nan, 0,   3  ], [ 3,   7,   9  ], [ 3,   5,   2  ], ..."
          ],
          [
           "array([ 13.14869292,  14.3784627 ,  -1.15539732,  10.96606197,  -5.33782027])\n\nFeature Pipelines¶Wit..."
          ],
          [
           "In Depth: Naive Bayes Classification | Python Data Science Handbook\n\nPython Data Science Handbook\n\nA..."
          ],
          [
           "Bayesian Classification¶Naive Bayes classifiers are built on Bayesian classification methods. These ..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import numpy as np import matplotlib.pyplot as plt import seaborn as sns..."
          ],
          [
           "model = GaussianNB()\n\nmodel.fit(X, y);\n\nNow let's generate some new data and predict the label:\n\nIn ..."
          ],
          [
           "The columns give the posterior probabilities of the first and second label, respectively. If you are..."
          ],
          [
           "windows.misc',\n\n'comp.sys.ibm.pc.hardware',\n\n'comp.sys.mac.hardware',\n\n'comp.windows.x',\n\n'misc.fors..."
          ],
          [
           "Fact or rumor....? Madalyn Murray O'Hare an atheist who eliminated the use of the bible reading and ..."
          ],
          [
           "Evidently, even this very simple classifier can successfully separate space talk from computer talk,..."
          ],
          [
           "They are extremely fast for both training and prediction They provide straightforward probabilistic ..."
          ],
          [
           "In Depth: Linear Regression\n\n< In Depth: Naive Bayes Classification | Contents | In-Depth: Support V..."
          ],
          [
           "model = LinearRegression(fit_intercept=True)\n\nmodel.fit(x[:, np.newaxis], y)\n\nxfit = np.linspace(0, ..."
          ],
          [
           "model.fit(X, y)\n\nprint(model.intercept_)\n\nprint(model.coef_)\n\n0.5 [ 1.5 -2. 1. ]\n\nHere the $y$ data ..."
          ],
          [
           "Polynomial basis functions¶This polynomial projection is useful enough that it is built into Scikit-..."
          ],
          [
           "plt.plot(xfit, yfit);\n\nOur linear model, through the use of 7th-order polynomial basis functions, ca..."
          ],
          [
           "def transform(self, X): return self._gauss_basis(X[:, :, np.newaxis], self.centers_, self.width_, ax..."
          ],
          [
           "plt.xlim(0, 10)\n\nplt.ylim(\n\n1.5, 1.5);\n\nWith the data projected to the 30-dimensional basis, the mod..."
          ],
          [
           "Ridge regression ($L_2$ Regularization)¶Perhaps the most common form of regularization is known as r..."
          ],
          [
           "from sklearn.linear_model import Lasso\n\nmodel = make_pipeline(GaussianFeatures(30), Lasso(alpha=0.00..."
          ],
          [
           "o FremontBridge.csv https://data.seattle.gov/api/views/65db\n\nxm6k/rows.csv?accessType=DOWNLOAD\n\nIn [..."
          ],
          [
           "We also might suspect that the hours of daylight would affect how many people ride; let's use the st..."
          ],
          [
           "daily = daily.join(weather[['PRCP', 'Temp (C)', 'dry day']])\n\nFinally, let's add a counter that incr..."
          ],
          [
           "13.60\n\n1.0\n\n0.002740\n\n2012\n\n10\n\n05\n\n3148.0\n\n0.0\n\n0.0\n\n0.0\n\n0.0\n\n1.0\n\n0.0\n\n0.0\n\n0.0\n\n11.161038\n\n0.0\n\n..."
          ],
          [
           "In [23]:\n\n# Drop any rows with null values daily.dropna(axis=0, how='any', inplace=True)\n\ncolumn_nam..."
          ],
          [
           "These numbers are difficult to interpret without some measure of their uncertainty. We can compute t..."
          ],
          [
           "We first see that there is a relatively stable trend in the weekly baseline: there are many more rid..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom scipy import ..."
          ],
          [
           "In [3]:\n\nxfit = np.linspace(-1, 3.5) plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plt.plo..."
          ],
          [
           "for m, b, d in [(1, 0.65, 0.33), (0.5, 1.6, 0.55), (-0.2, 2.9, 0.2)]: yfit = m * xfit + b plt.plot(x..."
          ],
          [
           "To better visualize what's happening here, let's create a quick convenience function that will plot ..."
          ],
          [
           "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') plot_svc_decision_function(model);\n\nThis is ..."
          ],
          [
           "ax = ax or plt.gca() ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn') ax.set_xlim(-1, 4) ax.se..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets.samples_generator import make_circles X, y = make_circles(100, facto..."
          ],
          [
           "90, 90], azip=(\n\n180, 180),\n\nX=fixed(X), y=fixed(y));\n\nWe can see that with this additional dimensio..."
          ],
          [
           "max_iter=\n\n1, probability=False, random_state=None, shrinking=True,\n\ntol=0.001, verbose=False)\n\nIn [..."
          ],
          [
           "In [17]:\n\nX, y = make_blobs(n_samples=100, centers=2, random_state=0, cluster_std=0.8)\n\nfig, ax = pl..."
          ],
          [
           "faces = fetch_lfw_people(min_faces_per_person=60)\n\nprint(faces.target_names)\n\nprint(faces.images.sha..."
          ],
          [
           "For the sake of testing our classifier output, we will split the data into a training and testing se..."
          ],
          [
           "yfit = model.predict(Xtest)\n\nLet's take a look at a few of the test images along with their predicte..."
          ],
          [
           "avg / total       0.85      0.85      0.85       337\n\nWe might also display the confusion matrix bet..."
          ],
          [
           "However, SVMs have several disadvantages as well:\n\nThe scaling with the number of samples $N$ is $\\m..."
          ],
          [
           "In-Depth: Decision Trees and Random Forests\n\n< In-Depth: Support Vector Machines | Contents | In Dep..."
          ],
          [
           "Creating a decision tree¶Consider the following two-dimensional data, which has one of four class la..."
          ],
          [
           "In [4]:\n\ndef visualize_classifier(model, X, y, ax=None, cmap='rainbow'): ax = ax or plt.gca()\n\n# Plo..."
          ],
          [
           "If you're running this notebook live, you can use the helpers script included in The Online Appendix..."
          ],
          [
           "Just as using information from two trees improves our results, we might expect that using informatio..."
          ],
          [
           "In [9]:\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(n_estim..."
          ],
          [
           "from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(200)\n\nforest.fit(..."
          ],
          [
           "# plot the digits: each image is 8x8 pixels for i in range(64): ax = fig.add_subplot(8, 8, i + 1, xt..."
          ],
          [
           "avg / total       0.98      0.98      0.98       450\n\nAnd for good measure, plot the confusion matri..."
          ],
          [
           "In Depth: Principal Component Analysis\n\n< In-Depth: Decision Trees and Random Forests | Contents | I..."
          ],
          [
           "By eye, it is clear that there is a nearly linear relationship between the x and y variables. This i..."
          ],
          [
           "# plot data plt.scatter(X[:, 0], X[:, 1], alpha=0.2) for length, vector in zip(pca.explained_varianc..."
          ],
          [
           "The transformed data has been reduced to a single dimension. To understand the effect of this dimens..."
          ],
          [
           "In [10]:\n\npca = PCA(2)  # project from 64 to 2 dimensions projected = pca.fit_transform(digits.data)..."
          ],
          [
           "What do the components mean?¶We can go a bit further here, and begin to ask what the reduced dimensi..."
          ],
          [
           "But the pixel-wise representation is not the only choice of basis. We can also use other basis funct..."
          ],
          [
           "plt.xlabel('number of components')\n\nplt.ylabel('cumulative explained variance');\n\nThis curve quantif..."
          ],
          [
           "In [14]:\n\nnp.random.seed(42)\n\nnoisy = np.random.normal(digits.data, 4)\n\nplot_digits(noisy)\n\nIt's cle..."
          ],
          [
           "Let's take a look at the principal axes that span this dataset. Because this is a large dataset, we ..."
          ],
          [
           "In [20]:\n\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\n\nplt.xlabel('number of components')\n\npl..."
          ],
          [
           "dim\\ninput')\n\nax[1, 0].set_ylabel('150\n\ndim\\nreconstruction');\n\nThe top row here shows the input ima..."
          ],
          [
           "RandomizedPCA, which we saw earlier, uses a non-deterministic method to quickly approximate the firs..."
          ],
          [
           "In\n\nDepth: Manifold Learning\n\n< In Depth: Principal Component Analysis | Contents | In Depth: k-Mean..."
          ],
          [
           "In [2]:\n\ndef make_hello(N=1000, rseed=42): # Make a plot with \"HELLO\" text; save as PNG fig, ax = pl..."
          ],
          [
           "The output is two dimensional, and consists of points drawn in the shape of the word, \"HELLO\". This ..."
          ],
          [
           "Out[5]:\n\n(1000, 1000)\n\nAs promised, for our N=1,000 points, we obtain a 1000×1000 matrix, which can ..."
          ],
          [
           "The MDS algorithm recovers one of the possible two-dimensional coordinate representations of our dat..."
          ],
          [
           "This is essentially the goal of a manifold learning estimator: given high-dimensional embedded data,..."
          ],
          [
           "In [14]:\n\nfrom sklearn.manifold import MDS model = MDS(n_components=2, random_state=2) outS = model...."
          ],
          [
           "In [15]:\n\nfrom sklearn.manifold import LocallyLinearEmbedding model = LocallyLinearEmbedding(n_neigh..."
          ],
          [
           "With all that on the table, the only clear advantage of manifold learning methods over PCA is their ..."
          ],
          [
           "faces = fetch_lfw_people(min_faces_per_person=30)\n\nfaces.data.shape\n\nOut[16]:\n\n(2370, 2914)\n\nWe have..."
          ],
          [
           "In [19]:\n\nfrom sklearn.manifold import Isomap\n\nmodel = Isomap(n_components=2)\n\nproj = model.fit_tran..."
          ],
          [
           "Calling this function now, we see the result:\n\nIn [21]:\n\nfig, ax = plt.subplots(figsize=(10, 10)) pl..."
          ],
          [
           "This gives us an idea of the variety of handwriting styles in the dataset. Let's compute a manifold ..."
          ],
          [
           "The result gives you an idea of the variety of forms that the number \"1\" can take within the dataset..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import matplotlib.pyplot as plt import seaborn as sns; sns.set()  # for ..."
          ],
          [
           "Let's visualize the results by plotting the data colored by these labels. We will also plot the clus..."
          ],
          [
           "Guess some cluster centers Repeat until converged E-Step: assign points to the nearest cluster cente..."
          ],
          [
           "# 2c. Check for convergence if np.all(centers == new_centers): break centers = new_centers\n\nreturn c..."
          ],
          [
           "Whether the result is meaningful is a question that is difficult to answer definitively; one approac..."
          ],
          [
           "In [10]:\n\nfrom sklearn.cluster import SpectralClustering model = SpectralClustering(n_clusters=2, af..."
          ],
          [
           "In [11]:\n\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\n\ndigits.data.shape\n\nOut[1..."
          ],
          [
           "Now we can check how accurate our unsupervised clustering was in finding similar digits within the d..."
          ],
          [
           "# Compute the clusters\n\nkmeans = KMeans(n_clusters=10, random_state=0)\n\nclusters = kmeans.fit_predic..."
          ],
          [
           "In [19]:\n\nchina.shape\n\nOut[19]:\n\n(427, 640, 3)\n\nOne way we can view this set of pixels is as a cloud..."
          ],
          [
           "fig.suptitle(title, size=20);\n\nIn [22]:\n\nplot_pixels(data, title='Input color space: 16 million poss..."
          ],
          [
           "Some detail is certainly lost in the rightmost panel, but the overall image is still easily recogniz..."
          ],
          [
           "In [1]:\n\n%matplotlib inline import matplotlib.pyplot as plt import seaborn as sns; sns.set() import ..."
          ],
          [
           "From an intuitive standpoint, we might expect that the clustering assignment for some points is more..."
          ],
          [
           "In [5]:\n\nkmeans = KMeans(n_clusters=4, random_state=0)\n\nplot_kmeans(kmeans, X)\n\nAn important observa..."
          ],
          [
           "Generalizing E–M: Gaussian Mixture Models¶A Gaussian mixture model (GMM) attempts to find a mixture ..."
          ],
          [
           "Under the hood, a Gaussian mixture model is very similar to k-means: it uses an expectation–maximiza..."
          ],
          [
           "# Draw the Ellipse for nsig in range(1, 4): ax.add_patch(Ellipse(position, nsig * width, nsig * heig..."
          ],
          [
           "This makes clear that GMM addresses the two main practical issues with k-means encountered before.\n\n..."
          ],
          [
           "If we try to fit this with a two-component GMM viewed as a clustering model, the results are not par..."
          ],
          [
           "plt.scatter(Xnew[:, 0], Xnew[:, 1]);\n\nGMM is convenient as a flexible means of modeling an arbitrary..."
          ],
          [
           "The optimal number of clusters is the value that minimizes the AIC or BIC, depending on which approx..."
          ],
          [
           "We have nearly 1,800 digits in 64 dimensions, and we can build a GMM on top of these to generate mor..."
          ],
          [
           "data_new = gmm.sample(100, random_state=0)\n\ndata_new.shape\n\nOut[23]:\n\n(100, 41)\n\nFinally, we can use..."
          ],
          [
           "In\n\nDepth: Kernel Density Estimation\n\n< In Depth: Gaussian Mixture Models | Contents | Application: ..."
          ],
          [
           "x = rand.randn(N)\n\nx[int(f\n\nN):] += 5\n\nreturn x\n\nx = make_data(1000)\n\nWe have previously seen that t..."
          ],
          [
           "In [5]:\n\nx = make_data(20)\n\nbins = np.linspace(\n\n5, 10, 10)\n\nIn [6]:\n\nfig, ax = plt.subplots(1, 2, f..."
          ],
          [
           "Out[7]:\n\n(\n\n0.2, 8)\n\nThe problem with our two binnings stems from the fact that the height of the bl..."
          ],
          [
           "plt.fill_between(x_d, density, alpha=0.5)\n\nplt.plot(x, np.full_like(x,\n\n0.1), '|k', markeredgewidth=..."
          ],
          [
           "In [10]:\n\nfrom sklearn.neighbors import KernelDensity\n\n# instantiate and fit the KDE model kde = Ker..."
          ],
          [
           "Out[10]:\n\n(\n\n0.02, 0.22)\n\nThe result here is normalized such that the area under the curve is equal ..."
          ],
          [
           "{'bandwidth': bandwidths},\n\ncv=LeaveOneOut(len(x)))\n\ngrid.fit(x[:, None]);\n\nNow we can find the choi..."
          ],
          [
           "With this data loaded, we can use the Basemap toolkit (mentioned previously in Geographic Data with ..."
          ],
          [
           "In [15]:\n\n# Set up the data grid for the contour plot X, Y = np.meshgrid(xgrid[::5], ygrid[::5][::-1..."
          ],
          [
           "# plot contours of the density levels = np.linspace(0, Z.max(), 25) axi.contourf(X, Y, Z, levels=lev..."
          ],
          [
           "In [16]:\n\nfrom sklearn.base import BaseEstimator, ClassifierMixin\n\nclass KDEClassifier(BaseEstimator..."
          ],
          [
           "Parameters ---------- bandwidth : float the kernel bandwidth within each class kernel : str the kern..."
          ],
          [
           "Here we find the unique classes in the training data, train a KernelDensity model for each class, an..."
          ],
          [
           "In [17]:\n\nfrom sklearn.datasets import load_digits\n\nfrom sklearn.grid_search import GridSearchCV\n\ndi..."
          ],
          [
           "Out[19]:\n\n0.81860038035501381\n\nOne benefit of such a generative classifier is interpretability of re..."
          ],
          [
           "Application: A Face Detection Pipeline\n\n< In-Depth: Kernel Density Estimation | Contents | Further M..."
          ],
          [
           "HOG Features¶The Histogram of Gradients is a straightforward feature extraction procedure that was d..."
          ],
          [
           "Obtain a set of image thumbnails of faces to constitute \"positive\" training samples. Obtain a set of..."
          ],
          [
           "In [5]:\n\nfrom sklearn.feature_extraction.image import PatchExtractor\n\ndef extract_patches(img, N, sc..."
          ],
          [
           "from itertools import chain\n\nX_train = np.array([feature.hog(im)\n\nfor im in chain(positive_patches,\n..."
          ],
          [
           "In [10]:\n\nfrom sklearn.svm import LinearSVC from sklearn.grid_search import GridSearchCV grid = Grid..."
          ],
          [
           "test_image = skimage.transform.rescale(test_image, 0.5)\n\ntest_image = test_image[:160, 40:180]\n\nplt...."
          ],
          [
           "In [16]:\n\nfig, ax = plt.subplots()\n\nax.imshow(test_image, cmap='gray')\n\nax.axis('off')\n\nNi, Nj = pos..."
          ],
          [
           "In fact, the sliding_window() utility used here is already built with this in mind. We should combin..."
          ],
          [
           "Python Data Science Handbook\n\nAbout\n\nArchive\n\nThis is an excerpt from the Python Data Science Handbo..."
          ],
          [
           "General Machine Learning¶Of course, machine learning is much broader than just the Python world. The..."
          ],
          [
           "In [1]:\n\n%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nimport seaborn as ..."
          ],
          [
           "x, y = xy\n\nif 1 in edges: ax.plot([x, x + size], [y + size, y + size], **kwargs) if 2 in edges: ax.p..."
          ],
          [
           "label_kwargs = {}\n\nax.text(x + 0.5\n\nsize, y + 0.5\n\nsize, label,\n\nha='center', va='center', *\n\nlabel_..."
          ],
          [
           "draw_cube(ax, (12, 10), 1, depth, [1, 2, 3, 4, 5, 6, 9], '5', **solid) draw_cube(ax, (13, 10), 1, de..."
          ],
          [
           "draw_cube(ax, (1, 6.5), 1, depth, [2, 3, 4], '1', **solid) draw_cube(ax, (2, 6.5), 1, depth, [2, 3],..."
          ],
          [
           "draw_cube(ax, (6, 5.5), 1, depth, [2, 3, 4, 7, 8, 10, 11, 12], '0', **dotted) draw_cube(ax, (7, 5.5)..."
          ],
          [
           "ax.text(5, 7.0, '+', size=12, ha='center', va='center') ax.text(10.5, 7.0, '=', size=12, ha='center'..."
          ],
          [
           "draw_cube(ax, (3, 3), 1, depth, [1, 2, 3, 6, 7, 9, 10, 11], '0', **dotted) draw_cube(ax, (3, 2), 1, ..."
          ],
          [
           "# third block draw_cube(ax, (12, 3), 1, depth, [1, 2, 3, 4, 5, 6, 9], '0', **solid) draw_cube(ax, (1..."
          ],
          [
           "ax.set_ylim(0.5, 12.5)\n\nfig.savefig('figures/02.05\n\nbroadcasting.png')\n\nAggregation and Grouping¶Fig..."
          ],
          [
           "# Create column labels for i in range(ncols - 1): plt.text(x + (i + 1.5) * dx, y + (nrows - 0.5) * d..."
          ],
          [
           "ax.axis('off')\n\ndraw_dataframe(df, [0, 0])\n\nfor y, ind in zip([3, 1, -1], 'ABC'): split = df[df.inde..."
          ],
          [
           "plt.annotate('', (3.8, 3.8), (3.2, 3.8), arrowprops=arrowprops) plt.annotate('', (3.8, 1.75), (3.2, ..."
          ],
          [
           "In [6]:\n\nfrom sklearn.datasets.samples_generator import make_blobs\n\nfrom sklearn.svm import SVC\n\n# c..."
          ],
          [
           "# plot points and model fig, ax = plt.subplots(figsize=(8, 6)) line_style = dict(levels = [-1.0, 0.0..."
          ],
          [
           "fig.savefig('figures/05.01\n\nclassification\n\n3.png')\n\nRegression Example Figures¶Figure Context The f..."
          ],
          [
           "# plot points in 3D fig = plt.figure() ax = fig.add_subplot(111, projection='3d') ax.scatter(X[:, 0]..."
          ],
          [
           "regression\n\n2.png')\n\nRegression Example Figure 3¶\n\nIn [13]:\n\nfrom matplotlib.collections import Line..."
          ],
          [
           "ax[1].scatter(X2[:, 0], X2[:, 1], c=y2, s=50, cmap='viridis', norm=pts.norm) ax[1].axis([-4, 4, -3, ..."
          ],
          [
           "# format the plot\n\nformat_plot(ax, 'Learned Cluster Labels')\n\nfig.savefig('figures/05.01\n\nclustering..."
          ],
          [
           "fig.savefig('figures/05.01\n\ndimesionality\n\n2.png')\n\nIntroducing Scikit\n\nLearn¶\n\nFeatures and Labels ..."
          ],
          [
           "2)\n\nfig.savefig('figures/05.02\n\nsamples\n\nfeatures.png')\n\nHyperparameters and Model Validation¶\n\nCros..."
          ],
          [
           "fig.savefig('figures/05.03\n\n5\n\nfold\n\nCV.png')\n\nOverfitting and Underfitting¶\n\nIn [24]:\n\nimport numpy..."
          ],
          [
           "ax[0].scatter(X.ravel(), y, s=40) ax[0].plot(xfit.ravel(), model1.predict(xfit), color='gray') ax[0]..."
          ],
          [
           "X2, y2 = make_data(10, rseed=42)\n\nax[0].scatter(X.ravel(), y, s=40, c='blue') ax[0].plot(xfit.ravel(..."
          ],
          [
           "ax[1].scatter(X.ravel(), y, s=40, c='blue') ax[1].plot(xfit.ravel(), model20.predict(xfit), color='g..."
          ],
          [
           "ax.text(0.15, 0.2, \"training score\", rotation=45, size=16, color='blue') ax.text(0.2, -0.05, \"valida..."
          ],
          [
           "fig, ax = plt.subplots() ax.plot(x, y1, lw=10, alpha=0.5, color='blue') ax.plot(x, y2, lw=10, alpha=..."
          ],
          [
           "from sklearn.datasets import make_blobs X, y = make_blobs(100, 2, centers=2, random_state=2, cluster..."
          ],
          [
           "fig.savefig('figures/05.05\n\ngaussian\n\nNB.png')\n\nLinear Regression¶Gaussian Basis Functions¶Figure Co..."
          ],
          [
           "LinearRegression())\n\ngauss_model.fit(x[:, np.newaxis], y)\n\nyfit = gauss_model.predict(xfit[:, np.new..."
          ],
          [
           "def visualize_tree(estimator, X, y, boundaries=True, xlim=None, ylim=None, ax=None): ax = ax or plt...."
          ],
          [
           "ax.plot([tree.threshold[i], tree.threshold[i]], ylim, '\n\nk', zorder=2)\n\nplot_boundaries(tree.childre..."
          ],
          [
           "def fit_randomized_tree(random_state=0):\n\nclf = DecisionTreeClassifier(max_depth=15)\n\ni = np.arange(..."
          ],
          [
           "text(ax, 0.5, 0.9, \"How big is\\nthe animal? \", 20) text(ax, 0.3, 0.6, \"Does the animal\\nhave horns? ..."
          ],
          [
           "text(ax, 0.66, 0.45, \"yes\", 12, alpha=0.4) text(ax, 0.79, 0.45, \"no\", 12, alpha=0.4)\n\nax.plot([0.3, ..."
          ],
          [
           "X, y = make_blobs(n_samples=300, centers=4, random_state=0, cluster_std=1.0)\n\nfor axi, depth in zip(..."
          ],
          [
           "In [38]:\n\nrng = np.random.RandomState(1) X = np.dot(rng.rand(2, 2), rng.randn(2, 200)).T pca = PCA(n..."
          ],
          [
           "fig.savefig('figures/05.09\n\nPCA\n\nrotation.png')\n\nDigits Pixel Components¶\n\nIn [39]:\n\ndef plot_pca_co..."
          ],
          [
           "for i in range(n_components): approx = approx + coefficients[i] * components[i] show(0, i + counter,..."
          ],
          [
           "digits\n\npca\n\ncomponents.png')\n\nManifold Learning¶\n\nLLE vs MDS Linkages¶\n\nIn [42]:\n\ndef make_hello(N=..."
          ],
          [
           "z = np.sign(t)\n\n(np.cos(t)\n\n1)\n\nreturn np.vstack((x, y, z)).T\n\nX = make_hello(1000) XS = make_hello_..."
          ],
          [
           "for axi, title, lines in zip(ax, titles, [lines_MDS, lines_LLE]): axi.scatter3D(XS[:, 0], XS[:, 1], ..."
          ],
          [
           "def make_ax(fig, gs):\n\nax = fig.add_subplot(gs)\n\nax.xaxis.set_major_formatter(plt.NullFormatter())\n\n..."
          ],
          [
           "# Finish iteration centers = new_centers ax1.text(0.95, 0.95, \"E-Step\", transform=ax1.transAxes, ha=..."
          ],
          [
           "def plot_points(X, labels, n_clusters): plt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis'..."
          ],
          [
           "plt.xlim(\n\n4, 4)\n\nplt.ylim(\n\n2, 10)\n\nif frame % 3 == 1: plt.text(3.8, 9.5, \"1. Reassign points to ne..."
          ],
          [
           "# Draw the Ellipse for nsig in range(1, 4): ax.add_patch(Ellipse(position, nsig * width, nsig * heig..."
          ],
          [
           "5. Machine Learning¶ What Is Machine Learning? Introducing Scikit-Learn Hyperparameters and Model Va..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "marker": {
          "color": "#00cc96",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\PythonDSHandbook-VanderPlas.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -4.0849695,
          -5.8085155,
          -5.404238,
          -3.5928752,
          -4.0652895,
          -3.902263,
          -3.7537887,
          -4.1964116,
          -2.9773965,
          -2.0112152,
          -2.174055,
          -4.2059097,
          -3.1910396,
          -1.8424842,
          -1.6904345,
          -1.6130252,
          -1.7448153,
          -1.8165002,
          -1.848285,
          -1.808541,
          -1.7098808,
          -1.8520993,
          -1.7687069,
          -1.8570191,
          10.438133,
          -1.7649105,
          -1.678097,
          -1.7033404,
          -2.0940037,
          -1.7168674,
          -1.8754272,
          -1.8628616,
          -1.8352902,
          -1.6861686,
          -1.669672,
          -1.6805671,
          -1.7034479,
          -1.6829305,
          -1.7180843,
          10.393635,
          10.21887,
          10.387372,
          10.350523,
          10.429487,
          10.372631,
          10.400761,
          -3.559397,
          -2.9044695,
          9.602544,
          -3.3106453,
          -4.1637616,
          9.847438,
          10.3008795,
          10.287471,
          9.949161,
          9.457041,
          9.417641,
          9.101852,
          9.616744,
          10.027971,
          9.010313,
          9.054689,
          8.9071045,
          8.871054,
          8.628972,
          8.611732,
          8.50921,
          8.475333,
          8.27665,
          8.607352,
          8.657237,
          8.9575615,
          10.165824,
          8.307209,
          8.173097,
          8.053413,
          8.016226,
          8.69044,
          8.244845,
          7.9360957,
          8.116233,
          8.459574,
          8.248329,
          8.810654,
          9.48897,
          8.880513,
          9.29043,
          8.460176,
          7.246359,
          8.573374,
          8.298311,
          8.278021,
          8.388373,
          8.406035,
          8.806534,
          8.281848,
          8.477451,
          7.443841,
          7.6104155,
          7.931043,
          7.843837,
          7.9138856,
          7.611381,
          7.598939,
          7.73676,
          7.3348837,
          7.982315,
          7.8608727,
          8.880044,
          8.7226,
          8.539013,
          8.886867,
          9.107302,
          8.454887,
          -1.805278,
          -1.8176277,
          9.345026,
          9.481114,
          9.24463,
          8.853706,
          9.051918,
          8.8436,
          9.026601,
          8.771186,
          -8.263033,
          9.954023,
          10.574271,
          10.445363,
          10.5919895,
          10.387312,
          9.9399,
          10.065363,
          9.794895,
          -3.5186932,
          -4.090268,
          -4.266838,
          12.735427,
          12.713011,
          13.061855,
          13.258278,
          13.408113,
          13.4030485,
          13.405228,
          11.91987,
          12.485889,
          12.61853,
          13.140369,
          12.45103,
          12.776524,
          12.82446,
          13.034407,
          13.627544,
          13.261404,
          14.065752,
          6.766112,
          13.21959,
          13.230191,
          14.240609,
          14.206264,
          11.596533,
          10.404525,
          11.697977,
          11.365113,
          10.4068,
          11.215178,
          11.246186,
          11.798405,
          11.469053,
          11.267566,
          9.753174,
          9.29267,
          11.137724,
          11.472919,
          11.54369,
          11.339081,
          11.519619,
          11.382352,
          11.826054,
          13.630037,
          13.768734,
          13.852705,
          13.621526,
          13.677621,
          13.687858,
          13.7655115,
          13.427558,
          13.008396,
          13.511075,
          13.561489,
          13.046302,
          13.132213,
          13.3475,
          13.283885,
          14.110762,
          13.267673,
          6.540763,
          12.264845,
          16.762321,
          9.283203,
          16.991032,
          17.064657,
          17.054012,
          16.927258,
          16.962296,
          17.156422,
          17.146904,
          17.03943,
          16.946754,
          16.461716,
          16.897707,
          17.237967,
          17.309542,
          17.210424,
          17.218054,
          17.234507,
          17.331417,
          17.298792,
          17.217175,
          17.21745,
          17.175928,
          17.123753,
          17.16918,
          17.112906,
          16.690985,
          14.78874,
          15.0992365,
          14.723282,
          14.963813,
          14.694333,
          14.70759,
          14.602057,
          14.711682,
          7.6601987,
          7.9287186,
          7.778048,
          7.6212792,
          8.256644,
          8.911562,
          9.010861,
          8.273822,
          7.696437,
          7.2060533,
          7.8498874,
          9.345036,
          9.375817,
          9.269067,
          9.312145,
          9.1445875,
          8.909654,
          9.06778,
          7.764281,
          7.6372375,
          8.046496,
          7.692404,
          7.9116607,
          7.8578734,
          7.7977905,
          8.172294,
          7.6844916,
          5.556086,
          5.233073,
          4.744102,
          4.6829734,
          4.7043214,
          4.6255383,
          10.746267,
          10.7066345,
          -1.4282651,
          10.748626,
          10.757267,
          10.799151,
          10.634686,
          10.494002,
          10.464604,
          10.339711,
          10.536453,
          10.378379,
          10.691495,
          6.2814837,
          6.4892163,
          6.462156,
          6.4707212,
          6.4303308,
          6.428513,
          6.4071436,
          6.3289046,
          6.439134,
          6.4044213,
          6.454109,
          6.3590636,
          5.881364,
          6.366002,
          5.8535714,
          5.609588,
          5.329306,
          5.486256,
          5.820566,
          5.6016064,
          5.5474534,
          5.2554393,
          5.155504,
          5.0893245,
          4.9246826,
          9.414802,
          8.442769,
          9.390257,
          9.210332,
          9.499048,
          9.716839,
          10.131641,
          9.648601,
          9.619501,
          9.210554,
          -3.844557,
          -4.0604177,
          1.026399,
          0.80633813,
          1.0660374,
          1.4422153,
          1.1560823,
          1.370946,
          1.2381089,
          1.163406,
          -4.4087205,
          1.1702857,
          0.9497136,
          0.52419245,
          1.5918527,
          1.2695086,
          0.91662747,
          0.5164203,
          0.12735106,
          -0.4643287,
          -0.55203897,
          -3.3653138,
          -3.3343012,
          -4.246689,
          -3.7869453,
          -1.4245399,
          -1.4440548,
          -0.8731185,
          -1.2739191,
          -1.6444646,
          -1.6703978,
          -1.8450695,
          -2.6452792,
          1.0758882,
          0.80082506,
          0.6904844,
          0.5790312,
          1.0810281,
          -0.1777002,
          -0.59161973,
          -0.87413305,
          -0.67009115,
          -0.8504225,
          -9.366374,
          1.314384,
          1.6567838,
          1.7566735,
          1.6410707,
          1.7784238,
          3.6233795,
          4.3203473,
          2.5049424,
          1.6008105,
          1.8581688,
          2.1556318,
          1.120413,
          1.9453259,
          1.5991338,
          1.6683795,
          1.7608601,
          1.7736591,
          1.7380761,
          1.6592345,
          1.7385813,
          1.3911778,
          0.39715686,
          0.82695997,
          0.6794424,
          0.65149236,
          0.56869227,
          0.2020601,
          -1.1283702,
          -1.1400543,
          -1.5151156,
          -1.6142219,
          -1.9241167,
          -1.3921578,
          -1.1868575,
          -1.3078655,
          -1.2805675,
          -1.2722125,
          -1.2365397,
          -1.3387042,
          -1.3271819,
          -1.3156513,
          -1.1838064,
          -0.97920203,
          6.302754,
          -1.0826725,
          0.3889399,
          1.0671707,
          0.55725485,
          -1.5020356,
          6.836462,
          6.6222286,
          7.5402637,
          6.798953,
          6.610907,
          6.553792,
          6.597636,
          6.3692565,
          6.491858,
          6.48051,
          6.5440917,
          0.91835296,
          0.9218388,
          -5.79474,
          -4.1931014,
          -5.6932263,
          -5.6011825,
          -6.0672626,
          -5.3845983,
          -7.564767,
          -6.0232224,
          -8.788137,
          -5.438922,
          -7.067427,
          -7.3263984,
          -7.251268,
          -6.1677957,
          -5.834367,
          -5.787424,
          -5.5598,
          -6.57654,
          -6.686102,
          -7.2073174,
          -9.713608,
          -9.203451,
          -9.526982,
          -7.017152,
          -7.9907737,
          -6.5836625,
          -7.0142593,
          -6.4437103,
          -5.961232,
          -5.2422557,
          -5.497156,
          -5.817694,
          -5.679891,
          -5.8782325,
          -5.1526294,
          -5.5530276,
          -5.7018123,
          -5.943671,
          -6.277193,
          -5.871624,
          -5.429267,
          -5.255476,
          -3.9831135,
          -3.0200665,
          -4.7414346,
          -4.9922795,
          -4.799096,
          -4.9558406,
          11.524963,
          -4.8476963,
          -5.7563314,
          -5.8724055,
          -6.289902,
          -6.4008045,
          -5.7306237,
          -5.3394256,
          -5.196131,
          -5.7060943,
          -6.109435,
          -5.7196665,
          -5.2088184,
          -4.6922507,
          -4.6565804,
          -5.039485,
          -5.047317,
          -5.1200466,
          -5.092566,
          -4.919759,
          5.166502,
          5.050323,
          5.3435907,
          5.240828,
          4.799933,
          5.242624,
          4.8230257,
          -6.8726244,
          -7.04095,
          -6.8660994,
          -6.942144,
          -7.0030274,
          -6.839306,
          -6.6392684,
          -6.9146886,
          -6.8945107,
          -7.0563974,
          -8.638737,
          -7.2050185,
          -7.4466133,
          -8.293058,
          -7.158349,
          -12.14189,
          -4.8397365,
          -5.103549,
          -4.5071225,
          -11.719524,
          -4.418798,
          -10.830055,
          -9.148572,
          -8.152892,
          -9.0272045,
          -8.824194,
          -9.149909,
          -9.237026,
          -9.345092,
          -8.75136,
          -9.298028,
          -9.208241,
          -9.364627,
          -9.060447,
          -8.912123,
          -9.140861,
          -9.0396185,
          -8.957013,
          -7.86689,
          -8.002524,
          -8.176925,
          -8.567868,
          -8.736817,
          -8.77359,
          -8.890367,
          -8.916284,
          -9.003932,
          -8.269029,
          -8.8537445,
          -9.256974,
          -9.469922,
          -9.734386,
          -9.753791,
          -9.772714,
          -9.631764,
          -9.819686,
          -9.788466,
          -9.818615,
          -9.63926,
          -9.900041,
          -0.8092636,
          -9.402522,
          -9.817012,
          -9.67784,
          -9.917039,
          -9.816553,
          -9.8595915,
          -9.981792,
          -9.631221,
          -9.851365,
          -9.852548,
          -9.834815,
          -9.846317,
          -9.82381,
          -9.625367,
          -6.875642,
          -1.9210942,
          -1.8074534,
          -2.0361283,
          -2.7721722,
          -5.0199566,
          -6.050975,
          -5.5641656,
          -1.6172901,
          -1.4516324,
          -6.408357,
          -6.005824,
          -5.98259,
          -6.309443,
          -6.408133,
          -6.7419686,
          -8.359712,
          -8.428682,
          -8.72091,
          -8.671342,
          -8.615263,
          -8.454958,
          -8.649983,
          -8.583038,
          -8.531822,
          -5.5461855,
          -5.38575,
          0.8996773,
          0.8265528,
          0.66953635,
          0.38976717,
          0.23541582,
          0.20279698,
          0.458755,
          0.21100837,
          0.28011575,
          1.2548362,
          1.2340622,
          1.3895704,
          -6.4406486,
          -6.8872666,
          -6.5423846,
          -6.369472,
          1.2649282,
          -6.484486,
          -8.649258,
          -7.8711452,
          -6.988137,
          -6.4426527,
          -6.027302,
          -6.641799,
          -6.3423915,
          -6.4116693,
          -6.2704997,
          -6.493216,
          -8.06029,
          -5.977444,
          -5.306302,
          -5.0848074,
          -4.9298754,
          -4.879165,
          -1.0959648,
          -4.9396663,
          -5.298334,
          -8.300794,
          -8.249532,
          -8.150177,
          -8.5484495,
          -8.401852,
          -8.637996,
          -7.8387337,
          -9.306691,
          -8.732136,
          -9.109524,
          -8.187867,
          -5.6000047
         ],
         "xaxis": "x",
         "y": [
          -6.897065,
          -5.127376,
          -4.177553,
          -6.6339445,
          -6.478919,
          -6.4455366,
          -6.5821342,
          -6.8784266,
          -7.3250422,
          -8.226637,
          -8.216017,
          -6.962182,
          -7.162307,
          -8.294979,
          -8.608555,
          -8.345343,
          -8.229747,
          -8.468136,
          -8.559079,
          -8.458859,
          -8.5391655,
          -8.47347,
          -8.571341,
          -8.4113,
          -4.34469,
          -8.450706,
          -8.347529,
          -8.54634,
          -8.221056,
          -8.089297,
          -8.336634,
          -8.293188,
          -8.400039,
          -8.728493,
          -8.738905,
          -8.847147,
          -8.744771,
          -8.852912,
          -8.902782,
          -4.5126057,
          -4.6225414,
          -4.4982457,
          -4.3602133,
          -4.4759364,
          -4.4133906,
          -4.3986316,
          -6.921916,
          -7.3679323,
          -3.2133784,
          -6.636494,
          -6.9725375,
          -3.3396647,
          -3.184126,
          -3.4896038,
          -3.200861,
          -3.5526404,
          -3.7393725,
          -3.3484418,
          -3.1918762,
          -3.1691244,
          -3.7418745,
          -3.8658488,
          -4.0256305,
          -4.331999,
          -4.3335614,
          -4.276745,
          -4.0238485,
          -4.1622596,
          -3.8189573,
          -4.3222117,
          -4.3462873,
          -2.5390794,
          -3.854023,
          -2.7350829,
          -2.5095732,
          -2.220472,
          -2.1107004,
          -2.9186764,
          -2.188621,
          -2.4238727,
          -2.2754948,
          -2.710178,
          -2.4085526,
          -1.4632657,
          -2.8066983,
          -1.0397506,
          -1.5413578,
          -0.58230203,
          1.2949908,
          -2.5247376,
          -3.3145435,
          -3.3925204,
          -3.1452603,
          -3.438195,
          -2.8703775,
          -2.9457898,
          -2.322822,
          -0.79524857,
          -0.778113,
          -1.3007959,
          -1.6119488,
          -1.2758254,
          -0.9582698,
          -1.0647469,
          -1.1416295,
          -0.5506633,
          -1.5946082,
          -1.3763846,
          -4.3486395,
          -4.0068293,
          -4.077548,
          -4.291377,
          -4.605821,
          -3.18742,
          3.3881793,
          3.4012065,
          -4.3625336,
          -4.503222,
          -4.5856266,
          -4.786201,
          -4.974246,
          -5.2369237,
          -5.1826954,
          -5.3830004,
          2.3794963,
          -3.5808806,
          -2.075761,
          -1.6026341,
          -1.3363036,
          -2.5909803,
          -2.943619,
          -2.2525165,
          -3.2479048,
          -6.236931,
          -6.890031,
          -6.6422744,
          -1.8704734,
          -1.6161838,
          -1.5072882,
          -1.4501227,
          -1.1766336,
          -1.4419243,
          -1.3139827,
          -1.0568544,
          -1.6864886,
          -1.867731,
          -1.3867743,
          -1.6094701,
          -1.609568,
          -1.6682949,
          -1.7903535,
          -1.28428,
          -1.3429152,
          -1.0904256,
          1.8842667,
          -1.5916225,
          -1.5219945,
          -1.2490685,
          -1.4621698,
          -1.1720355,
          -2.05223,
          -1.2058755,
          -0.8758544,
          -0.47388998,
          -0.97551996,
          -0.7107262,
          -0.6998181,
          -0.7478185,
          -1.0732281,
          -1.5918375,
          -2.092355,
          -0.86022943,
          -0.73283273,
          -0.7362854,
          -0.5389363,
          -0.76084965,
          -0.63451326,
          -0.7640312,
          -0.82295215,
          -0.4874243,
          -0.63488674,
          -0.60965043,
          -0.4478014,
          -0.5951988,
          -0.67072004,
          -0.5204879,
          -0.3278569,
          -0.7299795,
          -0.57243305,
          -0.6599198,
          -0.5768783,
          -0.90979487,
          -0.9336905,
          -0.7836291,
          -0.49972296,
          1.939132,
          -0.5961305,
          -1.8873137,
          -2.5791268,
          -1.9855168,
          -2.0060108,
          -1.9870651,
          -1.9544463,
          -2.0068793,
          -2.0132515,
          -2.0295727,
          -1.9941252,
          -1.9439645,
          -1.7842802,
          -1.8259369,
          -1.9204569,
          -1.9367613,
          -1.9105532,
          -1.9148871,
          -1.9271448,
          -1.9051229,
          -1.9367297,
          -1.9236549,
          -1.9154137,
          -1.9281601,
          -1.909328,
          -1.9033588,
          -1.9076135,
          -1.783732,
          -1.2876327,
          -1.3086555,
          -1.1637534,
          -1.2820826,
          -1.2435888,
          -1.199679,
          -1.2595447,
          -1.2861077,
          1.017498,
          1.0187652,
          1.139854,
          1.3564106,
          0.60314566,
          1.3271942,
          0.9906989,
          1.0950656,
          1.2448716,
          1.7580395,
          1.311394,
          0.90106606,
          0.92166156,
          1.1134737,
          0.9114614,
          1.0843167,
          1.2948129,
          1.1810156,
          1.4668567,
          1.2652862,
          2.0451264,
          2.1437004,
          2.0736272,
          2.3743646,
          2.0413024,
          2.0598702,
          2.1907728,
          2.41606,
          2.8475614,
          3.0299242,
          3.055244,
          3.032608,
          3.0865028,
          -1.0322345,
          -0.8405221,
          -8.084199,
          -0.69928,
          -0.7016062,
          -0.48350728,
          -0.8834822,
          -0.8413737,
          -0.79860157,
          -0.69416434,
          -0.72627336,
          -0.6669107,
          -0.74231595,
          4.553406,
          4.8657627,
          4.841583,
          4.8036566,
          4.755064,
          4.818974,
          4.7837563,
          4.6163774,
          4.785344,
          4.767355,
          4.8166876,
          4.652666,
          3.8035064,
          4.6747975,
          3.742989,
          3.0844808,
          3.142076,
          3.1179242,
          3.4035163,
          2.9549716,
          2.0471346,
          1.9032383,
          2.054254,
          1.8489728,
          1.9561564,
          -1.3732454,
          -1.2363831,
          -0.6247208,
          -0.6504483,
          -0.37916595,
          -0.4590036,
          -0.088030435,
          0.020141698,
          -0.34437075,
          -0.8717977,
          -6.8583736,
          -6.775495,
          5.9619875,
          5.824996,
          5.742347,
          5.781471,
          5.953419,
          5.5891585,
          5.779574,
          6.0398974,
          -6.808683,
          5.799472,
          5.748527,
          5.6744986,
          5.450746,
          5.730085,
          5.7193866,
          5.683739,
          5.852895,
          5.719186,
          5.3186417,
          3.4901702,
          3.3538713,
          3.0110557,
          2.6916597,
          5.418819,
          5.4927697,
          5.551839,
          4.932741,
          3.6645463,
          3.6815226,
          3.5757585,
          3.3062913,
          5.595236,
          5.7667713,
          4.532936,
          5.7002277,
          5.411269,
          5.71757,
          5.7635627,
          5.629033,
          5.726048,
          5.703105,
          3.1342447,
          5.0642967,
          5.201303,
          4.9373417,
          5.1724606,
          4.9725413,
          3.5554876,
          3.1448228,
          3.7434494,
          5.070418,
          4.8997746,
          4.1327415,
          3.1661391,
          3.6054668,
          4.817533,
          5.058092,
          4.993277,
          4.9895926,
          5.1592464,
          4.863731,
          4.871405,
          5.051027,
          4.7628827,
          5.4712715,
          5.52111,
          5.507807,
          5.4897656,
          5.2007923,
          5.513849,
          5.4902573,
          5.6076417,
          5.5731373,
          5.544331,
          5.5970607,
          7.040352,
          6.9938097,
          6.9645824,
          6.853983,
          6.9650826,
          7.0294647,
          7.11172,
          6.929805,
          6.854754,
          6.1899467,
          1.5616431,
          6.5118017,
          6.197611,
          5.474644,
          5.5361085,
          3.9609528,
          1.8493557,
          2.0211556,
          1.5472413,
          1.9269332,
          4.3839846,
          2.2942946,
          2.0873785,
          2.0842779,
          2.1274529,
          2.1164212,
          2.1025453,
          5.995619,
          5.886939,
          -5.202198,
          -6.9293065,
          -4.851665,
          -3.4317658,
          -1.2340536,
          -2.4226825,
          1.7633194,
          -2.788351,
          2.4536898,
          -4.6861343,
          -2.3421295,
          -2.1240125,
          -2.052257,
          -1.5074711,
          -2.533136,
          -0.57863766,
          -0.02570773,
          -1.1348476,
          -1.2189194,
          -1.6930071,
          4.474747,
          2.8548548,
          3.286207,
          -0.9133822,
          -0.20889685,
          -1.1416996,
          -1.1683583,
          -0.7005616,
          0.03863426,
          -0.0043192757,
          0.6581317,
          0.22549482,
          0.20613362,
          0.35452476,
          2.0938883,
          0.9230609,
          1.2493447,
          0.36144012,
          3.4343395,
          0.6957979,
          1.2039499,
          -3.1226249,
          -1.6447539,
          -0.65003335,
          -2.2565827,
          -1.6545328,
          -1.4547096,
          1.3329089,
          -0.5605249,
          0.94502175,
          -1.9536606,
          -1.3385696,
          -1.1438202,
          -0.6770833,
          -1.572607,
          -1.7408836,
          -2.1652405,
          -1.6627232,
          -1.2671474,
          0.76719546,
          1.1597111,
          1.2430419,
          1.5622823,
          1.4897035,
          2.0639646,
          2.0968533,
          0.24453983,
          0.019725174,
          1.9606134,
          1.8031391,
          1.9615643,
          2.460003,
          1.6610193,
          1.8650752,
          1.5062824,
          0.68619335,
          1.8802284,
          1.926523,
          2.1187508,
          2.0421996,
          2.166184,
          1.8240035,
          1.84672,
          1.7850244,
          1.9124919,
          0.7624329,
          0.07190615,
          -0.78080195,
          0.198457,
          0.79986763,
          -1.6962892,
          3.4679112,
          3.5344167,
          3.008439,
          -1.487885,
          0.4092225,
          -0.76692206,
          1.9092788,
          -0.20558006,
          2.6511831,
          2.893534,
          3.060253,
          3.1540926,
          3.4788263,
          2.611938,
          3.2534966,
          3.2834024,
          3.322147,
          3.3786402,
          3.2542593,
          2.7838838,
          2.4437613,
          2.5525992,
          4.0305705,
          2.332415,
          2.5895326,
          2.4956603,
          2.57395,
          2.8570998,
          2.7863224,
          2.7319977,
          2.8991098,
          3.1577826,
          2.6625764,
          3.2475238,
          3.2835963,
          5.5129323,
          5.511239,
          5.491457,
          5.502545,
          5.4738054,
          5.5360923,
          5.27722,
          3.9041471,
          5.1616473,
          5.70694,
          5.3599305,
          5.184941,
          5.2881546,
          5.506734,
          5.43732,
          4.97818,
          5.1631994,
          5.0123115,
          5.1410275,
          4.9664917,
          4.873503,
          4.749691,
          4.400721,
          3.8825586,
          0.20342031,
          3.370609,
          3.3357384,
          3.247163,
          2.9569507,
          1.0617628,
          0.09380166,
          0.7032835,
          5.697028,
          5.7347317,
          -0.5771445,
          -0.1924517,
          -0.52760273,
          -0.86902046,
          0.013441774,
          -0.2934934,
          0.3423599,
          0.33372048,
          0.42343953,
          0.39453152,
          0.5155227,
          0.34790435,
          0.33022815,
          0.43797845,
          0.30431467,
          -5.221858,
          -4.5152636,
          3.7163372,
          3.1093967,
          2.8127806,
          2.4986196,
          2.3138976,
          2.264913,
          2.5256748,
          2.212679,
          2.3244677,
          4.128604,
          3.4755168,
          3.3352592,
          3.8737824,
          2.8643904,
          3.8600037,
          3.688149,
          4.2075233,
          3.7376177,
          4.9324174,
          4.202143,
          3.7191896,
          3.677202,
          3.285306,
          3.8600917,
          3.6000204,
          3.7320833,
          3.8057761,
          3.8906796,
          4.381697,
          3.3644826,
          3.755413,
          3.6660867,
          3.557036,
          3.5299642,
          1.3876101,
          3.6354654,
          3.6695533,
          3.7384725,
          3.7657642,
          3.794084,
          3.2717402,
          4.296107,
          4.842377,
          4.2799873,
          5.4253764,
          4.9182887,
          5.07654,
          4.340127,
          -4.9815617
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay hello welcome to uh week 11's lecture uh it's been a little while since we\n\ntalked about some o..."
          ],
          [
           "all right and so uh what we're gonna do is we're gonna build our models off of this training set all..."
          ],
          [
           "you right here the answer is probably not right to a certain extent they they will but it's importan..."
          ],
          [
           "in a classification standpoint all right so we're doing all classification here i'll talk about regr..."
          ],
          [
           "outputs so the idea is that they're they can't they'll predict hard classes right these ones are zer..."
          ],
          [
           "think back to what i just said about the 75 25 scenario all right\n\nand let's be more discreet about ..."
          ],
          [
           "and true positive are good all right so we want these numbers here we've talked about this before to..."
          ],
          [
           "all the way up to all the way up to 100 right so now nothing is fraud\n\neverybody becomes rich throug..."
          ],
          [
           "this true positive true positive false negative i think we walked through this so i'm going to spend..."
          ],
          [
           "positive and false positive rate and those just become data points on a axis you just graph them\n\non..."
          ],
          [
           "all right what this means is that your your your classifier is contributing absolutely nothing right..."
          ],
          [
           "precision and recall okay it's particularly useful if you have unbalanced data sets right\n\nif you ha..."
          ],
          [
           "that wrong log loss takes that into account okay all right so if we see a log loss\n\nof one can be ex..."
          ],
          [
           "right but basically the way you calculate this is that you know say we had you know and that's good ..."
          ],
          [
           "substantial agreement so we've got two that agree here right that's how campo works it's just\n\nthat ..."
          ],
          [
           "so there's different metrics that you would use to assess a continuous variable right kind of in a r..."
          ],
          [
           "right but this is not going to be in the language of the dependent root mean squared error will be a..."
          ],
          [
           "i bring this up because it's associated with thresholding because if you want to adjust the threshol..."
          ],
          [
           "would see over here right all right this one here is going to have high bias\n\nokay it's going to be ..."
          ],
          [
           "this second white circle right but it is on target okay so we've introduced a bunch of\n\nconcept here..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week7-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "marker": {
          "color": "#ab63fa",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week7-lecture.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -5.464925,
          -12.88394,
          -13.286949,
          -13.252674,
          -13.264349,
          -13.244073,
          -13.315072,
          -13.315798,
          -13.259501,
          -13.243091,
          -13.210565,
          -13.234584,
          -13.279276,
          -13.321549,
          -13.13496,
          -13.25654,
          -13.077463,
          -12.26333,
          -12.642505,
          -12.936676
         ],
         "xaxis": "x",
         "y": [
          -4.40962,
          -2.8021955,
          -3.1479092,
          -2.989463,
          -3.0229714,
          -3.0769913,
          -3.1669786,
          -3.0728624,
          -3.0554833,
          -3.061383,
          -3.0220447,
          -3.1050084,
          -3.1051722,
          -2.9980085,
          -2.8683226,
          -2.820372,
          -2.757552,
          -2.3623583,
          -2.4761975,
          -2.9316232
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "okay all right so let me pop this up here\n\nbigger i can do that there we go all right so we've been ..."
          ],
          [
           "way and so here what we see this is our this is our root note up here all right this is the old clas..."
          ],
          [
           "what's your favorite music you know if you don't know this one i guess it depends on your your\n\nyour..."
          ],
          [
           "hurdle and now you're on to what music do you like right and so\n\nhere you know it might be that you ..."
          ],
          [
           "okay excuse me and then we get more specific right based off the type of\n\nmusic that people are inte..."
          ],
          [
           "the model is is built such that a sequence of ordered decisions concerning the value result and you ..."
          ],
          [
           "individual node those individual internal leaves okay all right\n\nand it will consider every possible..."
          ],
          [
           "tree all right it was first uh introduced here by 1984 with these four\n\nresearchers all right it can..."
          ],
          [
           "and then even when you get up to ensemble models with random force they also become a little a littl..."
          ],
          [
           "small variations in the data because of the nature of how they're how they're designed all right so\n..."
          ],
          [
           "compared to predict the class and these are the two common ones for classification they're really ve..."
          ],
          [
           "here so what we see here right it's just a total you know kind of one class example obviously we we ..."
          ],
          [
           "date which makes sense all right so they yes all right the people the no date uh stop right there al..."
          ],
          [
           "i guess it was pedal width right so at a certain numerical range 1.75\n\nor greater or was it less any..."
          ],
          [
           "that could be gained uh and specific to to the um this is the you know when on a date\n\ncategory so w..."
          ],
          [
           "right and then when we look across what we see is we have two nodes and one yes all right so it does..."
          ],
          [
           "when we do this weighted average obvious this is all going to be zero just like i said before it's g..."
          ],
          [
           "um you just have a you know a tree with the depth of just one split and that's it okay\n\nso that's en..."
          ],
          [
           "when we do when we did enthalpy here we see it's 0.5 which kind of represents a perfect\n\nsplit okay ..."
          ],
          [
           "variable at that particular split and then it will include the variable that reduces the mean square..."
          ],
          [
           "and one solution is we can tune those hyper parameters all right so another solution is built to ens..."
          ],
          [
           "are available all right are ones that have not been used uh anywhere higher all right\n\ninside the sp..."
          ],
          [
           "test is you know basically they compete against each other all right as the training set gets\n\nbigge..."
          ],
          [
           "okay so um let's take a look at overfitting all\n\nright um again uh we've talked about well you guys ..."
          ]
         ],
         "hovertemplate": "source=RAG-docs\\processed\\Week9-lecture.txt<br>symbol=circle<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "marker": {
          "color": "#FFA15A",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4,
           4
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "RAG-docs\\processed\\Week9-lecture.txt, circle",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -12.657882,
          -12.885225,
          -12.914273,
          -13.128876,
          -12.849899,
          -12.9684925,
          -12.878056,
          -12.855892,
          -12.352574,
          -12.396778,
          -13.323241,
          -13.425886,
          -13.214281,
          -13.409359,
          -13.031398,
          -13.556661,
          -13.454118,
          -13.224075,
          -13.267784,
          -12.793197,
          -12.410268,
          -12.66126,
          -12.222678,
          -12.391755
         ],
         "xaxis": "x",
         "y": [
          -1.9360416,
          -1.9633291,
          -2.0857701,
          -2.2322655,
          -2.0037165,
          -2.124319,
          -2.071521,
          -2.1134868,
          -1.9241482,
          -1.7898011,
          -2.7179828,
          -2.5256922,
          -2.360219,
          -2.7839243,
          -2.211704,
          -2.8800263,
          -2.838909,
          -2.4669707,
          -2.6105905,
          -2.0910318,
          -1.8179412,
          -1.9503797,
          -2.052444,
          -1.884632
         ],
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "What is One-Hot encoding?"
          ]
         ],
         "hovertemplate": "source=User query<br>symbol=star<br>x=%{x}<br>y=%{y}<br>size_col=%{marker.size}<br>extract=%{customdata[0]}<extra></extra>",
         "legendgroup": "User query, star",
         "marker": {
          "color": "black",
          "line": {
           "color": "DarkSlateGrey",
           "width": 0
          },
          "opacity": 1,
          "size": [
           100
          ],
          "sizemode": "area",
          "sizeref": 0.25,
          "symbol": "diamond"
         },
         "mode": "markers",
         "name": "User query, star",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          -2.5623121
         ],
         "xaxis": "x",
         "y": [
          -0.308523
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "height": 700,
        "legend": {
         "itemsizing": "constant",
         "title": {
          "text": "<b>Chunk source</b>"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "<b>2D Projection of Chunk Embeddings via PaCMAP</b>"
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "x"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "y"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# vistualize pca projection\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"x\": documents_projected[i, 0],\n",
    "            \"y\": documents_projected[i, 1],\n",
    "            \"source\": docs_processed[i].metadata[\"source\"][\"source\"],#.split(\"/\")[1],\n",
    "            \"extract\": docs_processed[i].page_content[:100] + \"...\",\n",
    "            \"symbol\": \"circle\",\n",
    "            \"size_col\": 4,\n",
    "        }\n",
    "        for i in range(len(docs_processed))\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"x\": documents_projected[-1, 0],\n",
    "            \"y\": documents_projected[-1, 1],\n",
    "            \"source\": \"User query\",\n",
    "            \"extract\": user_query,\n",
    "            \"size_col\": 100,\n",
    "            \"symbol\": \"star\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Visualize the embedding\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x=\"x\",\n",
    "    y=\"y\",\n",
    "    color=\"source\",\n",
    "    hover_data=\"extract\",\n",
    "    size=\"size_col\",\n",
    "    symbol=\"symbol\",\n",
    "    color_discrete_map={\"User query\": \"black\"},\n",
    "    width=1000,\n",
    "    height=700,\n",
    ")\n",
    "fig.update_traces(\n",
    "    marker=dict(opacity=1, line=dict(width=0, color=\"DarkSlateGrey\")),\n",
    "    selector=dict(mode=\"markers\"),\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"<b>Chunk source</b>\",\n",
    "    title=\"<b>2D Projection of Chunk Embeddings via PaCMAP</b>\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
